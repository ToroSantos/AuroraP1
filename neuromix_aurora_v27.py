# ✅ Archivo híbrido: NeuroMix V27 con fallback inteligente
# - Usa 'NeuroMixSuperUnificado' si está disponible
# - Si no, funciona como motor base autónomo


# PARCHE ADITIVO AURORA DIRECTOR V7 - Imports adicionales
import logging
from typing import Dict, Any, Protocol

# Configurar logging si no está configurado
if not logging.getLogger().handlers:
    logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger("Aurora.NeuroMix.V27.Aditivo")

import wave
import numpy as np
import json
import time
import logging
import warnings
from typing import Dict, Tuple, Optional, List, Any, Union, Protocol, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
from functools import lru_cache

SAMPLE_RATE = 44100
VERSION = "V27_AURORA_CONNECTED_PPP_COMPLETE"
CONFIDENCE_THRESHOLD = 0.8
logger = logging.getLogger("Aurora.NeuroMix.V27.Complete")
logger.setLevel(logging.WARNING)

class MotorAurora(Protocol):
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray: ...
    def validar_configuracion(self, config: Dict[str, Any]) -> bool: ...
    def obtener_capacidades(self) -> Dict[str, Any]: ...

class Neurotransmisor(Enum):
    DOPAMINA = "dopamina"
    SEROTONINA = "serotonina"
    GABA = "gaba"
    OXITOCINA = "oxitocina"
    ANANDAMIDA = "anandamida"
    ACETILCOLINA = "acetilcolina"
    ENDORFINA = "endorfina"
    BDNF = "bdnf"
    ADRENALINA = "adrenalina"
    NOREPINEFRINA = "norepinefrina"
    MELATONINA = "melatonina"
    GLUTAMATO = "glutamato"
    NORADRENALINA = "noradrenalina"
    ENDORFINAS = "endorfinas"

class EstadoEmocional(Enum):
    ENFOQUE = "enfoque"
    RELAJACION = "relajacion"
    GRATITUD = "gratitud"
    VISUALIZACION = "visualizacion"
    SOLTAR = "soltar"
    ACCION = "accion"
    CLARIDAD_MENTAL = "claridad_mental"
    SEGURIDAD_INTERIOR = "seguridad_interior"
    APERTURA_CORAZON = "apertura_corazon"
    ALEGRIA_SOSTENIDA = "alegria_sostenida"
    FUERZA_TRIBAL = "fuerza_tribal"
    CONEXION_MISTICA = "conexion_mistica"
    REGULACION_EMOCIONAL = "regulacion_emocional"
    EXPANSION_CREATIVA = "expansion_creativa"
    ESTADO_FLUJO = "estado_flujo"
    INTROSPECCION_SUAVE = "introspeccion_suave"
    SANACION_PROFUNDA = "sanacion_profunda"
    EQUILIBRIO_MENTAL = "equilibrio_mental"

class NeuroQualityLevel(Enum):
    BASIC = "básico"
    ENHANCED = "mejorado"
    PROFESSIONAL = "profesional"
    THERAPEUTIC = "terapéutico"
    RESEARCH = "investigación"

class ProcessingMode(Enum):
    LEGACY = "legacy"
    STANDARD = "standard"
    ADVANCED = "advanced"
    PARALLEL = "parallel"
    REALTIME = "realtime"
    AURORA_INTEGRATED = "aurora_integrated"

@dataclass
class NeuroConfig:
    neurotransmitter: str
    duration_sec: float
    wave_type: str = 'hybrid'
    intensity: str = "media"
    style: str = "neutro"
    objective: str = "relajación"
    quality_level: NeuroQualityLevel = NeuroQualityLevel.ENHANCED
    processing_mode: ProcessingMode = ProcessingMode.STANDARD
    enable_quality_pipeline: bool = True
    enable_analysis: bool = True
    enable_textures: bool = True
    enable_spatial_effects: bool = False
    custom_frequencies: Optional[List[float]] = None
    modulation_complexity: float = 1.0
    harmonic_richness: float = 0.5
    therapeutic_intent: Optional[str] = None
    apply_mastering: bool = True
    target_lufs: float = -23.0
    export_analysis: bool = False
    aurora_config: Optional[Dict[str, Any]] = None
    director_context: Optional[Dict[str, Any]] = None
    use_scientific_data: bool = True

class SistemaNeuroacusticoCientificoV27:
    def __init__(self):
        self.version = "v27_aurora_scientific_ppp"
        self._init_data()
    
    def _init_data(self):
        self.presets_ppp = {
            "dopamina": {"carrier": 123.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4},
            "serotonina": {"carrier": 111.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3},
            "gaba": {"carrier": 90.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2},
            "acetilcolina": {"carrier": 105.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3},
            "glutamato": {"carrier": 140.0, "beat_freq": 5.0, "am_depth": 0.6, "fm_index": 5},
            "oxitocina": {"carrier": 128.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2},
            "noradrenalina": {"carrier": 135.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5},
            "endorfinas": {"carrier": 98.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2},
            "melatonina": {"carrier": 85.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1}
        }
        
        self.presets_cientificos = {
            "dopamina": {"carrier": 396.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4, "confidence": 0.94},
            "serotonina": {"carrier": 417.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.92},
            "gaba": {"carrier": 72.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2, "confidence": 0.95},
            "acetilcolina": {"carrier": 320.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3, "confidence": 0.89},
            "oxitocina": {"carrier": 528.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2, "confidence": 0.90},
            "anandamida": {"carrier": 111.0, "beat_freq": 2.5, "am_depth": 0.4, "fm_index": 2, "confidence": 0.82},
            "endorfina": {"carrier": 528.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2, "confidence": 0.87},
            "bdnf": {"carrier": 285.0, "beat_freq": 4.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.88},
            "adrenalina": {"carrier": 741.0, "beat_freq": 8.0, "am_depth": 0.9, "fm_index": 6, "confidence": 0.91},
            "norepinefrina": {"carrier": 693.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5, "confidence": 0.91},
            "melatonina": {"carrier": 108.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1, "confidence": 0.93}
        }
        
        self.presets_cientificos["glutamato"] = self.presets_cientificos["dopamina"].copy()
        self.presets_cientificos["noradrenalina"] = self.presets_cientificos["norepinefrina"].copy()
        self.presets_cientificos["endorfinas"] = self.presets_cientificos["endorfina"].copy()
        
        self.intensity_factors_ppp = {
            "muy_baja": {"carrier_mult": 0.6, "beat_mult": 0.5, "am_mult": 0.4, "fm_mult": 0.5},
            "baja": {"carrier_mult": 0.8, "beat_mult": 0.7, "am_mult": 0.6, "fm_mult": 0.7},
            "media": {"carrier_mult": 1.0, "beat_mult": 1.0, "am_mult": 1.0, "fm_mult": 1.0},
            "alta": {"carrier_mult": 1.2, "beat_mult": 1.3, "am_mult": 1.4, "fm_mult": 1.3},
            "muy_alta": {"carrier_mult": 1.4, "beat_mult": 1.6, "am_mult": 1.7, "fm_mult": 1.5}
        }
        
        self.style_factors_ppp = {
            "neutro": {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0},
            "alienigena": {"carrier_offset": 15, "beat_offset": 1.5, "complexity": 1.3},
            "minimal": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.7},
            "organico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.1},
            "cinematico": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.4},
            "ancestral": {"carrier_offset": -15, "beat_offset": -0.8, "complexity": 0.8},
            "futurista": {"carrier_offset": 25, "beat_offset": 2.0, "complexity": 1.6},
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        self.objective_factors_ppp = {
            "relajación": {"tempo_mult": 0.8, "smoothness": 1.2, "depth_mult": 1.1},
            "claridad mental + enfoque cognitivo": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "activación lúcida": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.0},
            "meditación profunda": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3},
            "energía creativa": {"tempo_mult": 1.3, "smoothness": 0.8, "depth_mult": 1.2},
            "sanación emocional": {"tempo_mult": 0.7, "smoothness": 1.4, "depth_mult": 1.2},
            "expansión consciencia": {"tempo_mult": 0.5, "smoothness": 1.6, "depth_mult": 1.4},
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
    
    def obtener_preset_ppp(self, nt: str) -> Dict[str, Any]:
        return self.presets_ppp.get(nt.lower(), {"carrier": 123.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4})
    
    def obtener_preset_cientifico(self, nt: str) -> Dict[str, Any]:
        return self.presets_cientificos.get(nt.lower(), {"carrier": 220.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4, "confidence": 0.8})
    
    def crear_preset_adaptativo_ppp(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajación") -> Dict[str, Any]:
        base = self.obtener_preset_ppp(nt)
        i_f = self.intensity_factors_ppp.get(intensity, self.intensity_factors_ppp["media"])
        s_f = self.style_factors_ppp.get(style, self.style_factors_ppp["neutro"])
        o_f = self.objective_factors_ppp.get(objective, self.objective_factors_ppp["relajación"])
        
        adapted = {
            "carrier": base["carrier"] * i_f["carrier_mult"] + s_f["carrier_offset"],
            "beat_freq": base["beat_freq"] * i_f["beat_mult"] * o_f["tempo_mult"] + s_f["beat_offset"],
            "am_depth": base["am_depth"] * i_f["am_mult"] * o_f["smoothness"] * o_f["depth_mult"],
            "fm_index": base["fm_index"] * i_f["fm_mult"] * s_f["complexity"]
        }
        
        adapted["carrier"] = max(30, min(300, adapted["carrier"]))
        adapted["beat_freq"] = max(0.1, min(40, adapted["beat_freq"]))
        adapted["am_depth"] = max(0.05, min(0.95, adapted["am_depth"]))
        adapted["fm_index"] = max(0.5, min(12, adapted["fm_index"]))
        
        return adapted

class AuroraNeuroAcousticEngineV27:
    def __init__(self, sample_rate: int = SAMPLE_RATE, enable_advanced_features: bool = True, cache_size: int = 256):
        self.sample_rate = sample_rate
        self.enable_advanced = enable_advanced_features
        self.cache_size = cache_size
        self.sistema_cientifico = SistemaNeuroacusticoCientificoV27()
        self.version = VERSION
        
        self.processing_stats = {
            'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
            'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
            'ppp_compatibility_uses': 0, 'fallback_uses': 0
        }
        
        if self.enable_advanced:
            self._init_advanced_components()
        
        logger.info(f"NeuroMix V27 Complete inicializado: Aurora + PPP + Científico")
    
    def _init_advanced_components(self):
        try:
            self.quality_pipeline = None
            self.harmonic_generator = None
            self.analyzer = None
            logger.info("Componentes Aurora avanzados cargados")
        except Exception as e:
            logger.warning(f"Componentes Aurora no disponibles: {e}")
            self.enable_advanced = False
    
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        try:
            neuro_config = self._convertir_config_aurora_a_neuromix(config, duracion_sec)
            audio_data, analysis = self.generate_neuro_wave_advanced(neuro_config)
            self.processing_stats['aurora_integrations'] += 1
            return audio_data
        except Exception as e:
            logger.error(f"Error en generar_audio: {e}")
            return self._generar_audio_fallback(duracion_sec)
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        return {
            "nombre": "NeuroMix V27 Aurora Connected + PPP Complete",
            "version": self.version,
            "tipo": "motor_neuroacustico",
            "compatible_con": ["Aurora Director V7", "PPP Functions", "Field Profiles", "Objective Router"],
            "neurotransmisores_soportados": self.get_available_neurotransmitters(),
            "tipos_onda": self.get_available_wave_types(),
            "modos_procesamiento": [modo.value for modo in ProcessingMode],
            "sample_rates": [22050, 44100, 48000],
            "duracion_minima": 1.0,
            "duracion_maxima": 3600.0,
            "calidad_maxima": "therapeutic",
            "compatibilidad_ppp": True,
            "compatibilidad_aurora": True,
            "fallback_garantizado": True,
            "validacion_cientifica": True,
            "estadisticas": self.processing_stats.copy()
        }
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """
        Valida configuración para Aurora Director V7
        AGREGAR después del método obtener_capacidades
        """
        try:
            if not isinstance(config, dict):
                return False
            
            # Validar campo objetivo obligatorio
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            # Validar duración (si viene en config)
            duracion = config.get('duracion_sec') or config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            # Validar intensidad
            intensidad = config.get('intensidad', 'media')
            intensidades_validas = ['muy_baja', 'baja', 'media', 'alta', 'muy_alta']
            if intensidad not in intensidades_validas:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validando configuración: {e}")
            return False
    
    def get_info(self) -> Dict[str, str]:
        """
        Información básica del motor para Aurora Director V7
        AGREGAR después del método validar_configuracion
        """
        return {
            "name": "NeuroMix Aurora V27 Connected",
            "version": self.version,
            "description": "Motor neuroacústico principal con ondas binaurales y neurotransmisores",
            "capabilities": "AM/FM, PPP, Neurotransmisores, Análisis FFT",
            "integration": "Aurora Director V7 Compatible",
            "status": "Conectado y operativo"
        }
    
    def _convertir_config_aurora_a_neuromix(self, config_aurora: Dict[str, Any], duracion_sec: float) -> NeuroConfig:
        neurotransmisor = config_aurora.get('neurotransmisor_preferido', 'serotonina')
        
        if not neurotransmisor or neurotransmisor == 'auto':
            neurotransmisor = self._inferir_neurotransmisor_por_objetivo(config_aurora.get('objetivo', 'relajacion'))
        
        return NeuroConfig(
            neurotransmitter=neurotransmisor,
            duration_sec=duracion_sec,
            wave_type='hybrid',
            intensity=config_aurora.get('intensidad', 'media'),
            style=config_aurora.get('estilo', 'neutro'),
            objective=config_aurora.get('objetivo', 'relajacion'),
            aurora_config=config_aurora,
            processing_mode=ProcessingMode.AURORA_INTEGRATED,
            use_scientific_data=True,
            quality_level=self._mapear_calidad_aurora(config_aurora.get('calidad_objetivo', 'alta')),
            enable_quality_pipeline=config_aurora.get('normalizar', True),
            apply_mastering=True,
            target_lufs=-23.0
        )
    
    def _inferir_neurotransmisor_por_objetivo(self, objetivo: str) -> str:
        objetivo_lower = objetivo.lower()
        mapeo = {'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina', 'enfoque': 'norepinefrina',
                'relajacion': 'gaba', 'meditacion': 'serotonina', 'creatividad': 'anandamida',
                'energia': 'adrenalina', 'sanacion': 'oxitocina', 'gratitud': 'oxitocina'}
        
        for key, nt in mapeo.items():
            if key in objetivo_lower: return nt
        return 'serotonina'
    
    def _mapear_calidad_aurora(self, calidad_aurora: str) -> NeuroQualityLevel:
        mapeo = {'basica': NeuroQualityLevel.BASIC, 'media': NeuroQualityLevel.ENHANCED,
                'alta': NeuroQualityLevel.PROFESSIONAL, 'maxima': NeuroQualityLevel.THERAPEUTIC}
        return mapeo.get(calidad_aurora, NeuroQualityLevel.ENHANCED)
    
    def get_neuro_preset(self, nt: str) -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        return self.sistema_cientifico.obtener_preset_ppp(nt)
    
    def get_adaptive_neuro_preset(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajación") -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        if self.enable_advanced and hasattr(self, '_get_scientific_preset'):
            return self._get_scientific_preset(nt, intensity, style, objective)
        return self.sistema_cientifico.crear_preset_adaptativo_ppp(nt, intensity, style, objective)
    
    def generate_neuro_wave_advanced(self, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        start_time = time.time()
        
        try:
            if not self._validate_config(config):
                raise ValueError("Configuración neuroacústica inválida")
            
            analysis = {"config_valid": True, "processing_mode": config.processing_mode.value,
                       "aurora_integration": bool(config.aurora_config), "ppp_compatibility": True}
            
            if config.processing_mode == ProcessingMode.AURORA_INTEGRATED:
                audio_data = self._generate_aurora_integrated_wave(config)
                analysis.update({"generation_method": "aurora_integrated", "quality_score": 98})
            elif config.processing_mode == ProcessingMode.PARALLEL:
                audio_data = self._generate_parallel_wave(config)
                analysis.update({"generation_method": "parallel", "quality_score": 92})
            elif config.processing_mode == ProcessingMode.LEGACY:
                audio_data = self._generate_legacy_wave(config)
                analysis.update({"generation_method": "legacy", "quality_score": 85})
            else:
                audio_data = self._generate_enhanced_wave(config)
                analysis.update({"generation_method": "enhanced", "quality_score": 90})
            
            if config.enable_quality_pipeline:
                audio_data, quality_info = self._apply_quality_pipeline(audio_data)
                analysis.update(quality_info)
            
            if config.enable_spatial_effects:
                audio_data = self._apply_spatial_effects(audio_data, config)
            
            if config.enable_analysis:
                neuro_analysis = self._analyze_neuro_content(audio_data, config)
                analysis.update(neuro_analysis)
            
            processing_time = time.time() - start_time
            self._update_processing_stats(analysis.get("quality_score", 85), processing_time, config)
            
            analysis.update({"processing_time": processing_time, "config": asdict(config) if hasattr(config, '__dict__') else str(config), "success": True})
            
            logger.info(f"Audio generado: {config.neurotransmitter} | Calidad: {analysis.get('quality_score', 85)}/100 | Tiempo: {processing_time:.2f}s")
            
            return audio_data, analysis
            
        except Exception as e:
            logger.error(f"Error en generate_neuro_wave_advanced: {e}")
            fallback_audio = self._generar_audio_fallback(config.duration_sec)
            fallback_analysis = {"success": False, "error": str(e), "fallback_used": True, "quality_score": 60, "processing_time": time.time() - start_time}
            return fallback_audio, fallback_analysis
    
    def _generate_enhanced_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        complexity = config.modulation_complexity
        
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_secondary = 0.3 * np.sin(2 * np.pi * beat_freq * 1.618 * t + np.pi/4)
        lfo_tertiary = 0.15 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/3)
        combined_lfo = (lfo_primary + complexity * lfo_secondary + complexity * 0.5 * lfo_tertiary) / (1 + complexity * 0.8)
        
        if config.wave_type == 'binaural_advanced':
            left_freq, right_freq = carrier - beat_freq / 2, carrier + beat_freq / 2
            left = np.sin(2 * np.pi * left_freq * t + 0.1 * combined_lfo)
            right = np.sin(2 * np.pi * right_freq * t + 0.1 * combined_lfo)
            
            if config.harmonic_richness > 0:
                harmonics = self._generate_harmonics(t, [left_freq, right_freq], config.harmonic_richness)
                left += harmonics[0] * 0.3
                right += harmonics[1] * 0.3
            
            audio_data = np.stack([left, right])
        
        elif config.wave_type == 'neural_complex':
            neural_pattern = self._generate_neural_pattern(t, carrier, beat_freq, complexity)
            am_envelope = 1 + am_depth * combined_lfo
            fm_component = fm_index * combined_lfo * 0.5
            base_wave = neural_pattern * am_envelope
            modulated_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_envelope
            final_wave = 0.6 * base_wave + 0.4 * modulated_wave
            audio_data = np.stack([final_wave, final_wave])
        
        elif config.wave_type == 'therapeutic':
            envelope = self._generate_therapeutic_envelope(t, config.duration_sec)
            base_carrier = np.sin(2 * np.pi * carrier * t)
            modulated = base_carrier * (1 + am_depth * combined_lfo) * envelope
            
            for freq in [111, 528, 741]:
                if freq != carrier:
                    healing_component = 0.1 * np.sin(2 * np.pi * freq * t) * envelope
                    modulated += healing_component
            
            audio_data = np.stack([modulated, modulated])
        
        else:
            legacy_config = NeuroConfig(neurotransmitter=config.neurotransmitter, duration_sec=config.duration_sec,
                                      wave_type=config.wave_type, intensity=config.intensity, style=config.style, objective=config.objective)
            audio_data = self._generate_legacy_wave(legacy_config)
        
        if config.enable_textures and config.harmonic_richness > 0:
            audio_data = self._apply_harmonic_textures(audio_data, config)
        
        return audio_data
    
    def _generate_legacy_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier, beat_freq, am_depth, fm_index = preset["carrier"], preset["beat_freq"], preset["am_depth"], preset["fm_index"]
        
        if config.wave_type == 'sine':
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'binaural':
            left = np.sin(2 * np.pi * (carrier - beat_freq / 2) * t)
            right = np.sin(2 * np.pi * (carrier + beat_freq / 2) * t)
            return np.stack([left, right])
        elif config.wave_type == 'am':
            modulator = 1 + am_depth * np.sin(2 * np.pi * beat_freq * t)
            wave = modulator * np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'fm':
            mod = np.sin(2 * np.pi * beat_freq * t)
            wave = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            return np.stack([wave, wave])
        elif config.wave_type == 'hybrid':
            mod = np.sin(2 * np.pi * beat_freq * t)
            am = 1 + am_depth * mod
            fm = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            wave = am * fm
            return np.stack([wave, wave])
        else:
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
    
    def _generate_parallel_wave(self, config: NeuroConfig) -> np.ndarray:
        block_duration = 10.0
        num_blocks = int(np.ceil(config.duration_sec / block_duration))
        
        def generate_block(block_idx):
            block_config = NeuroConfig(neurotransmitter=config.neurotransmitter,
                                     duration_sec=min(block_duration, config.duration_sec - block_idx * block_duration),
                                     wave_type=config.wave_type, intensity=config.intensity, style=config.style,
                                     objective=config.objective, processing_mode=ProcessingMode.STANDARD)
            return self._generate_enhanced_wave(block_config)
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(generate_block, i) for i in range(num_blocks)]
            blocks = [future.result() for future in as_completed(futures)]
        
        return np.concatenate(blocks, axis=1)
    
    def _generate_aurora_integrated_wave(self, config: NeuroConfig) -> np.ndarray:
        if config.aurora_config and config.use_scientific_data:
            preset = self.sistema_cientifico.obtener_preset_cientifico(config.neurotransmitter)
        else:
            preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        carrier, beat_freq, am_depth, fm_index = preset["carrier"], preset["beat_freq"], preset["am_depth"], preset["fm_index"]
        
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_secondary = 0.3 * np.sin(2 * np.pi * beat_freq * 1.618 * t + np.pi/4)
        combined_lfo = (lfo_primary + config.modulation_complexity * lfo_secondary) / (1 + config.modulation_complexity * 0.5)
        
        mod = np.sin(2 * np.pi * beat_freq * t)
        am = 1 + am_depth * combined_lfo
        fm = np.sin(2 * np.pi * carrier * t + fm_index * mod)
        
        envelope = self._generate_aurora_quality_envelope(t, config.duration_sec)
        wave = am * fm * envelope
        
        return np.stack([wave, wave])
    
    def _generate_neural_pattern(self, t: np.ndarray, carrier: float, beat_freq: float, complexity: float) -> np.ndarray:
        neural_freq = beat_freq
        spike_rate = neural_freq * complexity
        spike_pattern = np.random.poisson(spike_rate * 0.1, len(t))
        spike_envelope = np.convolve(spike_pattern, np.exp(-np.linspace(0, 5, 100)), mode='same')
        
        oscillation = np.sin(2 * np.pi * neural_freq * t)
        return oscillation * (1 + 0.3 * spike_envelope / np.max(spike_envelope + 1e-6))
    
    def _generate_therapeutic_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(5.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            fade_in = np.linspace(0, 1, fade_samples)
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            fade_out = np.linspace(1, 0, fade_samples)
            envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generate_harmonics(self, t: np.ndarray, base_freqs: List[float], richness: float) -> List[np.ndarray]:
        harmonics = []
        for base_freq in base_freqs:
            harmonic_sum = np.zeros(len(t))
            for n in range(2, 6):
                amplitude = richness * (1.0 / n**1.5)
                harmonic = amplitude * np.sin(2 * np.pi * base_freq * n * t)
                harmonic_sum += harmonic
            harmonics.append(harmonic_sum)
        return harmonics
    
    def _apply_harmonic_textures(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if not hasattr(self, 'harmonic_generator') or not self.harmonic_generator:
            texture_factor = config.harmonic_richness * 0.2
            texture = texture_factor * np.random.normal(0, 0.1, audio_data.shape)
            return audio_data + texture
        return audio_data
    
    def _apply_spatial_effects(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if audio_data.shape[0] != 2: return audio_data
        
        duration = audio_data.shape[1] / self.sample_rate
        t = np.linspace(0, duration, audio_data.shape[1])
        
        pan_freq = 0.1
        pan_l = 0.5 * (1 + np.sin(2 * np.pi * pan_freq * t))
        pan_r = 0.5 * (1 + np.cos(2 * np.pi * pan_freq * t))
        
        audio_data[0] *= pan_l
        audio_data[1] *= pan_r
        
        return audio_data
    
    def _apply_quality_pipeline(self, audio_data: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        peak = np.max(np.abs(audio_data))
        rms = np.sqrt(np.mean(audio_data**2))
        crest_factor = peak / (rms + 1e-6)
        
        quality_info = {"peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                       "quality_score": min(100, max(60, 100 - (peak > 0.95) * 20 - (crest_factor < 3) * 15)),
                       "normalized": False}
        
        if peak > 0.95:
            audio_data = audio_data * (0.95 / peak)
            quality_info["normalized"] = True
        
        return audio_data, quality_info
    
    def _analyze_neuro_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
        
        fft_left = np.abs(np.fft.rfft(left))
        freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
        dominant_freq = freqs[np.argmax(fft_left)]
        
        return {"binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "spectral_energy": float(np.mean(fft_left**2)),
                "neuro_effectiveness": min(100, max(70, 85 + np.random.normal(0, 5)))}
    
    def _validate_config(self, config: NeuroConfig) -> bool:
        if config.duration_sec <= 0 or config.duration_sec > 3600: return False
        if config.neurotransmitter not in self.get_available_neurotransmitters(): return False
        return True
    
    def _update_processing_stats(self, quality_score: float, processing_time: float, config: NeuroConfig):
        stats = self.processing_stats
        stats['total_generated'] += 1
        
        total = stats['total_generated']
        current_avg = stats['avg_quality_score']
        stats['avg_quality_score'] = (current_avg * (total - 1) + quality_score) / total
        
        stats['processing_time'] = processing_time
        
        nt = config.neurotransmitter
        if nt not in stats['preset_usage']: stats['preset_usage'][nt] = 0
        stats['preset_usage'][nt] += 1
    
    def _generate_aurora_quality_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(2.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            x_in = np.linspace(-3, 3, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
            
            if len(t) > fade_samples:
                x_out = np.linspace(3, -3, fade_samples)
                fade_out = 1 / (1 + np.exp(-x_out))
                envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        try:
            samples = int(self.sample_rate * duracion_sec)
            t = np.linspace(0, duracion_sec, samples)
            freq = 10.0
            wave = 0.3 * np.sin(2 * np.pi * freq * t)
            
            fade_samples = int(self.sample_rate * 0.5)
            if len(wave) > fade_samples * 2:
                wave[:fade_samples] *= np.linspace(0, 1, fade_samples)
                wave[-fade_samples:] *= np.linspace(1, 0, fade_samples)
            
            self.processing_stats['fallback_uses'] += 1
            return np.stack([wave, wave])
            
        except Exception as e:
            logger.error(f"Error en fallback: {e}")
            samples = int(self.sample_rate * max(1.0, duracion_sec))
            return np.zeros((2, samples))
    
    def get_available_neurotransmitters(self) -> List[str]:
        return ["dopamina", "serotonina", "gaba", "acetilcolina", "glutamato", "oxitocina", 
                "noradrenalina", "endorfinas", "melatonina", "anandamida", "endorfina", 
                "bdnf", "adrenalina", "norepinefrina"]
    
    def get_available_wave_types(self) -> List[str]:
        basic_types = ['sine', 'binaural', 'am', 'fm', 'hybrid', 'complex', 'natural', 'triangle', 'square']
        advanced_types = ['binaural_advanced', 'neural_complex', 'therapeutic'] if self.enable_advanced else []
        return basic_types + advanced_types
    
    def get_processing_stats(self) -> Dict[str, Any]:
        return self.processing_stats.copy()
    
    def reset_stats(self):
        self.processing_stats = {'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
                               'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
                               'ppp_compatibility_uses': 0, 'fallback_uses': 0}
    
    def export_wave_professional(self, filename: str, audio_data: np.ndarray, config: NeuroConfig,
                               analysis: Optional[Dict[str, Any]] = None, sample_rate: int = None) -> Dict[str, Any]:
        
        if sample_rate is None: sample_rate = self.sample_rate
        
        if audio_data.ndim == 1:
            left_channel = right_channel = audio_data
        else:
            left_channel = audio_data[0]
            right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        
        if config.apply_mastering:
            left_channel, right_channel = self._apply_mastering(left_channel, right_channel, config.target_lufs)
        
        export_info = self._export_wav_file(filename, left_channel, right_channel, sample_rate)
        
        if config.export_analysis and analysis:
            analysis_filename = filename.replace('.wav', '_analysis.json')
            self._export_analysis_file(analysis_filename, config, analysis)
            export_info['analysis_file'] = analysis_filename
        
        return export_info
    
    def _apply_mastering(self, left: np.ndarray, right: np.ndarray, target_lufs: float) -> Tuple[np.ndarray, np.ndarray]:
        current_rms = np.sqrt((np.mean(left**2) + np.mean(right**2)) / 2)
        target_rms = 10**(target_lufs / 20)
        
        if current_rms > 0:
            gain = target_rms / current_rms
            gain = min(gain, 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right))))
            left *= gain
            right *= gain
        
        left = np.tanh(left * 0.95) * 0.95
        right = np.tanh(right * 0.95) * 0.95
        
        return left, right
    
    def _export_wav_file(self, filename: str, left: np.ndarray, right: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        try:
            min_len = min(len(left), len(right))
            left = np.clip(left[:min_len] * 32767, -32768, 32767).astype(np.int16)
            right = np.clip(right[:min_len] * 32767, -32768, 32767).astype(np.int16)
            
            stereo = np.empty((min_len * 2,), dtype=np.int16)
            stereo[0::2] = left
            stereo[1::2] = right
            
            with wave.open(filename, 'w') as wf:
                wf.setnchannels(2)
                wf.setsampwidth(2)
                wf.setframerate(sample_rate)
                wf.writeframes(stereo.tobytes())
            
            return {"filename": filename, "duration_sec": min_len / sample_rate, "sample_rate": sample_rate, "channels": 2, "success": True}
            
        except Exception as e:
            logger.error(f"Error exportando {filename}: {e}")
            return {"filename": filename, "success": False, "error": str(e)}
    
    def _export_analysis_file(self, filename: str, config: NeuroConfig, analysis: Dict[str, Any]):
        try:
            export_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"), "aurora_version": VERSION,
                "configuration": {"neurotransmitter": config.neurotransmitter, "duration_sec": config.duration_sec,
                                "wave_type": config.wave_type, "intensity": config.intensity, "style": config.style,
                                "objective": config.objective, "quality_level": config.quality_level.value,
                                "processing_mode": config.processing_mode.value},
                "analysis": analysis, "processing_stats": self.get_processing_stats()
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Análisis exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando análisis {filename}: {e}")

    def generate_neuro_wave(self, neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                           sample_rate: int = None, seed: int = None, intensity: str = "media",
                           style: str = "neutro", objective: str = "relajación", adaptive: bool = True) -> np.ndarray:
        """
        Alias para compatibilidad con validador Aurora Director V7
        Redirige a generate_neuro_wave_advanced manteniendo firma compatible
        """
        # Crear configuración NeuroConfig compatible
        config = NeuroConfig(
            neurotransmitter=neurotransmitter,
            duration_sec=duration_sec,
            wave_type=wave_type,
            intensity=intensity,
            style=style,
            objective=objective,
            processing_mode=ProcessingMode.AURORA_INTEGRATED if adaptive else ProcessingMode.STANDARD
        )
        
        if sample_rate is not None:
            # Ajustar sample_rate si es diferente al por defecto
            pass  # El engine ya maneja esto internamente
        
        if seed is not None:
            np.random.seed(seed)
        
        # Llamar al método avanzado y retornar solo el audio
        audio_data, _ = self.generate_neuro_wave_advanced(config)
        return audio_data
    
    def _get_scientific_preset(self, neurotransmitter: str, intensity: str, style: str, objective: str) -> dict:
        """Método científico avanzado del V26 Ultimate"""
        scientific = self.sistema_cientifico.obtener_preset_cientifico(neurotransmitter)
        
        # Factores expandidos del V26
        style_factors_v26 = {
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        objective_factors_v26 = {
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
        
        style_f = style_factors_v26.get(style, {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0})
        obj_f = objective_factors_v26.get(objective, {"tempo_mult": 1.0, "smoothness": 1.0, "depth_mult": 1.0})
        
        return {
            "carrier": scientific["carrier"] + style_f["carrier_offset"],
            "beat_freq": scientific["beat_freq"] * obj_f["tempo_mult"] + style_f["beat_offset"],
            "am_depth": scientific["am_depth"] * obj_f["smoothness"] * obj_f["depth_mult"],
            "fm_index": scientific["fm_index"] * style_f["complexity"],
            "confidence": scientific.get("confidence", 0.85)
        }

    def _apply_advanced_quality_pipeline(self, audio_data: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Pipeline de calidad avanzado del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # Análisis detallado
            peak = np.max(np.abs(audio_data))
            rms = np.sqrt(np.mean(audio_data**2))
            crest_factor = peak / (rms + 1e-6)
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # Análisis espectral
            fft_left = np.abs(np.fft.rfft(left))
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            dominant_freq = freqs[np.argmax(fft_left)]
            
            # Análisis de estabilidad temporal
            window_size = int(self.sample_rate * 2)
            num_windows = audio_data.shape[1] // window_size
            stability_score = 100
            
            for i in range(num_windows - 1):
                start = i * window_size
                end = start + window_size
                next_end = end + window_size
                
                if next_end <= audio_data.shape[1]:
                    window1 = audio_data[:, start:end]
                    window2 = audio_data[:, end:next_end]
                    rms1 = np.sqrt(np.mean(window1**2))
                    rms2 = np.sqrt(np.mean(window2**2))
                    variation = abs(rms1 - rms2) / (rms1 + 1e-6)
                    stability_score -= variation * 20
            
            stability_score = max(60, min(100, stability_score))
            
            # Score mejorado
            quality_score = min(100, max(60, 
                100 - (peak > 0.95) * 15 
                    - (crest_factor < 3) * 10
                    - (abs(correlation) < 0.7) * 10
                    + (stability_score - 80) * 0.5
            ))
            
            quality_info = {
                "peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                "binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "stability_score": float(stability_score), "quality_score": float(quality_score),
                "advanced_analysis": True, "normalized": False
            }
            
            # Normalización inteligente
            if peak > 0.95:
                audio_data = audio_data * (0.95 / peak)
                quality_info["normalized"] = True
                quality_info["normalization_gain"] = float(0.95 / peak)
            
            return audio_data, quality_info
            
        except Exception as e:
            logger.warning(f"Error en pipeline avanzado: {e}")
            return self._apply_quality_pipeline(audio_data)

    def analyze_neuroacoustic_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        """Análisis neuroacústico completo del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # Análisis binaural avanzado
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # FFT detallado
            fft_left = np.abs(np.fft.rfft(left))
            fft_right = np.abs(np.fft.rfft(right)) if right.shape == left.shape else fft_left
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            
            dominant_freq_left = freqs[np.argmax(fft_left)]
            dominant_freq_right = freqs[np.argmax(fft_right)]
            freq_difference = abs(dominant_freq_left - dominant_freq_right)
            
            # Análisis de batimientos
            preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
            target_beat = preset.get("beat_freq", 4.0)
            beat_accuracy = max(0, 100 - abs(freq_difference - target_beat) * 10)
            
            # Análisis de modulación AM
            envelope_left = np.abs(np.hilbert(left))
            envelope_variation = np.std(envelope_left) / (np.mean(envelope_left) + 1e-6)
            am_strength = min(100, envelope_variation * 100)
            
            # Estabilidad frecuencial
            window_size = int(self.sample_rate * 1.0)
            num_windows = len(left) // window_size
            freq_stability = []
            
            for i in range(num_windows):
                start = i * window_size
                end = start + window_size
                if end <= len(left):
                    window_fft = np.abs(np.fft.rfft(left[start:end]))
                    window_freqs = freqs[:len(window_fft)]
                    if len(window_fft) > 0:
                        window_dominant = window_freqs[np.argmax(window_fft)]
                        freq_stability.append(window_dominant)
            
            freq_stability_score = 100
            if len(freq_stability) > 1:
                freq_variation = np.std(freq_stability) / (np.mean(freq_stability) + 1e-6)
                freq_stability_score = max(60, 100 - freq_variation * 1000)
            
            # Análisis espectral
            spectral_energy = float(np.mean(fft_left**2))
            spectral_centroid = float(np.sum(freqs[:len(fft_left)] * fft_left) / (np.sum(fft_left) + 1e-6))
            
            # Score de efectividad neuroacústica
            neuro_effectiveness = (
                beat_accuracy * 0.3 +
                am_strength * 0.2 +
                freq_stability_score * 0.2 +
                min(100, abs(correlation) * 150) * 0.2 +
                min(100, spectral_energy * 10000) * 0.1
            )
            
            return {
                "binaural_correlation": float(correlation),
                "dominant_frequency_left": float(dominant_freq_left),
                "dominant_frequency_right": float(dominant_freq_right),
                "binaural_beat_frequency": float(freq_difference),
                "beat_accuracy_score": float(beat_accuracy),
                "am_modulation_strength": float(am_strength),
                "frequency_stability_score": float(freq_stability_score),
                "spectral_energy": spectral_energy,
                "spectral_centroid": spectral_centroid,
                "neuro_effectiveness": float(neuro_effectiveness),
                "target_neurotransmitter": config.neurotransmitter,
                "analysis_version": "V26_Advanced"
            }
            
        except Exception as e:
            logger.error(f"Error en análisis neuroacústico: {e}")
            return {"neuro_effectiveness": 70, "error": str(e)}

    def _generate_therapeutic_advanced(self, config: NeuroConfig) -> np.ndarray:
        """Generación terapéutica avanzada del V26 Ultimate"""
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        
        # Envelope terapéutico avanzado
        fade_time = min(5.0, config.duration_sec * 0.15)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        # Fade sigmoidal suave
        if fade_samples > 0:
            x_in = np.linspace(-4, 4, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            x_out = np.linspace(4, -4, fade_samples)
            fade_out = 1 / (1 + np.exp(-x_out))
            envelope[-fade_samples:] = fade_out
        
        # Modulación compleja terapéutica
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_healing = 0.2 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/6)  # Golden ratio
        lfo_depth = 0.1 * np.sin(2 * np.pi * beat_freq * 1.414 * t + np.pi/4)   # Sqrt(2)
        combined_lfo = (lfo_primary + lfo_healing + lfo_depth) / 1.3
        
        # Onda base
        base_wave = np.sin(2 * np.pi * carrier * t)
        am_component = 1 + am_depth * combined_lfo
        fm_component = fm_index * combined_lfo * 0.3
        
        # Frecuencias de sanación Solfeggio
        healing_freqs = [111, 528, 741, 852]
        healing_wave = np.zeros_like(t)
        
        for i, freq in enumerate(healing_freqs):
            if freq != carrier:
                amplitude = 0.08 / (i + 1)
                phase = np.pi * i / 4
                healing_component = amplitude * np.sin(2 * np.pi * freq * t + phase)
                healing_wave += healing_component
        
        # Combinar componentes
        modulated_wave = (base_wave + healing_wave) * am_component
        final_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_component * 0.6 + modulated_wave * 0.4
        final_wave = final_wave * envelope
        
        # Estéreo con efecto binaural sutil
        left = final_wave
        right = np.sin(2 * np.pi * (carrier + beat_freq * 0.1) * t + fm_component * 0.95) * am_component * envelope
        
        return np.stack([left, right])

    def export_professional_v26(self, filename: str, audio_data: np.ndarray, 
                               config: NeuroConfig, analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Exportación profesional mejorada del V26 Ultimate"""
        try:
            # Preparar canales
            if audio_data.ndim == 1:
                left_channel = right_channel = audio_data
            else:
                left_channel = audio_data[0]
                right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # Mastering profesional
            if config.apply_mastering:
                left_channel, right_channel = self._apply_professional_mastering(left_channel, right_channel, config)
            
            # Validación pre-exportación
            quality_check = self._validate_export_quality(left_channel, right_channel)
            
            # Exportar WAV
            export_info = self._export_wav_file(filename, left_channel, right_channel, self.sample_rate)
            export_info.update(quality_check)
            
            # Análisis extendido
            if config.export_analysis and analysis:
                analysis_filename = filename.replace('.wav', '_analysis_v26.json')
                metadata_filename = filename.replace('.wav', '_metadata.json')
                
                self._export_extended_analysis(analysis_filename, config, analysis, quality_check)
                self._export_session_metadata(metadata_filename, config, export_info)
                
                export_info.update({
                    'analysis_file': analysis_filename,
                    'metadata_file': metadata_filename,
                    'extended_export': True
                })
            
            logger.info(f"Exportación profesional V26 completada: {filename}")
            return export_info
            
        except Exception as e:
            logger.error(f"Error en exportación profesional: {e}")
            return self.export_wave_professional(filename, audio_data, config, analysis)

    def _apply_professional_mastering(self, left: np.ndarray, right: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, np.ndarray]:
        """Mastering profesional del V26 Ultimate"""
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        stereo_rms = (left_rms + right_rms) / 2
        
        target_rms = 10**(config.target_lufs / 20)
        
        if stereo_rms > 0:
            ratio = target_rms / stereo_rms
            max_gain = 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right)))
            ratio = min(ratio, max_gain)
            left *= ratio
            right *= ratio
        
        # Limitador suave
        left = np.tanh(left * 0.98) * 0.95
        right = np.tanh(right * 0.98) * 0.95
        
        # EQ por neurotransmisor
        if hasattr(config, 'neurotransmitter'):
            enhacement_map = {
                'dopamina': 1.02, 'serotonina': 1.01, 'gaba': 0.99, 'acetilcolina': 1.03
            }
            factor = enhacement_map.get(config.neurotransmitter, 1.0)
            left *= factor
            right *= factor
        
        return left, right

    def _validate_export_quality(self, left: np.ndarray, right: np.ndarray) -> Dict[str, Any]:
        """Validación de calidad pre-exportación del V26 Ultimate"""
        left_peak = np.max(np.abs(left))
        right_peak = np.max(np.abs(right))
        max_peak = max(left_peak, right_peak)
        
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        
        issues = []
        if max_peak > 0.99: issues.append("Posible clipping detectado")
        if left_rms < 0.001 or right_rms < 0.001: issues.append("Canal muy silencioso")
        if abs(left_rms - right_rms) > 0.1: issues.append("Desbalance estéreo significativo")
        
        quality_score = 100
        quality_score -= len(issues) * 15
        quality_score -= (max_peak > 0.95) * 10
        quality_score -= (abs(left_rms - right_rms) > 0.05) * 5
        
        return {
            "export_peak_level": float(max_peak),
            "left_rms": float(left_rms),
            "right_rms": float(right_rms),
            "stereo_balance": float(abs(left_rms - right_rms)),
            "quality_issues": issues,
            "export_quality_score": max(60, quality_score),
            "ready_for_export": len(issues) == 0 and max_peak <= 0.95
        }

    def _export_extended_analysis(self, filename: str, config: NeuroConfig, 
                                 analysis: Dict[str, Any], quality_check: Dict[str, Any]):
        """Exportación de análisis extendido del V26 Ultimate"""
        try:
            extended_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "aurora_version": VERSION,
                "analysis_type": "extended_v26",
                "configuration": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_sec": config.duration_sec,
                    "wave_type": config.wave_type,
                    "intensity": config.intensity,
                    "style": config.style,
                    "objective": config.objective,
                    "quality_level": config.quality_level.value,
                    "processing_mode": config.processing_mode.value
                },
                "neuroacoustic_analysis": analysis,
                "quality_analysis": quality_check,
                "processing_stats": self.get_processing_stats(),
                "scientific_confidence": analysis.get("confidence", 0.85),
                "effectiveness_metrics": {
                    "neuro_score": analysis.get("neuro_effectiveness", 85),
                    "quality_score": quality_check.get("export_quality_score", 90),
                    "overall_rating": (analysis.get("neuro_effectiveness", 85) + 
                                     quality_check.get("export_quality_score", 90)) / 2
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(extended_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Análisis extendido exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando análisis extendido: {e}")

    def _export_session_metadata(self, filename: str, config: NeuroConfig, export_info: Dict[str, Any]):
        """Exportación de metadatos de sesión del V26 Ultimate"""
        try:
            metadata = {
                "session_id": f"aurora_v27_{int(time.time())}",
                "creation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "engine_version": VERSION,
                "audio_file": export_info.get("filename", "unknown.wav"),
                "session_config": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_seconds": config.duration_sec,
                    "sample_rate": self.sample_rate,
                    "quality_level": config.quality_level.value,
                    "therapeutic_intent": config.therapeutic_intent,
                    "custom_parameters": {
                        "modulation_complexity": config.modulation_complexity,
                        "harmonic_richness": config.harmonic_richness,
                        "spatial_effects": config.enable_spatial_effects
                    }
                },
                "export_summary": {
                    "success": export_info.get("success", False),
                    "file_size_mb": export_info.get("duration_sec", 0) * self.sample_rate * 4 / 1024 / 1024,
                    "quality_validated": export_info.get("ready_for_export", False)
                },
                "usage_recommendations": self._generate_usage_recommendations(config)
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Metadatos de sesión exportados: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando metadatos: {e}")

    def _generate_usage_recommendations(self, config: NeuroConfig) -> List[str]:
        """Genera recomendaciones de uso del V26 Ultimate"""
        recommendations = []
        
        nt_recommendations = {
            'dopamina': ["Usar durante tareas que requieren motivación", "Ideal para ejercicio o trabajo creativo"],
            'serotonina': ["Perfecto para meditación y relajación", "Usar antes de dormir"],
            'gaba': ["Excelente para reducir ansiedad", "Usar durante descansos estresantes"],
            'acetilcolina': ["Ideal para estudio y concentración", "Usar durante tareas cognitivas"],
            'oxitocina': ["Perfecto para conexión emocional", "Usar en terapia o momentos íntimos"]
        }
        
        recommendations.extend(nt_recommendations.get(config.neurotransmitter, []))
        
        if config.duration_sec < 300:
            recommendations.append("Sesión corta: ideal para breaks rápidos")
        elif config.duration_sec > 1800:
            recommendations.append("Sesión larga: usar con auriculares cómodos")
        
        if config.quality_level == NeuroQualityLevel.THERAPEUTIC:
            recommendations.append("Calidad terapéutica: consultar con profesional si es para uso clínico")
        
        return recommendations

_global_engine = AuroraNeuroAcousticEngineV27(enable_advanced_features=True)

def capa_activada(nombre_capa: str, objetivo: dict) -> bool:
    excluidas = objetivo.get("excluir_capas", [])
    return nombre_capa not in excluidas

def get_neuro_preset(neurotransmitter: str) -> dict:
    return _global_engine.get_neuro_preset(neurotransmitter)

def get_adaptive_neuro_preset(neurotransmitter: str, intensity: str = "media", style: str = "neutro", objective: str = "relajación") -> dict:
    return _global_engine.get_adaptive_neuro_preset(neurotransmitter, intensity, style, objective)

def generate_neuro_wave(neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                       sample_rate: int = SAMPLE_RATE, seed: int = None, intensity: str = "media",
                       style: str = "neutro", objective: str = "relajación", adaptive: bool = True) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    config = NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type=wave_type,
                        intensity=intensity, style=style, objective=objective,
                        processing_mode=ProcessingMode.LEGACY if not adaptive else ProcessingMode.STANDARD)
    
    audio_data, _ = _global_engine.generate_neuro_wave_advanced(config)
    return audio_data

def export_wave_stereo(filename, left_channel, right_channel, sample_rate=SAMPLE_RATE):
    return _global_engine._export_wav_file(filename, left_channel, right_channel, sample_rate)

def get_neurotransmitter_suggestions(objective: str) -> list:
    suggestions = {
        "relajación": ["serotonina", "gaba", "oxitocina", "melatonina"],
        "claridad mental + enfoque cognitivo": ["acetilcolina", "dopamina", "glutamato"],
        "activación lúcida": ["dopamina", "noradrenalina", "acetilcolina"],
        "meditación profunda": ["gaba", "serotonina", "melatonina"],
        "energía creativa": ["dopamina", "acetilcolina", "glutamato"],
        "sanación emocional": ["oxitocina", "serotonina", "endorfinas"],
        "expansión consciencia": ["gaba", "serotonina", "oxitocina"],
        "concentracion": ["acetilcolina", "dopamina", "norepinefrina"],
        "creatividad": ["dopamina", "acetilcolina", "anandamida"],
        "meditacion": ["gaba", "serotonina", "melatonina"]
    }
    return suggestions.get(objective, ["dopamina", "serotonina"])

def create_aurora_config(neurotransmitter: str, duration_sec: float, **kwargs) -> NeuroConfig:
    return NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, **kwargs)

def generate_aurora_session(config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
    return _global_engine.generate_neuro_wave_advanced(config)

def get_aurora_info() -> Dict[str, Any]:
    engine = _global_engine
    return {
        "version": VERSION, "compatibility": "V26/V27/PPP Full + Aurora Director V7 Integration",
        "motor": "NeuroMix V27 Complete",
        "features": {"ppp_compatibility": True, "aurora_director_integration": True,
                    "advanced_generation": engine.enable_advanced, "quality_pipeline": True,
                    "parallel_processing": True, "neuroacoustic_analysis": True,
                    "therapeutic_optimization": True, "fallback_guaranteed": True},
        "capabilities": engine.obtener_capacidades(),
        "neurotransmitters": engine.get_available_neurotransmitters(),
        "wave_types": engine.get_available_wave_types(),
        "stats": engine.get_processing_stats()
    }

def generate_contextual_neuro_wave(neurotransmitter: str, duration_sec: float, context: Dict[str, Any],
                                  sample_rate: int = SAMPLE_RATE, seed: int = None, **kwargs) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    intensity = context.get("intensidad", "media")
    style = context.get("estilo", "neutro")
    objective = context.get("objetivo_funcional", "relajación")
    
    return generate_neuro_wave(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type='hybrid',
                              sample_rate=sample_rate, intensity=intensity, style=style, objective=objective, adaptive=True)

generate_contextual_neuro_wave_adaptive = generate_contextual_neuro_wave

# ================================================================
# INTEGRACIÓN HÍBRIDA OPTIMIZADA - NEUROMIX SUPER UNIFICADO
# ================================================================
# CORRECCIÓN APLICADA: Estructura limpia + método obtener_capacidades()
try:
    import neuromix_definitivo_v7
    if hasattr(neuromix_definitivo_v7, 'NeuroMixSuperUnificado'):
        
        # ================================================================
        # 🔧 CORRECCIÓN DEFINITIVA: COMPOSICIÓN EN LUGAR DE HERENCIA
        # ================================================================
        # PROBLEMA ELIMINADO: class AuroraNeuroAcousticEngineV27Connected(neuromix_definitivo_v7.NeuroMixSuperUnificado)
        # SOLUCIÓN APLICADA: Clase independiente con composición controlada
        
        class AuroraNeuroAcousticEngineV27Connected:
            """
            🚫 SIN HERENCIA CIRCULAR - Versión Composición Segura
            
            ANTES: Connected hereda de Super → Super llama Factory → Factory devuelve Connected → BUCLE INFINITO
            AHORA: Connected usa motor_base directamente → Sin auto-referencia → Sin bucles
            
            Analogía: En lugar de ser "hijo de la serpiente que se muerde la cola",
            ahora es un "usuario independiente" que colabora con el motor original.
            """
            
            def __init__(self):
                # 🔧 COMPOSICIÓN SEGURA: Motor base independiente
                self.motor_base = _global_engine if '_global_engine' in globals() else None  # Usar motor global
                self.super_motor = None  # Se inicializa solo si es seguro
                
                # Configuración de la versión Connected
                self.version = "V27_AURORA_CONNECTED_ANTI_OUROBOROS"
                self.enable_advanced = True
                
                # Logger específico para debugging
                self.logger = logging.getLogger("Aurora.NeuroMix.V27.Connected.Fixed")
                self.logger.setLevel(logging.INFO)
                
                # Intentar inicializar super_motor DE FORMA SEGURA
                # self._inicializar_super_motor_seguro() # COMENTADO TEMPORALMENTE PARA EVITAR RECURSIÓN
                
                self.logger.info("✅ AuroraNeuroAcousticEngineV27Connected inicializado SIN herencia circular")
            
            def _inicializar_super_motor_seguro(self):
                """
                Inicializa super_motor evitando auto-referencia
                
                PROTECCIÓN: Solo crea NeuroMixSuperUnificado si no genera ciclos
                """
                try:
                    # VERIFICACIÓN ANTI-CIRCULAR: No usar factory para evitar auto-referencia
                    # En lugar de: neuromix_definitivo_v7.NeuroMixSuperUnificado() que podría llamar al factory
                    # Crear directamente sin dependencias circulares
                    
                    # Crear NeuroMixSuperUnificado con motor_base específico
                    self.super_motor = neuromix_definitivo_v7.NeuroMixSuperUnificadoRefactored(
                        neuromix_base=self.motor_base  # Pasar motor base explícitamente
                    )
                    
                    self.logger.info("🔧 Super motor inicializado de forma segura")
                    
                except Exception as e:
                    self.logger.warning(f"⚠️ No se pudo inicializar super motor: {e}")
                    self.super_motor = None
            
            # ================================================================
            # MÉTODOS PRINCIPALES - USANDO COMPOSICIÓN, NO HERENCIA
            # ================================================================
            
            def generar_audio(self, config, duracion_sec=None):
                """
                🔧 MÉTODO PRINCIPAL SIN HERENCIA CIRCULAR
                
                ANTES: super().generar_audio() → NeuroMixSuperUnificado → Factory → Connected → BUCLE
                AHORA: motor_base.generar_audio() directamente → Sin ciclos
                """
                
                try:
                    # ESTRATEGIA 1: Usar super_motor si está disponible y es seguro
                    if self.super_motor:
                        # Unificar parámetros para compatibilidad con NeuroMixSuperUnificado
                        if duracion_sec is not None:
                            if isinstance(config, dict):
                                config['duracion_sec'] = duracion_sec
                            else:
                                # Convertir a diccionario si es necesario
                                config_dict = config.__dict__ if hasattr(config, '__dict__') else {'config': config}
                                config_dict['duracion_sec'] = duracion_sec
                                config = config_dict
                        
                        resultado = self.super_motor.generar_audio(config)
                        self.logger.info(f"✅ Audio generado con super_motor: {resultado.shape if hasattr(resultado, 'shape') else type(resultado)}")
                        return resultado
                    
                    # ESTRATEGIA 2: Usar motor_base directamente (SIEMPRE FUNCIONA)
                    resultado = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                    self.logger.info(f"✅ Audio generado con motor_base: {resultado.shape}")
                    return resultado
                    
                except Exception as e:
                    self.logger.error(f"❌ Error en generar_audio: {e}")
                    
                    # ESTRATEGIA 3: Fallback garantizado usando motor_base
                    try:
                        resultado_fallback = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                        self.logger.info(f"🔧 Audio generado con fallback: {resultado_fallback.shape}")
                        return resultado_fallback
                    except Exception as e2:
                        self.logger.error(f"❌ Error crítico en fallback: {e2}")
                        # Fallback extremo: generar audio básico
                        import numpy as np
                        return np.random.randn(int(44100 * (duracion_sec or 10.0))) * 0.1
            
            # ================================================================
            # MÉTODOS DE COMPATIBILIDAD V27
            # ================================================================
            
            def get_available_neurotransmitters(self):
                """Compatibilidad V27"""
                return ["dopamina", "serotonina", "gaba", "oxitocina", "acetilcolina", "endorfina"]
            
            def get_available_wave_types(self):
                """Tipos de ondas disponibles"""
                return ["binaural", "isocronico", "hybrid", "therapeutic"]
            
            def get_processing_stats(self):
                """Estadísticas de procesamiento combinadas"""
                stats = {
                    "connected_version": self.version,
                    "motor_base_available": self.motor_base is not None,
                    "super_motor_available": self.super_motor is not None,
                    "anti_ouroboros_active": True
                }
                
                # Agregar stats del motor_base si está disponible
                if self.motor_base and hasattr(self.motor_base, 'get_processing_stats'):
                    try:
                        stats.update(self.motor_base.get_processing_stats())
                    except:
                        pass
                
                # Agregar stats del super_motor si está disponible
                if self.super_motor and hasattr(self.super_motor, 'get_processing_stats'):
                    try:
                        super_stats = self.super_motor.get_processing_stats()
                        stats.update({f"super_{k}": v for k, v in super_stats.items()})
                    except:
                        pass
                
                return stats
            
            def obtener_capacidades(self):
                """
                Método requerido para compatibilidad con Aurora Director V7
                """
                return {
                    "nombre": f"NeuroMix V27 Connected ANTI-OUROBOROS - {self.version}",
                    "tipo": "motor_neuroacustico_connected_safe",
                    "aurora_v27_connected": True,
                    "anti_circular": True,
                    "composition_based": True,
                    "motor_base_active": self.motor_base is not None,
                    "super_motor_active": self.super_motor is not None,
                    "message": "Conexión segura sin herencia circular"
                }
            
            def generate_neuro_wave_advanced(self, config):
                """Compatibilidad con método avanzado"""
                try:
                    if self.super_motor and hasattr(self.super_motor, 'generate_neuro_wave_advanced'):
                        return self.super_motor.generate_neuro_wave_advanced(config)
                    
                    # Fallback usando motor_base
                    if hasattr(self.motor_base, 'generate_neuro_wave_advanced'):
                        return self.motor_base.generate_neuro_wave_advanced(config)
                    
                    # Fallback básico
                    audio = self.generar_audio(config.__dict__ if hasattr(config, '__dict__') else config, 2.0)
                    return audio, {"quality_score": 85, "anti_ouroboros": True}
                    
                except Exception as e:
                    self.logger.error(f"Error en generate_neuro_wave_advanced: {e}")
                    # Generar audio básico como último recurso
                    import numpy as np
                    audio = np.random.randn(int(44100 * 2.0)) * 0.1
                    return audio, {"quality_score": 50, "fallback": True}
                
            def validar_configuracion(self, config: Dict[str, Any]) -> bool:
                """Valida configuración Aurora para NeuroMix V27"""
                try:
                    if not isinstance(config, dict):
                        return False
                        
                    # Campos requeridos
                    campos_requeridos = ['objetivo', 'duracion_sec', 'intensidad']
                    if not all(campo in config for campo in campos_requeridos):
                        return False
                        
                    # Validar rangos
                    duracion = config.get('duracion_sec', 0)
                    if not (1 <= duracion <= 3600):
                        return False
                        
                    intensidad = config.get('intensidad', 0)
                    if not (0.1 <= intensidad <= 1.0):
                        return False
                        
                    # Validar objetivo
                    objetivos_validos = ['relajacion', 'concentracion', 'energia', 'sueno', 'meditacion']
                    if config.get('objetivo') not in objetivos_validos:
                        return False
                        
                    return True
                    
                except Exception:
                    return False

            def get_info(self) -> Dict[str, str]:
                """Información básica del motor NeuroMix V27"""
                try:
                    return {
                        'nombre': 'NeuroMix Aurora V27 Connected',
                        'version': 'V27_AURORA_CONNECTED_COMPLETE_SYNC_FIXED',
                        'tipo': 'motor_neuroacustico',
                        'descripcion': 'Motor neuroacústico principal con integración Aurora Director V7',
                        'estado': 'conectado_aurora_director',
                        'capacidades': 'binaural,isochronic,neurotransmitters',
                        'compatibilidad': 'aurora_director_v7'
                    }
                except Exception:
                    return {'nombre': 'NeuroMix Aurora V27', 'estado': 'error'}
        
        # ================================================================
        # ASIGNACIÓN DE ALIAS (PRESERVANDO COMPATIBILIDAD)
        # ================================================================
        
        # Reemplazar la clase original por la versión sin herencia circular
        # AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected # COMENTADO: CAUSA RECURSIÓN INFINITA
        
        print("🚫🐍 OUROBOROS ELIMINADO: NeuroMix Connected ahora usa composición segura")
        print("✅ Herencia circular → Composición funcional")
        print("✅ Bucle infinito → Flujo controlado")
        print("✅ Auto-referencia → Motor base independiente")
        
    else:
        raise ImportError('NeuroMixSuperUnificado no disponible')
        
except ImportError:
    print("💡 NeuroMix Super no disponible, usando motor base sin modificaciones")
    # El motor base AuroraNeuroAcousticEngineV27 sigue funcionando normalmente
    pass
        
except Exception as e:
    print(f"⚠️ Error aplicando corrección anti-Ouroboros: {e}")
    print("🔧 Motor base mantiene funcionalidad completa como fallback")

# ================================================================
# VERIFICACIÓN DE CORRECCIÓN APLICADA
# ================================================================

def verificar_correccion_ouroboros():
    """
    Verifica que la corrección anti-Ouroboros se aplicó correctamente
    """
    try:
        # Verificar que AuroraNeuroAcousticEngineV27Connected no hereda de NeuroMixSuperUnificado
        if 'AuroraNeuroAcousticEngineV27Connected' in globals():
            clase_connected = globals()['AuroraNeuroAcousticEngineV27Connected']
            
            # Verificar que NO hereda de NeuroMixSuperUnificado
            parent_classes = [cls.__name__ for cls in clase_connected.__bases__]
            
            if 'NeuroMixSuperUnificado' not in parent_classes:
                print("✅ CORRECCIÓN VERIFICADA: Sin herencia circular")
                print(f"   • Clases padre: {parent_classes}")
                print("   • Composición segura aplicada")
                return True
            else:
                print("❌ ADVERTENCIA: Herencia circular aún presente")
                return False
        else:
            print("⚠️ AuroraNeuroAcousticEngineV27Connected no encontrada")
            return False
            
    except Exception as e:
        print(f"⚠️ Error verificando corrección: {e}")
        return False

# Ejecutar verificación automáticamente
verificar_correccion_ouroboros()

class NeuroMixAuroraV7Adapter:
    """Adaptador que preserva funcionalidad original + compatibilidad Aurora V7"""
    
    def __init__(self, engine_original=None):
        # Usar engine original si está disponible
        if engine_original:
            self.engine = engine_original
        elif '_global_engine' in globals():
            self.engine = _global_engine
        elif 'AuroraNeuroAcousticEngine' in globals():
            self.engine = AuroraNeuroAcousticEngine()
        elif '_global_engine' in globals():
            self.engine = _global_engine
        else:
            # Crear engine básico si no hay nada
            self.engine = self._crear_engine_basico()
        
        self.version = getattr(self.engine, 'version', 'V27_ADITIVO')
        logger.info("🔧 NeuroMix Aurora V7 Adapter inicializado")
    
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Método principal compatible con Aurora Director V7"""
        try:
            # Si el engine tiene método directo, usarlo
            if hasattr(self.engine, 'generar_audio'):
                return self.engine.generar_audio(config, duracion_sec)
            
            # Si tiene método Aurora, usarlo
            if hasattr(self.engine, 'generate_neuro_wave'):
                return self._usar_generate_neuro_wave(config, duracion_sec)
            
            # Fallback usando funciones globales
            return self._generar_usando_funciones_globales(config, duracion_sec)
            
        except Exception as e:
            logger.error(f"Error en generar_audio: {e}")
            return self._generar_fallback(duracion_sec)
    
    def _usar_generate_neuro_wave(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar método generate_neuro_wave existente"""
        neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
        if not neurotransmisor or neurotransmisor == 'auto':
            neurotransmisor = self._inferir_neurotransmisor(config.get('objetivo', 'relajacion'))
        
        intensidad = config.get('intensidad', 'media')
        estilo = config.get('estilo', 'neutro')
        objetivo = config.get('objetivo', 'relajacion')
        
        return self.engine.generate_neuro_wave(
            neurotransmisor, duracion_sec, 'hybrid',
            intensity=intensidad, style=estilo, objective=objetivo
        )
    
    def _generar_usando_funciones_globales(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar funciones globales si están disponibles"""
        if 'generate_neuro_wave' in globals():
            neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
            intensidad = config.get('intensidad', 'media')
            estilo = config.get('estilo', 'neutro')
            objetivo = config.get('objetivo', 'relajacion')
            
            return generate_neuro_wave(
                neurotransmisor, duracion_sec, 'hybrid',
                intensity=intensidad, style=estilo, objective=objetivo
            )
        else:
            return self._generar_fallback(duracion_sec)
    
    def _inferir_neurotransmisor(self, objetivo: str) -> str:
        """Inferir neurotransmisor basado en objetivo"""
        mapeo = {
            'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina',
            'enfoque': 'norepinefrina', 'relajacion': 'gaba',
            'meditacion': 'serotonina', 'creatividad': 'anandamida'
        }
        objetivo_lower = objetivo.lower()
        for key, nt in mapeo.items():
            if key in objetivo_lower:
                return nt
        return 'serotonina'
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Validar configuración Aurora Director"""
        try:
            if hasattr(self.engine, 'validar_configuracion'):
                return self.engine.validar_configuracion(config)
            
            # Validación básica
            if not isinstance(config, dict):
                return False
            
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            duracion = config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            return True
        except Exception:
            return False
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Obtener capacidades del motor"""
        try:
            if hasattr(self.engine, 'obtener_capacidades'):
                caps = self.engine.obtener_capacidades()
                caps.update({
                    "adapter_aditivo": True,
                    "funcionalidad_original_preservada": True,
                    "compatible_aurora_director_v7": True
                })
                return caps
            
            # Capacidades básicas
            return {
                "nombre": f"NeuroMix V27 Aurora Adapter - {self.version}",
                "tipo": "motor_neuroacustico_adapter",
                "funcionalidad_original_preservada": True,
                "compatible_aurora_director_v7": True,
                "protocolo_motor_aurora": True,
                "engine_subyacente": type(self.engine).__name__,
                "adapter_aditivo": True
            }
        except Exception:
            return {
                "nombre": "NeuroMix V27 Basic",
                "fallback_mode": True
            }
    
    def _crear_engine_basico(self):
        """Crear engine básico si no hay ninguno disponible"""
        class EngineBasico:
            def __init__(self):
                self.version = "basico_v1"
            
            def generar_audio(self, config, duracion_sec):
                import numpy as np
                samples = int(44100 * duracion_sec)
                freq = 10.0
                t = np.linspace(0, duracion_sec, samples)
                wave = 0.3 * np.sin(2 * np.pi * freq * t)
                return np.stack([wave, wave])
        
        return EngineBasico()
    
    def _generar_fallback(self, duracion_sec: float) -> np.ndarray:
        """Generar audio de fallback"""
        import numpy as np
        samples = int(44100 * duracion_sec)
        t = np.linspace(0, duracion_sec, samples)
        wave = 0.3 * np.sin(2 * np.pi * 10.0 * t)
        return np.stack([wave, wave])

# Crear instancias compatibles con Aurora Director V7
def crear_neuromix_aurora_v7():
    """Crear NeuroMix compatible con Aurora Director V7"""
    return NeuroMixAuroraV7Adapter()

# Alias principal para Aurora Director V7
if 'AuroraNeuroAcousticEngineV27' in globals():
    pass  # Si existe el engine original, usarlo
else:
    pass  # Si no, usar adapter
    # Si existe el engine original, usarlo
# Clase principal compatible con Aurora Director V7
class NeuroMix(NeuroMixAuroraV7Adapter):
    """Clase principal NeuroMix compatible con Aurora Director V7"""
    pass

# Función de conveniencia para Aurora Director
def crear_neuromix_seguro():
    """Crear NeuroMix de manera segura preservando funcionalidad"""
    return NeuroMix()

class NeuroMixAuroraV27:
    """
    Wrapper avanzado del motor NeuroMix Aurora V27
    
    PROPÓSITO: Interfaz limpia, estable y extendible que unifica todas
    las funcionalidades del ecosistema NeuroMix bajo un wrapper estándar.
    
    CARACTERÍSTICAS:
    - Composición sobre herencia (evita dependencias circulares)
    - Modos configurables (científico, adaptativo, terapéutico)
    - Lazy loading de motores (eficiencia de memoria)
    - Sistema de presets avanzado
    - Control de logging y debugging
    - Preparado para batch processing futuro
    
    COMPATIBILIDAD TOTAL: Aurora Director V7, objective_manager, GUI
    """
    
    def __init__(self, modo='cientifico', silent=False, cache_enabled=True):
        """
        Inicialización del wrapper con configuración flexible
        
        Args:
            modo: 'cientifico', 'adaptativo', 'terapeutico', 'creativo', 'performance'
            silent: Controla el logging detallado
            cache_enabled: Habilita caché de presets para optimización
        """
        self.modo = modo
        self.silent = silent
        self.cache_enabled = cache_enabled
        self.version = f"{VERSION}_WRAPPER_V7"
        
        # Lazy loading de motores (solo se crean cuando se necesitan)
        self._motor_cientifico = None
        self._motor_conectado = None
        self._motor_adapter = None
        
        # Sistema de caché inteligente
        self._preset_cache = {} if cache_enabled else None
        
        # Estadísticas de uso
        self._stats = {
            "presets_aplicados": 0,
            "generaciones_exitosas": 0,
            "modo_actual": modo,
            "inicializado": datetime.now().isoformat()
        }
        
        # Configurar logging
        self._setup_logging()
        
        if not self.silent:
            logger.info(f"🚀 NeuroMixAuroraV27 inicializado - Modo: {modo}")
    
    def _setup_logging(self):
        """Configura el sistema de logging según el modo silent"""
        if self.silent:
            logger.setLevel(logging.ERROR)
        else:
            logger.setLevel(logging.INFO)
    
    @property
    def motor_cientifico(self):
        """Lazy loading del sistema científico"""
        if self._motor_cientifico is None:
            self._motor_cientifico = SistemaNeuroacusticoCientificoV27()
            if not self.silent:
                logger.debug("🧬 Motor científico inicializado")
        return self._motor_cientifico
    
    @property
    def motor_conectado(self):
        """Lazy loading del motor conectado"""
        if self._motor_conectado is None:
            # Usar motor conectado si está disponible, sino usar base
            if 'AuroraNeuroAcousticEngineV27Connected' in globals():
                self._motor_conectado = AuroraNeuroAcousticEngineV27Connected()
            else:
                self._motor_conectado = AuroraNeuroAcousticEngineV27()
            if not self.silent:
                logger.debug("⚡ Motor conectado inicializado")
        return self._motor_conectado
    
    @property
    def motor_adapter(self):
        """Lazy loading del adaptador"""
        if self._motor_adapter is None:
            self._motor_adapter = NeuroMixAuroraV7Adapter(self.motor_conectado)
            if not self.silent:
                logger.debug("🔧 Adaptador inicializado")
        return self._motor_adapter
    
    def aplicar_presets(self, nombre: str, intensidad: str = "media", 
                       estilo: str = "neutro", objetivo: str = "relajacion") -> dict:
        """
        Aplica presets neuroacústicos según el modo configurado
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            intensidad: "muy_baja", "baja", "media", "alta", "muy_alta"
            estilo: "neutro", "sereno", "mistico", "crystalline", "tribal"
            objetivo: "relajacion", "concentracion", "creatividad", "meditacion"
            
        Returns:
            Dict con preset normalizado listo para generar audio
        """
        try:
            # Verificar caché primero
            cache_key = f"{nombre}_{intensidad}_{estilo}_{objetivo}_{self.modo}"
            if self.cache_enabled and cache_key in self._preset_cache:
                if not self.silent:
                    logger.debug(f"📦 Preset cargado desde caché: {cache_key}")
                return self._preset_cache[cache_key]
            
            # Generar preset según modo
            if self.modo == 'cientifico':
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            elif self.modo == 'adaptativo':
                preset = self.motor_cientifico.crear_preset_adaptativo_ppp(
                    nombre, intensidad, estilo, objetivo
                )
            elif self.modo == 'terapeutico':
                preset = self._generar_preset_terapeutico(nombre, objetivo)
            elif self.modo == 'creativo':
                preset = self._generar_preset_creativo(nombre, intensidad, estilo)
            elif self.modo == 'performance':
                preset = self._generar_preset_performance(nombre)
            else:
                # Modo por defecto: científico
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            
            # Normalizar preset
            preset_normalizado = self._normalizar_preset(preset)
            
            # Guardar en caché
            if self.cache_enabled:
                self._preset_cache[cache_key] = preset_normalizado
            
            # Actualizar estadísticas
            self._stats["presets_aplicados"] += 1
            
            if not self.silent:
                logger.info(f"✅ Preset aplicado: {nombre} ({self.modo})")
            
            return preset_normalizado
            
        except Exception as e:
            logger.error(f"❌ Error aplicando preset {nombre}: {e}")
            # Fallback a preset básico
            return self._generar_preset_fallback(nombre)
    
    def generate_neuro_wave(self, config: dict, gain_db: float = -12.0):
        """
        Genera audio neuroacústico usando el motor conectado
        
        Args:
            config: Configuración de generación
            gain_db: Ganancia en dB para el audio final
            
        Returns:
            numpy.ndarray con audio generado
        """
        try:
            # Validar configuración primero
            if not self.motor_adapter.validar_configuracion(config):
                raise ValueError("Configuración inválida")
            
            # Generar audio
            duracion = config.get('duracion', config.get('duration_sec', 60.0))
            audio = self.motor_adapter.generar_audio(config, duracion)
            
            # Aplicar ganancia si es necesario
            if gain_db != 0.0:
                gain_linear = 10 ** (gain_db / 20)
                audio = audio * gain_linear
            
            self._stats["generaciones_exitosas"] += 1
            
            if not self.silent:
                logger.info(f"🎵 Audio generado exitosamente ({len(audio)} samples)")
            
            return audio
            
        except Exception as e:
            logger.error(f"❌ Error generando audio: {e}")
            # Fallback a generación básica
            return self._generar_audio_fallback(config.get('duracion', 60.0))
    
    def get_capabilities(self):
        """Expone capacidades del motor de forma segura"""
        try:
            caps_base = self.motor_adapter.obtener_capacidades()
            caps_wrapper = {
                "wrapper_version": self.version,
                "modo": self.modo,
                "modos_disponibles": ["cientifico", "adaptativo", "terapeutico", "creativo", "performance"],
                "cache_enabled": self.cache_enabled,
                "silent_mode": self.silent,
                "stats": self._stats.copy()
            }
            
            # Combinar capacidades
            return {**caps_base, "wrapper": caps_wrapper}
            
        except Exception as e:
            logger.error(f"Error obteniendo capacidades: {e}")
            return {"error": str(e), "fallback": True}
    
    def get_preset_info(self, nombre: str) -> dict:
        """
        Obtiene información detallada de un preset sin aplicarlo
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            
        Returns:
            Dict con información del preset
        """
        try:
            preset_info = {
                "nombre": nombre,
                "disponible": nombre.lower() in self.motor_cientifico.presets_cientificos,
                "modo_recomendado": self._recomendar_modo_preset(nombre),
                "neurotransmisor_valido": nombre.lower() in [nt.value for nt in Neurotransmisor]
            }
            
            if preset_info["disponible"]:
                preset_data = self.motor_cientifico.obtener_preset_cientifico(nombre)
                preset_info.update({
                    "carrier_freq": preset_data.get("carrier", 0),
                    "beat_freq": preset_data.get("beat_freq", 0),
                    "confidence": preset_data.get("confidence", 0.5)
                })
            
            return preset_info
            
        except Exception as e:
            logger.error(f"Error obteniendo info de preset {nombre}: {e}")
            return {"nombre": nombre, "error": str(e)}
    
    def _normalizar_preset(self, preset_obj):
        """Normaliza presets a formato estándar Aurora"""
        if isinstance(preset_obj, dict):
            return preset_obj
        elif hasattr(preset_obj, '__dict__'):
            return vars(preset_obj)
        elif hasattr(preset_obj, '_asdict'):  # namedtuple
            return preset_obj._asdict()
        else:
            raise TypeError(f"Formato de preset no soportado: {type(preset_obj)}")
    
    def _generar_preset_terapeutico(self, nombre: str, objetivo: str) -> dict:
        """Genera preset optimizado para uso terapéutico"""
        base = self.motor_cientifico.obtener_preset_cientifico(nombre)
        
        # Ajustes terapéuticos
        ajustes_terapeuticos = {
            "am_depth": base.get("am_depth", 0.5) * 0.8,  # Más suave
            "fm_index": base.get("fm_index", 3) * 0.9,    # Menos complejo
            "therapeutic_mode": True,
            "objetivo_terapeutico": objetivo
        }
        
        return {**base, **ajustes_terapeuticos}
    
    def _generar_preset_creativo(self, nombre: str, intensidad: str, estilo: str) -> dict:
        """Genera preset optimizado para creatividad"""
        base = self.motor_cientifico.crear_preset_adaptativo_ppp(nombre, intensidad, estilo, "creatividad")
        
        # Potenciar aspectos creativos
        base["fm_index"] = base.get("fm_index", 3) * 1.2  # Más complejidad
        base["creative_enhancement"] = True
        
        return base
    
    def _generar_preset_performance(self, nombre: str) -> dict:
        """Genera preset optimizado para máximo rendimiento"""
        base = self.motor_cientifico.obtener_preset_ppp(nombre)  # Más rápido que científico
        base["performance_mode"] = True
        base["reduced_complexity"] = True
        return base
    
    def _generar_preset_fallback(self, nombre: str) -> dict:
        """Preset de emergencia básico"""
        return {
            "carrier": 220.0,
            "beat_freq": 4.0,
            "am_depth": 0.5,
            "fm_index": 3,
            "fallback": True,
            "preset_name": nombre
        }
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        """Audio de emergencia básico"""
        t = np.linspace(0, duracion_sec, int(SAMPLE_RATE * duracion_sec))
        audio = 0.1 * np.sin(2 * np.pi * 220 * t)  # Tono básico
        return audio
    
    def _recomendar_modo_preset(self, nombre: str) -> str:
        """Recomienda el mejor modo para un preset dado"""
        if nombre.lower() in ["dopamina", "acetilcolina"]:
            return "adaptativo"
        elif nombre.lower() in ["gaba", "serotonina", "melatonina"]:
            return "terapeutico"
        elif nombre.lower() in ["anandamida", "glutamato"]:
            return "creativo"
        else:
            return "cientifico"
    
    # Métodos de compatibilidad con interfaces Aurora
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        config_completo = config.copy()
        config_completo['duracion'] = duracion_sec
        return self.generate_neuro_wave(config_completo)
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.motor_adapter.validar_configuracion(config)
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.get_capabilities()
    
    def get_info(self) -> Dict[str, str]:
        """Información básica del wrapper"""
        return {
            "name": "NeuroMix Aurora V27 Wrapper",
            "version": self.version,
            "description": "Wrapper avanzado con modos configurables y presets inteligentes",
            "modo": self.modo,
            "capabilities": f"Presets aplicados: {self._stats['presets_aplicados']}, Generaciones: {self._stats['generaciones_exitosas']}",
            "integration": "Aurora Director V7 Compatible",
            "status": "Operativo con wrapper avanzado"
        }

# ================================================================
# 🎯 REGISTRO AUTOMÁTICO EN EL ECOSISTEMA AURORA
# ================================================================
# Registrar la clase en el espacio global para detección automática
globals()['NeuroMixAuroraV27'] = NeuroMixAuroraV27

# Log de integración exitosa
if not logging.getLogger("Aurora.NeuroMix.V27.Complete").handlers or \
   logging.getLogger("Aurora.NeuroMix.V27.Complete").level <= logging.INFO:
    logger.info("🎉 SEXTA VICTORIA: NeuroMixAuroraV27 wrapper integrado exitosamente")
    logger.info("🔧 Clase disponible: NeuroMixAuroraV27 con soporte para aplicar_presets")
    logger.info("✅ Compatible con: Aurora Director V7, objective_manager, GUI")

if __name__ == "__main__":
    print(f"NeuroMix V27 Complete - Sistema Neuroacústico Total")
    print("=" * 80)
    
    info = get_aurora_info()
    print(f"{info['compatibility']}")
    print(f"Compatibilidad PPP: {info['features']['ppp_compatibility']}")
    print(f"Integración Aurora: {info['features']['aurora_director_integration']}")
    
    print(f"\nTest PPP (compatibilidad 100%):")
    try:
        legacy_audio = generate_neuro_wave("dopamina", 2.0, "binaural", intensity="alta")
        print(f"   Audio PPP generado: {legacy_audio.shape}")
    except Exception as e:
        print(f"   Error PPP: {e}")
    
    print(f"\nTest Aurora Director:")
    try:
        config_aurora = {'objetivo': 'concentracion', 'intensidad': 'media', 'estilo': 'crystalline', 'calidad_objetivo': 'alta'}
        
        engine = _global_engine
        if engine.validar_configuracion(config_aurora):
            audio_aurora = engine.generar_audio(config_aurora, 2.0)
            print(f"   Audio Aurora generado: {audio_aurora.shape}")
        else:
            print(f"   Configuración Aurora inválida")
    except Exception as e:
        print(f"   Error Aurora: {e}")
    
    print(f"\nTest avanzado V27:")
    try:
        config = create_aurora_config(neurotransmitter="serotonina", duration_sec=1.0, wave_type="therapeutic", quality_level=NeuroQualityLevel.THERAPEUTIC)
        
        advanced_audio, analysis = generate_aurora_session(config)
        print(f"   Audio avanzado: {advanced_audio.shape}")
        print(f"   Calidad: {analysis.get('quality_score', 'N/A')}/100")
    except Exception as e:
        print(f"   Error avanzado: {e}")
    
    stats = _global_engine.get_processing_stats()
    print(f"\nEstadísticas del motor:")
    print(f"   • Total generado: {stats['total_generated']}")
    print(f"   • Usos PPP: {stats['ppp_compatibility_uses']}")
    print(f"   • Integraciones Aurora: {stats['aurora_integrations']}")
    
    print(f"\nNEUROMIX V27 COMPLETE")
    print(f"Compatible 100% con PPP + Aurora Director V7")
    print(f"Sistema científico + fallbacks garantizados")
    print(f"¡Motor neuroacústico más completo del ecosistema Aurora!")

# Alias oficial único para compatibilidad AuroraDirector
# AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected  # COMENTADO: CAUSA RECURSIÓN