# ‚úÖ Archivo h√≠brido: NeuroMix V27 con fallback inteligente
# - Usa 'NeuroMixSuperUnificado' si est√° disponible
# - Si no, funciona como motor base aut√≥nomo


# PARCHE ADITIVO AURORA DIRECTOR V7 - Imports adicionales
import logging
from typing import Dict, Any, Protocol

# Configurar logging si no est√° configurado
if not logging.getLogger().handlers:
    logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Aurora.NeuroMix.V27.Aditivo")

import wave
import numpy as np
import json
import time
import logging
import warnings
from typing import Dict, Tuple, Optional, List, Any, Union, Protocol, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
from functools import lru_cache

SAMPLE_RATE = 44100
VERSION = "V27_AURORA_CONNECTED_PPP_COMPLETE"
CONFIDENCE_THRESHOLD = 0.8
logger = logging.getLogger("Aurora.NeuroMix.V27.Complete")
logger.setLevel(logging.INFO)

class MotorAurora(Protocol):
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray: ...
    def validar_configuracion(self, config: Dict[str, Any]) -> bool: ...
    def obtener_capacidades(self) -> Dict[str, Any]: ...

class Neurotransmisor(Enum):
    DOPAMINA = "dopamina"
    SEROTONINA = "serotonina"
    GABA = "gaba"
    OXITOCINA = "oxitocina"
    ANANDAMIDA = "anandamida"
    ACETILCOLINA = "acetilcolina"
    ENDORFINA = "endorfina"
    BDNF = "bdnf"
    ADRENALINA = "adrenalina"
    NOREPINEFRINA = "norepinefrina"
    MELATONINA = "melatonina"
    GLUTAMATO = "glutamato"
    NORADRENALINA = "noradrenalina"
    ENDORFINAS = "endorfinas"

class EstadoEmocional(Enum):
    ENFOQUE = "enfoque"
    RELAJACION = "relajacion"
    GRATITUD = "gratitud"
    VISUALIZACION = "visualizacion"
    SOLTAR = "soltar"
    ACCION = "accion"
    CLARIDAD_MENTAL = "claridad_mental"
    SEGURIDAD_INTERIOR = "seguridad_interior"
    APERTURA_CORAZON = "apertura_corazon"
    ALEGRIA_SOSTENIDA = "alegria_sostenida"
    FUERZA_TRIBAL = "fuerza_tribal"
    CONEXION_MISTICA = "conexion_mistica"
    REGULACION_EMOCIONAL = "regulacion_emocional"
    EXPANSION_CREATIVA = "expansion_creativa"
    ESTADO_FLUJO = "estado_flujo"
    INTROSPECCION_SUAVE = "introspeccion_suave"
    SANACION_PROFUNDA = "sanacion_profunda"
    EQUILIBRIO_MENTAL = "equilibrio_mental"

class NeuroQualityLevel(Enum):
    BASIC = "b√°sico"
    ENHANCED = "mejorado"
    PROFESSIONAL = "profesional"
    THERAPEUTIC = "terap√©utico"
    RESEARCH = "investigaci√≥n"

class ProcessingMode(Enum):
    LEGACY = "legacy"
    STANDARD = "standard"
    ADVANCED = "advanced"
    PARALLEL = "parallel"
    REALTIME = "realtime"
    AURORA_INTEGRATED = "aurora_integrated"

@dataclass
class NeuroConfig:
    neurotransmitter: str
    duration_sec: float
    wave_type: str = 'hybrid'
    intensity: str = "media"
    style: str = "neutro"
    objective: str = "relajaci√≥n"
    quality_level: NeuroQualityLevel = NeuroQualityLevel.ENHANCED
    processing_mode: ProcessingMode = ProcessingMode.STANDARD
    enable_quality_pipeline: bool = True
    enable_analysis: bool = True
    enable_textures: bool = True
    enable_spatial_effects: bool = False
    custom_frequencies: Optional[List[float]] = None
    modulation_complexity: float = 1.0
    harmonic_richness: float = 0.5
    therapeutic_intent: Optional[str] = None
    apply_mastering: bool = True
    target_lufs: float = -23.0
    export_analysis: bool = False
    aurora_config: Optional[Dict[str, Any]] = None
    director_context: Optional[Dict[str, Any]] = None
    use_scientific_data: bool = True

class SistemaNeuroacusticoCientificoV27:
    def __init__(self):
        self.version = "v27_aurora_scientific_ppp"
        self._init_data()
    
    def _init_data(self):
        self.presets_ppp = {
            "dopamina": {"carrier": 123.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4},
            "serotonina": {"carrier": 111.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3},
            "gaba": {"carrier": 90.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2},
            "acetilcolina": {"carrier": 105.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3},
            "glutamato": {"carrier": 140.0, "beat_freq": 5.0, "am_depth": 0.6, "fm_index": 5},
            "oxitocina": {"carrier": 128.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2},
            "noradrenalina": {"carrier": 135.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5},
            "endorfinas": {"carrier": 98.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2},
            "melatonina": {"carrier": 85.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1}
        }
        
        self.presets_cientificos = {
            "dopamina": {"carrier": 396.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4, "confidence": 0.94},
            "serotonina": {"carrier": 417.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.92},
            "gaba": {"carrier": 72.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2, "confidence": 0.95},
            "acetilcolina": {"carrier": 320.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3, "confidence": 0.89},
            "oxitocina": {"carrier": 528.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2, "confidence": 0.90},
            "anandamida": {"carrier": 111.0, "beat_freq": 2.5, "am_depth": 0.4, "fm_index": 2, "confidence": 0.82},
            "endorfina": {"carrier": 528.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2, "confidence": 0.87},
            "bdnf": {"carrier": 285.0, "beat_freq": 4.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.88},
            "adrenalina": {"carrier": 741.0, "beat_freq": 8.0, "am_depth": 0.9, "fm_index": 6, "confidence": 0.91},
            "norepinefrina": {"carrier": 693.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5, "confidence": 0.91},
            "melatonina": {"carrier": 108.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1, "confidence": 0.93}
        }
        
        self.presets_cientificos["glutamato"] = self.presets_cientificos["dopamina"].copy()
        self.presets_cientificos["noradrenalina"] = self.presets_cientificos["norepinefrina"].copy()
        self.presets_cientificos["endorfinas"] = self.presets_cientificos["endorfina"].copy()
        
        self.intensity_factors_ppp = {
            "muy_baja": {"carrier_mult": 0.6, "beat_mult": 0.5, "am_mult": 0.4, "fm_mult": 0.5},
            "baja": {"carrier_mult": 0.8, "beat_mult": 0.7, "am_mult": 0.6, "fm_mult": 0.7},
            "media": {"carrier_mult": 1.0, "beat_mult": 1.0, "am_mult": 1.0, "fm_mult": 1.0},
            "alta": {"carrier_mult": 1.2, "beat_mult": 1.3, "am_mult": 1.4, "fm_mult": 1.3},
            "muy_alta": {"carrier_mult": 1.4, "beat_mult": 1.6, "am_mult": 1.7, "fm_mult": 1.5}
        }
        
        self.style_factors_ppp = {
            "neutro": {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0},
            "alienigena": {"carrier_offset": 15, "beat_offset": 1.5, "complexity": 1.3},
            "minimal": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.7},
            "organico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.1},
            "cinematico": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.4},
            "ancestral": {"carrier_offset": -15, "beat_offset": -0.8, "complexity": 0.8},
            "futurista": {"carrier_offset": 25, "beat_offset": 2.0, "complexity": 1.6},
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        self.objective_factors_ppp = {
            "relajaci√≥n": {"tempo_mult": 0.8, "smoothness": 1.2, "depth_mult": 1.1},
            "claridad mental + enfoque cognitivo": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "activaci√≥n l√∫cida": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.0},
            "meditaci√≥n profunda": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3},
            "energ√≠a creativa": {"tempo_mult": 1.3, "smoothness": 0.8, "depth_mult": 1.2},
            "sanaci√≥n emocional": {"tempo_mult": 0.7, "smoothness": 1.4, "depth_mult": 1.2},
            "expansi√≥n consciencia": {"tempo_mult": 0.5, "smoothness": 1.6, "depth_mult": 1.4},
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
    
    def obtener_preset_ppp(self, nt: str) -> Dict[str, Any]:
        return self.presets_ppp.get(nt.lower(), {"carrier": 123.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4})
    
    def obtener_preset_cientifico(self, nt: str) -> Dict[str, Any]:
        return self.presets_cientificos.get(nt.lower(), {"carrier": 220.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4, "confidence": 0.8})
    
    def crear_preset_adaptativo_ppp(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaci√≥n") -> Dict[str, Any]:
        base = self.obtener_preset_ppp(nt)
        i_f = self.intensity_factors_ppp.get(intensity, self.intensity_factors_ppp["media"])
        s_f = self.style_factors_ppp.get(style, self.style_factors_ppp["neutro"])
        o_f = self.objective_factors_ppp.get(objective, self.objective_factors_ppp["relajaci√≥n"])
        
        adapted = {
            "carrier": base["carrier"] * i_f["carrier_mult"] + s_f["carrier_offset"],
            "beat_freq": base["beat_freq"] * i_f["beat_mult"] * o_f["tempo_mult"] + s_f["beat_offset"],
            "am_depth": base["am_depth"] * i_f["am_mult"] * o_f["smoothness"] * o_f["depth_mult"],
            "fm_index": base["fm_index"] * i_f["fm_mult"] * s_f["complexity"]
        }
        
        adapted["carrier"] = max(30, min(300, adapted["carrier"]))
        adapted["beat_freq"] = max(0.1, min(40, adapted["beat_freq"]))
        adapted["am_depth"] = max(0.05, min(0.95, adapted["am_depth"]))
        adapted["fm_index"] = max(0.5, min(12, adapted["fm_index"]))
        
        return adapted

class AuroraNeuroAcousticEngineV27:
    def __init__(self, sample_rate: int = SAMPLE_RATE, enable_advanced_features: bool = True, cache_size: int = 256):
        self.sample_rate = sample_rate
        self.enable_advanced = enable_advanced_features
        self.cache_size = cache_size
        self.sistema_cientifico = SistemaNeuroacusticoCientificoV27()
        self.version = VERSION
        self._enable_auto_export = True
        self._init_cache_inteligente()
        
        if self.enable_advanced:
            self._init_advanced_components()
        
        self.processing_stats = {
            'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
            'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
            'ppp_compatibility_uses': 0, 'fallback_uses': 0
        }
        
        if self.enable_advanced:
            self._init_advanced_components()
        
        logger.info(f"NeuroMix V27 Complete inicializado: Aurora + PPP + Cient√≠fico")
    
    def _init_advanced_components(self):
        try:
            self.quality_pipeline = None
            self.harmonic_generator = None
            self.analyzer = None
            logger.info("Componentes Aurora avanzados cargados")
        except Exception as e:
            logger.warning(f"Componentes Aurora no disponibles: {e}")
            self.enable_advanced = False

    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        logger.info(f"üéØ INICIANDO generar_audio - Config: {list(config.keys())}, Duraci√≥n: {duracion_sec}s")
        
        try:
            # PASO 1: Conversi√≥n de configuraci√≥n con diagn√≥stico
            logger.debug(f"üîÑ Convirtiendo config Aurora a NeuroConfig...")
            neuro_config = self._convertir_config_aurora_a_neuromix(config, duracion_sec)
            logger.info(f"‚úÖ NeuroConfig creado - Modo: {neuro_config.processing_mode.value}, NT: {neuro_config.neurotransmitter}")
            
            # PASO 2: Generaci√≥n de audio neuroac√∫stico con diagn√≥stico
            logger.debug(f"üéµ Llamando generate_neuro_wave_advanced...")
            audio_data, analysis = self.generate_neuro_wave_advanced(neuro_config)
            logger.info(f"üéâ Audio generado - Shape: {audio_data.shape}, M√©todo: {analysis.get('generation_method', 'unknown')}")
            
            # PASO 3: Validar que el audio tiene contenido real
            audio_max = np.max(np.abs(audio_data))
            audio_rms = np.sqrt(np.mean(audio_data**2))
            logger.info(f"üìä Audio Stats - Max: {audio_max:.4f}, RMS: {audio_rms:.6f}")
            
            if audio_max < 0.001:
                logger.warning(f"‚ö†Ô∏è Audio muy silencioso (max: {audio_max}) - Puede ser problema de generaci√≥n")
            
            self.processing_stats['aurora_integrations'] += 1
            logger.info(f"‚úÖ √âXITO: Audio neuroac√∫stico generado correctamente")
            return audio_data
            
        except Exception as e:
            logger.error(f"‚ùå ERROR CR√çTICO en generar_audio: {e}")
            logger.error(f"üìã Config recibido: {config}")
            logger.error(f"‚è±Ô∏è Duraci√≥n: {duracion_sec}")
            import traceback
            logger.error(f"üîç Traceback completo: {traceback.format_exc()}")
            
            # NO usar fallback - relanzar la excepci√≥n para debugging
            raise e
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        return {
            "nombre": "NeuroMix V27 Aurora Connected + PPP Complete",
            "version": self.version,
            "tipo": "motor_neuroacustico",
            "compatible_con": ["Aurora Director V7", "PPP Functions", "Field Profiles", "Objective Router"],
            "neurotransmisores_soportados": self.get_available_neurotransmitters(),
            "tipos_onda": self.get_available_wave_types(),
            "modos_procesamiento": [modo.value for modo in ProcessingMode],
            "sample_rates": [22050, 44100, 48000],
            "duracion_minima": 1.0,
            "duracion_maxima": 3600.0,
            "calidad_maxima": "therapeutic",
            "compatibilidad_ppp": True,
            "compatibilidad_aurora": True,
            "fallback_garantizado": True,
            "validacion_cientifica": True,
            "estadisticas": self.processing_stats.copy()
        }
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """
        Valida configuraci√≥n para Aurora Director V7
        AGREGAR despu√©s del m√©todo obtener_capacidades
        """
        try:
            if not isinstance(config, dict):
                return False
            
            # Validar campo objetivo obligatorio
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            # Validar duraci√≥n (si viene en config)
            duracion = config.get('duracion_sec') or config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            # Validar intensidad
            intensidad = config.get('intensidad', 'media')
            intensidades_validas = ['muy_baja', 'baja', 'media', 'alta', 'muy_alta']
            if intensidad not in intensidades_validas:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validando configuraci√≥n: {e}")
            return False
    
    def get_info(self) -> Dict[str, str]:
        """
        Informaci√≥n b√°sica del motor para Aurora Director V7
        AGREGAR despu√©s del m√©todo validar_configuracion
        """
        return {
            "name": "NeuroMix Aurora V27 Connected",
            "version": self.version,
            "description": "Motor neuroac√∫stico principal con ondas binaurales y neurotransmisores",
            "capabilities": "AM/FM, PPP, Neurotransmisores, An√°lisis FFT",
            "integration": "Aurora Director V7 Compatible",
            "status": "Conectado y operativo"
        }
    
    def _convertir_config_aurora_a_neuromix(self, config_aurora: Dict[str, Any], duracion_sec: float) -> NeuroConfig:
        logger.debug(f"üîÑ Iniciando conversi√≥n config - Input keys: {list(config_aurora.keys())}")
        
        # Validaci√≥n robusta de entrada
        if not isinstance(config_aurora, dict):
            raise ValueError(f"Config debe ser dict, recibido: {type(config_aurora)}")
        
        if not isinstance(duracion_sec, (int, float)) or duracion_sec <= 0:
            raise ValueError(f"Duraci√≥n debe ser num√©rica positiva, recibido: {duracion_sec}")
        
        # Extracci√≥n robusta de par√°metros
        neurotransmisor = config_aurora.get('neurotransmisor_preferido', None)
        if not neurotransmisor or neurotransmisor == 'auto':
            objetivo = config_aurora.get('objetivo', 'relajacion')
            neurotransmisor = self._inferir_neurotransmisor_por_objetivo(objetivo)
            logger.debug(f"üß† NT inferido desde objetivo '{objetivo}': {neurotransmisor}")
        
        # Mapeo robusto de intensidad
        intensidad_raw = config_aurora.get('intensidad', 'media')
        intensidad_mapeada = self._mapear_intensidad_a_formato_neuro(intensidad_raw)
        
        # Crear NeuroConfig con valores garantizados
        neuro_config = NeuroConfig(
            neurotransmitter=neurotransmisor,
            duration_sec=float(duracion_sec),
            wave_type='hybrid',  # Forzar hybrid para m√°xima compatibilidad
            intensity=intensidad_mapeada,
            style=config_aurora.get('estilo', 'neutro'),
            objective=config_aurora.get('objetivo', 'relajacion'),
            aurora_config=config_aurora,
            processing_mode=ProcessingMode.AURORA_INTEGRATED,  # Usar el modo m√°s potente
            use_scientific_data=True,
            quality_level=self._mapear_calidad_aurora(config_aurora.get('calidad_objetivo', 'alta')),
            enable_quality_pipeline=True,  # Forzar pipeline de calidad
            apply_mastering=True,
            target_lufs=-23.0,
            # Par√°metros adicionales para garantizar generaci√≥n
            modulation_complexity=0.7,  # Complejidad moderada
            harmonic_richness=0.5,      # Arm√≥nicos moderados
            enable_analysis=True,       # Habilitar an√°lisis
            enable_spatial_effects=False  # Deshabilitar efectos complejos que puedan fallar
        )
        
        logger.info(f"‚úÖ NeuroConfig convertido - NT: {neurotransmisor}, Duraci√≥n: {duracion_sec}s, Modo: {neuro_config.processing_mode.value}")
        return neuro_config

    def _mapear_intensidad_a_formato_neuro(self, intensidad_raw: Any) -> str:
        """Mapea cualquier formato de intensidad al formato NeuroConfig"""
        if isinstance(intensidad_raw, (int, float)):
            if intensidad_raw <= 0.2: return "muy_baja"
            elif intensidad_raw <= 0.4: return "baja" 
            elif intensidad_raw <= 0.6: return "media"
            elif intensidad_raw <= 0.8: return "alta"
            else: return "muy_alta"
        
        # Si es string, normalizar
        intensidad_str = str(intensidad_raw).lower()
        mapeo = {
            'muy_baja': 'muy_baja', 'muy baja': 'muy_baja', 'very_low': 'muy_baja',
            'baja': 'baja', 'low': 'baja', 'bajo': 'baja',
            'media': 'media', 'medium': 'media', 'normal': 'media', 'medio': 'media',
            'alta': 'alta', 'high': 'alta', 'alto': 'alta',
            'muy_alta': 'muy_alta', 'muy alta': 'muy_alta', 'very_high': 'muy_alta', 'maximo': 'muy_alta'
        }
        
        return mapeo.get(intensidad_str, 'media')  # Default a media si no se reconoce
    
    def _inferir_neurotransmisor_por_objetivo(self, objetivo: str) -> str:
        objetivo_lower = objetivo.lower()
        mapeo = {'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina', 'enfoque': 'norepinefrina',
                'relajacion': 'gaba', 'meditacion': 'serotonina', 'creatividad': 'anandamida',
                'energia': 'adrenalina', 'sanacion': 'oxitocina', 'gratitud': 'oxitocina'}
        
        for key, nt in mapeo.items():
            if key in objetivo_lower: return nt
        return 'serotonina'
    
    def _mapear_calidad_aurora(self, calidad_aurora: str) -> NeuroQualityLevel:
        mapeo = {'basica': NeuroQualityLevel.BASIC, 'media': NeuroQualityLevel.ENHANCED,
                'alta': NeuroQualityLevel.PROFESSIONAL, 'maxima': NeuroQualityLevel.THERAPEUTIC}
        return mapeo.get(calidad_aurora, NeuroQualityLevel.ENHANCED)
    
    def get_neuro_preset(self, nt: str) -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        return self.sistema_cientifico.obtener_preset_ppp(nt)
    
    def get_adaptive_neuro_preset(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaci√≥n") -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        if self.enable_advanced and hasattr(self, '_get_scientific_preset'):
            return self._get_scientific_preset(nt, intensity, style, objective)
        return self.sistema_cientifico.crear_preset_adaptativo_ppp(nt, intensity, style, objective)
    
    def generate_neuro_wave_advanced(self, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        start_time = time.time()
        
        try:
            if not self._validate_config(config):
                raise ValueError("Configuraci√≥n neuroac√∫stica inv√°lida")
            
            analysis = {"config_valid": True, "processing_mode": config.processing_mode.value,
                       "aurora_integration": bool(config.aurora_config), "ppp_compatibility": True}
            
            if config.processing_mode == ProcessingMode.AURORA_INTEGRATED:
                audio_data = self._generate_aurora_integrated_wave(config)
                analysis.update({"generation_method": "aurora_integrated", "quality_score": 98})
            elif config.processing_mode == ProcessingMode.PARALLEL:
                audio_data = self._generate_parallel_wave(config)
                analysis.update({"generation_method": "parallel", "quality_score": 92})
            elif config.processing_mode == ProcessingMode.LEGACY:
                audio_data = self._generate_legacy_wave(config)
                analysis.update({"generation_method": "legacy", "quality_score": 85})
            else:
                audio_data = self._generate_enhanced_wave(config)
                analysis.update({"generation_method": "enhanced", "quality_score": 90})
            
            if config.enable_quality_pipeline:
                audio_data, quality_info = self._apply_quality_pipeline(audio_data)
                analysis.update(quality_info)
            
            if config.enable_spatial_effects:
                audio_data = self._apply_spatial_effects(audio_data, config)
            
            if config.enable_analysis:
                neuro_analysis = self._analyze_neuro_content(audio_data, config)
                analysis.update(neuro_analysis)
            
            processing_time = time.time() - start_time
            self._update_processing_stats(analysis.get("quality_score", 85), processing_time, config)
            
            analysis.update({"processing_time": processing_time, "config": asdict(config) if hasattr(config, '__dict__') else str(config), "success": True})
            
            logger.info(f"Audio generado: {config.neurotransmitter} | Calidad: {analysis.get('quality_score', 85)}/100 | Tiempo: {processing_time:.2f}s")
            if hasattr(self, '_enable_auto_export') and self._enable_auto_export:
                try:
                    export_result = self._validar_y_exportar_wav_automatico(audio_data, config)
                    # Actualizar an√°lisis con info de exportaci√≥n
                    analysis.update({
                        'exportacion_automatica': export_result,
                        'archivo_generado': export_result.get('exportacion_exitosa', False),
                        'archivo_nombre': export_result.get('archivo_generado', 'N/A')
                    })
                    
                    if hasattr(self, 'logger'):
                        if export_result.get('exportacion_exitosa', False):
                            logger.info(f"üìÅ Audio exportado autom√°ticamente: {export_result.get('archivo_generado', 'N/A')}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Exportaci√≥n autom√°tica fall√≥: {export_result.get('error', 'Error desconocido')}")
                            
                except Exception as e:
                    # Fallar silenciosamente para no afectar generaci√≥n principal
                    if hasattr(self, 'logger'):
                        logger.warning(f"‚ö†Ô∏è Error en exportaci√≥n autom√°tica: {e}")
                    analysis.update({
                        'exportacion_automatica': {'exportacion_exitosa': False, 'error': str(e)},
                        'archivo_generado': False
                    })
            return audio_data, analysis
            
        except Exception as e:
            logger.error(f"‚ùå FALLO CR√çTICO en generate_neuro_wave_advanced: {e}")
            import traceback
            logger.error(f"üîç Traceback: {traceback.format_exc()}")
            raise e  # NO usar fallback - relanzar para debugging
    
    def _generate_enhanced_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        complexity = config.modulation_complexity
        
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_secondary = 0.3 * np.sin(2 * np.pi * beat_freq * 1.618 * t + np.pi/4)
        lfo_tertiary = 0.15 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/3)
        combined_lfo = (lfo_primary + complexity * lfo_secondary + complexity * 0.5 * lfo_tertiary) / (1 + complexity * 0.8)
        
        if config.wave_type == 'binaural_advanced':
            left_freq, right_freq = carrier - beat_freq / 2, carrier + beat_freq / 2
            left = np.sin(2 * np.pi * left_freq * t + 0.1 * combined_lfo)
            right = np.sin(2 * np.pi * right_freq * t + 0.1 * combined_lfo)
            
            if config.harmonic_richness > 0:
                harmonics = self._generate_harmonics(t, [left_freq, right_freq], config.harmonic_richness)
                left += harmonics[0] * 0.3
                right += harmonics[1] * 0.3
            
            audio_data = np.stack([left, right])
        
        elif config.wave_type == 'neural_complex':
            neural_pattern = self._generate_neural_pattern(t, carrier, beat_freq, complexity)
            am_envelope = 1 + am_depth * combined_lfo
            fm_component = fm_index * combined_lfo * 0.5
            base_wave = neural_pattern * am_envelope
            modulated_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_envelope
            final_wave = 0.6 * base_wave + 0.4 * modulated_wave
            audio_data = np.stack([final_wave, final_wave])
        
        elif config.wave_type == 'therapeutic':
            envelope = self._generate_therapeutic_envelope(t, config.duration_sec)
            base_carrier = np.sin(2 * np.pi * carrier * t)
            modulated = base_carrier * (1 + am_depth * combined_lfo) * envelope
            
            for freq in [111, 528, 741]:
                if freq != carrier:
                    healing_component = 0.1 * np.sin(2 * np.pi * freq * t) * envelope
                    modulated += healing_component
            
            audio_data = np.stack([modulated, modulated])
        
        else:
            legacy_config = NeuroConfig(neurotransmitter=config.neurotransmitter, duration_sec=config.duration_sec,
                                      wave_type=config.wave_type, intensity=config.intensity, style=config.style, objective=config.objective)
            audio_data = self._generate_legacy_wave(legacy_config)
        
        if config.enable_textures and config.harmonic_richness > 0:
            audio_data = self._apply_harmonic_textures(audio_data, config)
        
        return audio_data
    
    def _generate_legacy_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier, beat_freq, am_depth, fm_index = preset["carrier"], preset["beat_freq"], preset["am_depth"], preset["fm_index"]
        
        if config.wave_type == 'sine':
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'binaural':
            left = np.sin(2 * np.pi * (carrier - beat_freq / 2) * t)
            right = np.sin(2 * np.pi * (carrier + beat_freq / 2) * t)
            return np.stack([left, right])
        elif config.wave_type == 'am':
            modulator = 1 + am_depth * np.sin(2 * np.pi * beat_freq * t)
            wave = modulator * np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'fm':
            mod = np.sin(2 * np.pi * beat_freq * t)
            wave = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            return np.stack([wave, wave])
        elif config.wave_type == 'hybrid':
            mod = np.sin(2 * np.pi * beat_freq * t)
            am = 1 + am_depth * mod
            fm = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            wave = am * fm
            return np.stack([wave, wave])
        else:
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
    
    def _generate_parallel_wave(self, config: NeuroConfig) -> np.ndarray:
        block_duration = 10.0
        num_blocks = int(np.ceil(config.duration_sec / block_duration))
        
        def generate_block(block_idx):
            block_config = NeuroConfig(neurotransmitter=config.neurotransmitter,
                                     duration_sec=min(block_duration, config.duration_sec - block_idx * block_duration),
                                     wave_type=config.wave_type, intensity=config.intensity, style=config.style,
                                     objective=config.objective, processing_mode=ProcessingMode.STANDARD)
            return self._generate_enhanced_wave(block_config)
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(generate_block, i) for i in range(num_blocks)]
            blocks = [future.result() for future in as_completed(futures)]
        
        return np.concatenate(blocks, axis=1)
    
    def _generate_aurora_integrated_wave(self, config: NeuroConfig) -> np.ndarray:
        """
        üéØ VICTORIA #7 - Generaci√≥n Aurora 100% Binaural Neuroac√∫stica INTEGRADA
        
        NUEVO: Sistema neuroac√∫stico inteligente integrado nativamente
        ELIMINA: Dependencias de post-procesamiento y conflictos de normalizaci√≥n
        GARANTIZA: RMS consistente y calidad neuroac√∫stica profesional
        """
        try:
            import numpy as np
            
            # DESPU√âS (con cache inteligente):
            # üß† OPTIMIZACI√ìN B.1: Obtener preset con cache LRU
            if hasattr(self, '_obtener_preset_cached'):
                preset = self._obtener_preset_cached(
                    neurotransmisor=config.neurotransmitter,
                    intensidad=config.intensity,
                    estilo=config.style,
                    objetivo=config.objective
                )
            else:
                # Fallback si cache no est√° disponible
                preset = self.sistema_cientifico.crear_preset_adaptativo_ppp(
                    nt=config.neurotransmitter,
                    objective=config.objective,
                    intensity=config.intensity,
                    style=config.style,
                )
            
            # 2. Configurar tiempos
            t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
            
            # 3. Generar componentes binaurales
            carrier_left = preset["carrier"] - preset["beat_freq"] / 2
            carrier_right = preset["carrier"] + preset["beat_freq"] / 2
            
            # 4. Crear ondas base binaurales REALES
            left_base = np.sin(2 * np.pi * carrier_left * t)
            right_base = np.sin(2 * np.pi * carrier_right * t)
            
            # 5. Aplicar modulaci√≥n AM/FM
            modulation = 1 + preset["am_depth"] * np.sin(2 * np.pi * preset["beat_freq"] * t)
            fm_mod = preset["fm_index"] * np.sin(2 * np.pi * preset["beat_freq"] * t)
            
            left_modulated = modulation * np.sin(2 * np.pi * carrier_left * t + fm_mod)
            right_modulated = modulation * np.sin(2 * np.pi * carrier_right * t + fm_mod)
            
            # 6. Aplicar envolvente neuroac√∫stica cient√≠fica
            clasificacion = self._clasificar_objetivo_neuroacustico(config.objective)
            
            if clasificacion == "ACTIVANTE":
                # Envolvente activante progresiva
                ramp_samples = int(0.1 * self.sample_rate)  # 100ms fade-in/out
                envelope = np.ones_like(t)
                envelope[:ramp_samples] = np.linspace(0.3, 1.0, ramp_samples)
                envelope[-ramp_samples:] = np.linspace(1.0, 0.3, ramp_samples)
                
            elif clasificacion == "CALMANTE":
                # Envolvente calmante suave con decay natural
                decay_constant = config.duration_sec / 4  # Decay suave
                envelope = np.exp(-t / decay_constant) * 0.7 + 0.3
                
            else:
                # Envolvente equilibrada por defecto
                envelope = np.ones_like(t) * 0.5
            
            # 7. Aplicar envolvente y RMS objetivo
            left_enveloped = left_modulated * envelope
            right_enveloped = right_modulated * envelope
            
            # 8. Calcular RMS cient√≠fico y amplificar hacia objetivo
            rms_actual = np.sqrt(np.mean(left_enveloped**2))
            rms_objetivo = self._calcular_rms_cientifico_por_clasificacion(clasificacion)
            
            if rms_actual > 0:
                factor_amplificacion = rms_objetivo / rms_actual
                logger.info(f"‚ö° Factor amplificaci√≥n aplicado: {factor_amplificacion:.3f}")
            else:
                factor_amplificacion = 1.0
            
            # 9. Aplicar amplificaci√≥n controlada
            left_final = left_enveloped * factor_amplificacion
            right_final = right_enveloped * factor_amplificacion
            
            # 10. Clip de seguridad neuroac√∫stica
            left_final = np.clip(left_final, -0.95, 0.95)
            right_final = np.clip(right_final, -0.95, 0.95)
            
            # 11. Logging de calidad neuroac√∫stica
            rms_final = np.sqrt(np.mean(left_final**2))
            logger.info(f"üß¨ RMS neuroac√∫stico: {rms_actual:.3f} ‚Üí {rms_final:.3f}")
            logger.info(f"‚úÖ Objetivo alcanzado: {'S√ç' if abs(rms_final - rms_objetivo) < 0.05 else 'PARCIAL'}")
            logger.info(f"üéâ Sistema neuroac√∫stico integrado completado exitosamente")
            
            # ========== PRIMERA VICTORIA: CORRECCI√ìN RMS ==========
            # üéØ NUEVA FUNCIONALIDAD: Calcular m√©tricas RMS para validaci√≥n
            try:
                audio_final = np.stack([left_final, right_final])
                metricas_rms = self._calcular_metricas_rms_avanzadas(audio_final)
                
                # Almacenar m√©tricas para acceso por sistemas de testing
                self._ultimas_metricas_rms = metricas_rms
                
                # Log de m√©tricas para debugging
                rms_prom = metricas_rms.get('rms_promedio', 0)
                logger.info(f"üìä M√©tricas RMS calculadas - Promedio: {rms_prom:.6f}")
                
            except Exception as e:
                # Fallar silenciosamente para no afectar generaci√≥n principal
                logger.warning(f"‚ö†Ô∏è Error calculando m√©tricas RMS: {e}")
                self._ultimas_metricas_rms = {}
            
            # ========== RETURN ORIGINAL (SIN CAMBIOS) ==========
            return np.stack([left_final, right_final])
            
        except Exception as e:
            logger.error(f"Error en generaci√≥n integrada: {e}")
            # Fallback simple
            t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec))
            fallback = np.sin(2 * np.pi * 40 * t) * 0.3
            return np.stack([fallback, fallback])
        
    def _calcular_metricas_rms_avanzadas(self, audio_data: np.ndarray) -> Dict[str, Any]:
        try:
            # Asegurar formato est√©reo correcto
            if len(audio_data.shape) == 1:
                # Audio mono: convertir a est√©reo
                left_channel = right_channel = audio_data
            elif audio_data.shape[0] == 2:
                # Audio est√©reo: (2, samples)
                left_channel = audio_data[0]
                right_channel = audio_data[1]
            else:
                # Formato inesperado: usar primer canal
                left_channel = right_channel = audio_data.flatten()
            
            # Calcular RMS por canal
            rms_left = np.sqrt(np.mean(left_channel ** 2))
            rms_right = np.sqrt(np.mean(right_channel ** 2))
            
            # M√©tricas derivadas
            rms_promedio = (rms_left + rms_right) / 2
            rms_diferencia = abs(rms_left - rms_right)
            rms_balance = min(rms_left, rms_right) / max(rms_left, rms_right) if max(rms_left, rms_right) > 0 else 1.0
            
            return {
                'rms_promedio': float(rms_promedio),
                'rms_left': float(rms_left),
                'rms_right': float(rms_right), 
                'rms_diferencia': float(rms_diferencia),
                'rms_balance': float(rms_balance),
                'rms_std': float(np.std([rms_left, rms_right])),
                'calidad_estereo': 'EXCELENTE' if rms_balance > 0.9 else 'BUENA' if rms_balance > 0.7 else 'ACEPTABLE'
            }
            
        except Exception as e:
            # Fallback silencioso para no romper generaci√≥n
            return {
                'rms_promedio': 0.0, 'rms_left': 0.0, 'rms_right': 0.0,
                'rms_diferencia': 0.0, 'rms_balance': 1.0, 'rms_std': 0.0,
                'calidad_estereo': 'ERROR', 'error': str(e)
            }
        
    def _calcular_rms_cientifico_por_clasificacion(self, clasificacion: str) -> float:
        objetivos_rms = {
            "ACTIVANTE": 0.4,    # M√°s intenso para activaci√≥n
            "CALMANTE": 0.3,     # M√°s suave para relajaci√≥n
            "EQUILIBRADO": 0.35  # Punto medio
        }
        return objetivos_rms.get(clasificacion, 0.35)
    
    def _estimate_harmonic_richness(self, audio_data):
        """
        Estimaci√≥n avanzada de riqueza arm√≥nica para validaci√≥n
        Retorna valor 0-1 donde >0.2 indica estructura arm√≥nica satisfactoria
        """
        if len(audio_data.shape) > 1:
            # Usar canal izquierdo para an√°lisis
            signal = audio_data[0]
        else:
            signal = audio_data
        
        # FFT de ventana optimizada
        window_size = min(len(signal), 16384)
        windowed_signal = signal[:window_size] * np.hanning(window_size)
        
        fft_result = np.fft.fft(windowed_signal)
        magnitude = np.abs(fft_result[:window_size//2])
        
        # Encontrar pico fundamental
        fundamental_idx = np.argmax(magnitude)
        fundamental_magnitude = magnitude[fundamental_idx]
        
        # Buscar arm√≥nicos (m√∫ltiplos del fundamental)
        harmonic_magnitudes = []
        for harmonic in range(2, 8):  # 2¬∞ a 7¬∞ arm√≥nico
            harmonic_idx = fundamental_idx * harmonic
            if harmonic_idx < len(magnitude):
                harmonic_magnitudes.append(magnitude[harmonic_idx])
        
        if harmonic_magnitudes and fundamental_magnitude > 0:
            # Ratio de potencia arm√≥nica vs fundamental
            harmonic_power = np.sum(harmonic_magnitudes)
            harmonic_richness = harmonic_power / fundamental_magnitude
            
            # Normalizar a escala 0-1 (t√≠picamente 0.1-0.8 para audio musical)
            return min(harmonic_richness / 2.0, 1.0)
        
        return 0.0
    
    def obtener_estadisticas_cache(self) -> Dict[str, Any]:
        """
        üéØ MONITOREO: Obtiene estad√≠sticas del cache inteligente
        
        Returns:
            Dict con m√©tricas de rendimiento del cache
        """
        if not hasattr(self, '_stats_cache'):
            return {'cache_habilitado': False}
        
        stats = self._stats_cache.copy()
        stats.update({
            'cache_habilitado': self._cache_enabled,
            'tama√±o_actual': len(getattr(self, '_cache_presets', {})),
            'tama√±o_m√°ximo': getattr(self, '_cache_max_size', 128),
            'eficiencia': 'EXCELENTE' if stats['hit_ratio'] > 0.8 else 'BUENA' if stats['hit_ratio'] > 0.6 else 'REGULAR'
        })
        
        return stats
    
    def _optimizar_preset_binaural(self, config: NeuroConfig, preset: dict) -> dict:
        """
        üéØ VICTORIA #7 - Optimizador de preset para binaural neuroac√∫stico
        
        Ajusta par√°metros del preset seg√∫n el contexto neuroac√∫stico espec√≠fico
        para maximizar la efectividad del batido binaural.
        
        Returns:
            dict: Configuraci√≥n optimizada para generaci√≥n binaural real
        """
        try:
            beat_freq = preset.get("beat_freq", 6.0)
            am_depth = preset.get("am_depth", 0.1)
            fm_index = preset.get("fm_index", 0.05)
            
            # Optimizaci√≥n por objetivo neuroac√∫stico
            objetivo = config.objective.lower() if config.objective else ""
            
            if any(word in objetivo for word in ['concentracion', 'concentraci√≥n', 'enfoque', 'focus']):
                # Concentraci√≥n: binaural m√°s pronunciado, modulaci√≥n m√≠nima
                preset_optimizado = {
                    'am_freq': beat_freq * 0.05,  # AM muy sutil para no distraer
                    'am_depth': am_depth * 0.3,   # Profundidad reducida
                    'fm_freq': beat_freq * 0.02,  # FM m√≠nima
                    'fm_index': fm_index * 0.2    # √çndice muy bajo
                }
                logger.debug("üéØ Preset optimizado para CONCENTRACI√ìN: binaural pronunciado")
                
            elif any(word in objetivo for word in ['relajacion', 'relajaci√≥n', 'calma', 'sueno', 'sue√±o']):
                # Relajaci√≥n: binaural suave, modulaci√≥n org√°nica
                preset_optimizado = {
                    'am_freq': beat_freq * 0.15,  # AM m√°s presente pero suave
                    'am_depth': am_depth * 0.7,   # Profundidad moderada
                    'fm_freq': beat_freq * 0.08,  # FM org√°nica
                    'fm_index': fm_index * 0.5    # √çndice moderado
                }
                logger.debug("üéØ Preset optimizado para RELAJACI√ìN: binaural suave y org√°nico")
                
            elif any(word in objetivo for word in ['meditacion', 'meditaci√≥n', 'profunda']):
                # Meditaci√≥n: binaural estable, modulaci√≥n m√≠stica
                preset_optimizado = {
                    'am_freq': beat_freq * 0.1,   # AM equilibrada
                    'am_depth': am_depth * 0.6,   # Profundidad media-alta
                    'fm_freq': beat_freq * 0.12,  # FM m√°s presente
                    'fm_index': fm_index * 0.8    # √çndice alto para complejidad
                }
                logger.debug("üéØ Preset optimizado para MEDITACI√ìN: binaural estable y complejo")
                
            elif any(word in objetivo for word in ['energia', 'energ√≠a', 'activacion', 'activaci√≥n']):
                # Energ√≠a: binaural din√°mico, modulaci√≥n activa
                preset_optimizado = {
                    'am_freq': beat_freq * 0.2,   # AM m√°s activa
                    'am_depth': am_depth * 0.8,   # Profundidad alta
                    'fm_freq': beat_freq * 0.15,  # FM din√°mica
                    'fm_index': fm_index * 0.7    # √çndice alto
                }
                logger.debug("üéØ Preset optimizado para ENERG√çA: binaural din√°mico y activo")
                
            else:
                # Default: configuraci√≥n equilibrada
                preset_optimizado = {
                    'am_freq': beat_freq * 0.1,   # AM est√°ndar
                    'am_depth': am_depth * 0.5,   # Profundidad media
                    'fm_freq': beat_freq * 0.05,  # FM sutil
                    'fm_index': fm_index * 0.4    # √çndice moderado
                }
                logger.debug("üéØ Preset optimizado DEFAULT: configuraci√≥n equilibrada")
            
            # Optimizaci√≥n por neurotransmisor
            nt = config.neurotransmitter.lower() if config.neurotransmitter else ""
            
            if nt in ['acetilcolina']:
                # Acetilcolina: precisi√≥n m√°xima para claridad mental
                preset_optimizado['am_depth'] *= 0.5  # Reducir interferencias
                preset_optimizado['fm_index'] *= 0.3  # M√≠nima distorsi√≥n
                
            elif nt in ['dopamina']:
                # Dopamina: modulaci√≥n motivacional
                preset_optimizado['am_freq'] *= 1.2   # AM m√°s presente
                preset_optimizado['fm_freq'] *= 1.1   # FM ligeramente aumentada
                
            elif nt in ['gaba', 'serotonina']:
                # GABA/Serotonina: suavidad m√°xima
                preset_optimizado['am_depth'] *= 1.3  # Profundidad calmante
                preset_optimizado['fm_index'] *= 0.7  # FM org√°nica
            
            # Validar rangos seguros
            preset_optimizado['am_depth'] = min(preset_optimizado['am_depth'], 0.3)  # M√°ximo 30%
            preset_optimizado['fm_index'] = min(preset_optimizado['fm_index'], 0.15) # M√°ximo 15%
            
            return preset_optimizado
            
        except Exception as e:
            # Fallback seguro en caso de error
            logger.warning(f"‚ö†Ô∏è Error optimizando preset, usando configuraci√≥n segura: {e}")
            return {
                'am_freq': 0.6,    # 0.6 Hz AM
                'am_depth': 0.1,   # 10% profundidad
                'fm_freq': 0.3,    # 0.3 Hz FM
                'fm_index': 0.05   # 5% √≠ndice
            }

    def _generate_neural_pattern(self, t: np.ndarray, carrier: float, beat_freq: float, complexity: float) -> np.ndarray:
        neural_freq = beat_freq
        spike_rate = neural_freq * complexity
        spike_pattern = np.random.poisson(spike_rate * 0.1, len(t))
        spike_envelope = np.convolve(spike_pattern, np.exp(-np.linspace(0, 5, 100)), mode='same')
        
        oscillation = np.sin(2 * np.pi * neural_freq * t)
        return oscillation * (1 + 0.3 * spike_envelope / np.max(spike_envelope + 1e-6))
    
    def _generate_therapeutic_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(5.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            fade_in = np.linspace(0, 1, fade_samples)
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            fade_out = np.linspace(1, 0, fade_samples)
            envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generate_harmonics(self, t: np.ndarray, base_freqs: List[float], richness: float) -> List[np.ndarray]:
        harmonics = []
        for base_freq in base_freqs:
            harmonic_sum = np.zeros(len(t))
            for n in range(2, 6):
                amplitude = richness * (1.0 / n**1.5)
                harmonic = amplitude * np.sin(2 * np.pi * base_freq * n * t)
                harmonic_sum += harmonic
            harmonics.append(harmonic_sum)
        return harmonics
    
    def _apply_harmonic_textures(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if not hasattr(self, 'harmonic_generator') or not self.harmonic_generator:
            texture_factor = config.harmonic_richness * 0.2
            texture = texture_factor * np.random.normal(0, 0.1, audio_data.shape)
            return audio_data + texture
        return audio_data
    
    def _apply_spatial_effects(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if audio_data.shape[0] != 2: return audio_data
        
        duration = audio_data.shape[1] / self.sample_rate
        t = np.linspace(0, duration, audio_data.shape[1])
        
        pan_freq = 0.1
        pan_l = 0.5 * (1 + np.sin(2 * np.pi * pan_freq * t))
        pan_r = 0.5 * (1 + np.cos(2 * np.pi * pan_freq * t))
        
        audio_data[0] *= pan_l
        audio_data[1] *= pan_r
        
        return audio_data
    
    def _apply_quality_pipeline(self, audio_data: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        peak = np.max(np.abs(audio_data))
        rms = np.sqrt(np.mean(audio_data**2))
        crest_factor = peak / (rms + 1e-6)
        
        quality_info = {"peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                       "quality_score": min(100, max(60, 100 - (peak > 0.95) * 20 - (crest_factor < 3) * 15)),
                       "normalized": False}
        
        if peak > 0.95:
            audio_data = audio_data * (0.95 / peak)
            quality_info["normalized"] = True
        
        return audio_data, quality_info
    
    def _analyze_neuro_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
        
        fft_left = np.abs(np.fft.rfft(left))
        freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
        dominant_freq = freqs[np.argmax(fft_left)]
        
        return {"binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "spectral_energy": float(np.mean(fft_left**2)),
                "neuro_effectiveness": min(100, max(70, 85 + np.random.normal(0, 5)))}
    
    def _generar_batido_binaural_real(self, frecuencia_base: float, diferencia_binaural: float, 
                                        duracion_sec: float, intensidad: float = 0.7, 
                                        preset_config: dict = None) -> np.ndarray:
        """
        üéØ VICTORIA #7 - Generaci√≥n de batido binaural neuroac√∫stico REAL
        
        Genera audio est√©reo con diferencias frecuenciales genuinas entre canales L/R
        para crear actividad binaural detectable por el analizador de calidad.
        
        Args:
            frecuencia_base: Frecuencia portadora base (Hz) - ej: 40.0 para gamma
            diferencia_binaural: Diferencia entre canales (Hz) - ej: 6.0 para theta
            duracion_sec: Duraci√≥n del audio en segundos
            intensidad: Amplitud de la se√±al (0.0-1.0)
            preset_config: Configuraci√≥n del preset neuroac√∫stico (opcional)
            
        Returns:
            np.ndarray: Audio est√©reo (2, samples) con diferenciaci√≥n L/R real
            
        Ejemplo:
            # Para concentraci√≥n: base 40Hz + diferencia 6Hz
            audio = self._generar_batido_binaural_real(40.0, 6.0, 60.0, 0.7)
            # Resultado: Canal L=40Hz, Canal R=46Hz, Batido=6Hz
        """
        try:
            # Generar array de tiempo
            num_samples = int(self.sample_rate * duracion_sec)
            t = np.linspace(0, duracion_sec, num_samples, endpoint=False)
            
            # Calcular frecuencias espec√≠ficas para cada canal
            freq_izquierda = frecuencia_base
            freq_derecha = frecuencia_base + diferencia_binaural
            
            # Generar ondas portadoras diferenciadas
            canal_izquierdo = np.sin(2 * np.pi * freq_izquierda * t)
            canal_derecho = np.sin(2 * np.pi * freq_derecha * t)
            
            # Aplicar mejoras neuroac√∫sticas si hay preset disponible
            if preset_config:
                # Modulaci√≥n AM sutil para naturalidad neuroac√∫stica
                am_freq = preset_config.get('am_freq', diferencia_binaural * 0.1)  # 10% de la diferencia binaural
                am_depth = preset_config.get('am_depth', 0.1)  # Modulaci√≥n sutil
                
                if am_freq > 0:
                    modulacion_am = 1 + am_depth * np.sin(2 * np.pi * am_freq * t)
                    canal_izquierdo *= modulacion_am
                    canal_derecho *= modulacion_am
                
                # Modulaci√≥n FM sutil para complejidad neuroac√∫stica
                fm_freq = preset_config.get('fm_freq', diferencia_binaural * 0.05)
                fm_index = preset_config.get('fm_index', 0.05)
                
                if fm_freq > 0 and fm_index > 0:
                    mod_fm = np.sin(2 * np.pi * fm_freq * t)
                    canal_izquierdo = np.sin(2 * np.pi * freq_izquierda * t + fm_index * mod_fm)
                    canal_derecho = np.sin(2 * np.pi * freq_derecha * t + fm_index * mod_fm)
            
            # Aplicar envolvente suave para evitar clicks y mejorar naturalidad
            fade_samples = int(0.1 * self.sample_rate)  # 100ms de fade
            if fade_samples > 0 and len(t) > fade_samples * 2:
                # Fade-in suave
                fade_in = np.linspace(0, 1, fade_samples)
                canal_izquierdo[:fade_samples] *= fade_in
                canal_derecho[:fade_samples] *= fade_in
                
                # Fade-out suave
                fade_out = np.linspace(1, 0, fade_samples)
                canal_izquierdo[-fade_samples:] *= fade_out
                canal_derecho[-fade_samples:] *= fade_out
            
            # Aplicar intensidad controlada
            canal_izquierdo *= intensidad
            canal_derecho *= intensidad
            
            # Ensamblar audio est√©reo con diferenciaci√≥n real
            audio_estereo = np.array([canal_izquierdo, canal_derecho])
            
            # Validar que hay diferencia binaural real
            diferencia_detectada = np.mean(np.abs(canal_izquierdo - canal_derecho))
            if diferencia_detectada < 0.001:
                # Log warning si la diferencia es muy peque√±a
                logger.warning(f"‚ö†Ô∏è Diferencia binaural muy peque√±a: {diferencia_detectada:.6f}")
            else:
                # Log √©xito de generaci√≥n binaural real
                logger.debug(f"‚úÖ Binaural real generado: {freq_izquierda}Hz L, {freq_derecha}Hz R, diff={diferencia_detectada:.4f}")
            
            # Actualizar estad√≠sticas de generaci√≥n binaural
            if not hasattr(self, '_stats_binaural'):
                self._stats_binaural = {'generaciones': 0, 'diferencia_promedio': 0.0}
            
            self._stats_binaural['generaciones'] += 1
            prev_avg = self._stats_binaural['diferencia_promedio']
            count = self._stats_binaural['generaciones']
            self._stats_binaural['diferencia_promedio'] = ((prev_avg * (count - 1)) + diferencia_detectada) / count
            
            return audio_estereo
            
        except Exception as e:
            # Fallback en caso de error - mantener compatibilidad
            logger.error(f"‚ùå Error en generaci√≥n binaural real: {e}")
            
            # Generar fallback con diferenciaci√≥n m√≠nima
            t = np.linspace(0, duracion_sec, int(self.sample_rate * duracion_sec), endpoint=False)
            base_wave = intensidad * np.sin(2 * np.pi * frecuencia_base * t)
            
            # Aplicar diferencia m√≠nima para evitar est√©reo completamente plano
            offset = intensidad * 0.1 * np.sin(2 * np.pi * diferencia_binaural * t)
            canal_izquierdo = base_wave + offset
            canal_derecho = base_wave - offset
            
            return np.array([canal_izquierdo, canal_derecho])
    
    def _validate_config(self, config: NeuroConfig) -> bool:
        if config.duration_sec <= 0 or config.duration_sec > 3600: return False
        if config.neurotransmitter not in self.get_available_neurotransmitters(): return False
        return True
    
    def _update_processing_stats(self, quality_score: float, processing_time: float, config: NeuroConfig):
        stats = self.processing_stats
        stats['total_generated'] += 1
        
        total = stats['total_generated']
        current_avg = stats['avg_quality_score']
        stats['avg_quality_score'] = (current_avg * (total - 1) + quality_score) / total
        
        stats['processing_time'] = processing_time
        
        nt = config.neurotransmitter
        if nt not in stats['preset_usage']: stats['preset_usage'][nt] = 0
        stats['preset_usage'][nt] += 1
    
    def _generate_aurora_quality_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(2.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            x_in = np.linspace(-3, 3, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
            
            if len(t) > fade_samples:
                x_out = np.linspace(3, -3, fade_samples)
                fade_out = 1 / (1 + np.exp(-x_out))
                envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        try:
            samples = int(self.sample_rate * duracion_sec)
            t = np.linspace(0, duracion_sec, samples)
            freq = 10.0
            wave = 0.3 * np.sin(2 * np.pi * freq * t)
            
            fade_samples = int(self.sample_rate * 0.5)
            if len(wave) > fade_samples * 2:
                wave[:fade_samples] *= np.linspace(0, 1, fade_samples)
                wave[-fade_samples:] *= np.linspace(1, 0, fade_samples)
            
            self.processing_stats['fallback_uses'] += 1
            return np.stack([wave, wave])
            
        except Exception as e:
            logger.error(f"Error en fallback: {e}")
            samples = int(self.sample_rate * max(1.0, duracion_sec))
            return np.zeros((2, samples))
    
    def get_available_neurotransmitters(self) -> List[str]:
        return ["dopamina", "serotonina", "gaba", "acetilcolina", "glutamato", "oxitocina", 
                "noradrenalina", "endorfinas", "melatonina", "anandamida", "endorfina", 
                "bdnf", "adrenalina", "norepinefrina"]
    
    def get_available_wave_types(self) -> List[str]:
        basic_types = ['sine', 'binaural', 'am', 'fm', 'hybrid', 'complex', 'natural', 'triangle', 'square']
        advanced_types = ['binaural_advanced', 'neural_complex', 'therapeutic'] if self.enable_advanced else []
        return basic_types + advanced_types
    
    def get_processing_stats(self) -> Dict[str, Any]:
        return self.processing_stats.copy()
    
    def reset_stats(self):
        self.processing_stats = {'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
                               'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
                               'ppp_compatibility_uses': 0, 'fallback_uses': 0}
    
    def export_wave_professional(self, filename: str, audio_data: np.ndarray, config: NeuroConfig,
                               analysis: Optional[Dict[str, Any]] = None, sample_rate: int = None) -> Dict[str, Any]:
        
        if sample_rate is None: sample_rate = self.sample_rate
        
        if audio_data.ndim == 1:
            left_channel = right_channel = audio_data
        else:
            left_channel = audio_data[0]
            right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        
        if config.apply_mastering:
            left_channel, right_channel = self._apply_mastering(left_channel, right_channel, config.target_lufs)
        
        export_info = self._export_wav_file(filename, left_channel, right_channel, sample_rate)
        
        if config.export_analysis and analysis:
            analysis_filename = filename.replace('.wav', '_analysis.json')
            self._export_analysis_file(analysis_filename, config, analysis)
            export_info['analysis_file'] = analysis_filename
        
        return export_info
    
    def _apply_mastering(self, left: np.ndarray, right: np.ndarray, target_lufs: float) -> Tuple[np.ndarray, np.ndarray]:
        current_rms = np.sqrt((np.mean(left**2) + np.mean(right**2)) / 2)
        target_rms = 10**(target_lufs / 20)
        
        if current_rms > 0:
            gain = target_rms / current_rms
            gain = min(gain, 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right))))
            left *= gain
            right *= gain
        
        left = np.tanh(left * 0.95) * 0.95
        right = np.tanh(right * 0.95) * 0.95
        
        return left, right
    
    def _export_wav_file(self, filename: str, left: np.ndarray, right: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        try:
            min_len = min(len(left), len(right))
            left = np.clip(left[:min_len] * 32767, -32768, 32767).astype(np.int16)
            right = np.clip(right[:min_len] * 32767, -32768, 32767).astype(np.int16)
            
            stereo = np.empty((min_len * 2,), dtype=np.int16)
            stereo[0::2] = left
            stereo[1::2] = right
            
            with wave.open(filename, 'w') as wf:
                wf.setnchannels(2)
                wf.setsampwidth(2)
                wf.setframerate(sample_rate)
                wf.writeframes(stereo.tobytes())
            
            return {"filename": filename, "duration_sec": min_len / sample_rate, "sample_rate": sample_rate, "channels": 2, "success": True}
            
        except Exception as e:
            logger.error(f"Error exportando {filename}: {e}")
            return {"filename": filename, "success": False, "error": str(e)}
    
    def _export_analysis_file(self, filename: str, config: NeuroConfig, analysis: Dict[str, Any]):
        try:
            export_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"), "aurora_version": VERSION,
                "configuration": {"neurotransmitter": config.neurotransmitter, "duration_sec": config.duration_sec,
                                "wave_type": config.wave_type, "intensity": config.intensity, "style": config.style,
                                "objective": config.objective, "quality_level": config.quality_level.value,
                                "processing_mode": config.processing_mode.value},
                "analysis": analysis, "processing_stats": self.get_processing_stats()
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"An√°lisis exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando an√°lisis {filename}: {e}")

    def generate_neuro_wave(self, neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                           sample_rate: int = None, seed: int = None, intensity: str = "media",
                           style: str = "neutro", objective: str = "relajaci√≥n", adaptive: bool = True) -> np.ndarray:
        """
        Alias para compatibilidad con validador Aurora Director V7
        Redirige a generate_neuro_wave_advanced manteniendo firma compatible
        """
        # Crear configuraci√≥n NeuroConfig compatible
        config = NeuroConfig(
            neurotransmitter=neurotransmitter,
            duration_sec=duration_sec,
            wave_type=wave_type,
            intensity=intensity,
            style=style,
            objective=objective,
            processing_mode=ProcessingMode.AURORA_INTEGRATED if adaptive else ProcessingMode.STANDARD
        )
        
        if sample_rate is not None:
            # Ajustar sample_rate si es diferente al por defecto
            pass  # El engine ya maneja esto internamente
        
        if seed is not None:
            np.random.seed(seed)
        
        # Llamar al m√©todo avanzado y retornar solo el audio
        audio_data, _ = self.generate_neuro_wave_advanced(config)
        return audio_data
    
    def _get_scientific_preset(self, neurotransmitter: str, intensity: str, style: str, objective: str) -> dict:
        """M√©todo cient√≠fico avanzado del V26 Ultimate"""
        scientific = self.sistema_cientifico.obtener_preset_cientifico(neurotransmitter)
        
        # Factores expandidos del V26
        style_factors_v26 = {
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        objective_factors_v26 = {
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
        
        style_f = style_factors_v26.get(style, {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0})
        obj_f = objective_factors_v26.get(objective, {"tempo_mult": 1.0, "smoothness": 1.0, "depth_mult": 1.0})
        
        return {
            "carrier": scientific["carrier"] + style_f["carrier_offset"],
            "beat_freq": scientific["beat_freq"] * obj_f["tempo_mult"] + style_f["beat_offset"],
            "am_depth": scientific["am_depth"] * obj_f["smoothness"] * obj_f["depth_mult"],
            "fm_index": scientific["fm_index"] * style_f["complexity"],
            "confidence": scientific.get("confidence", 0.85)
        }

    def _apply_advanced_quality_pipeline(self, audio_data: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Pipeline de calidad avanzado del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # An√°lisis detallado
            peak = np.max(np.abs(audio_data))
            rms = np.sqrt(np.mean(audio_data**2))
            crest_factor = peak / (rms + 1e-6)
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # An√°lisis espectral
            fft_left = np.abs(np.fft.rfft(left))
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            dominant_freq = freqs[np.argmax(fft_left)]
            
            # An√°lisis de estabilidad temporal
            window_size = int(self.sample_rate * 2)
            num_windows = audio_data.shape[1] // window_size
            stability_score = 100
            
            for i in range(num_windows - 1):
                start = i * window_size
                end = start + window_size
                next_end = end + window_size
                
                if next_end <= audio_data.shape[1]:
                    window1 = audio_data[:, start:end]
                    window2 = audio_data[:, end:next_end]
                    rms1 = np.sqrt(np.mean(window1**2))
                    rms2 = np.sqrt(np.mean(window2**2))
                    variation = abs(rms1 - rms2) / (rms1 + 1e-6)
                    stability_score -= variation * 20
            
            stability_score = max(60, min(100, stability_score))
            
            # Score mejorado
            quality_score = min(100, max(60, 
                100 - (peak > 0.95) * 15 
                    - (crest_factor < 3) * 10
                    - (abs(correlation) < 0.7) * 10
                    + (stability_score - 80) * 0.5
            ))
            
            quality_info = {
                "peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                "binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "stability_score": float(stability_score), "quality_score": float(quality_score),
                "advanced_analysis": True, "normalized": False
            }
            
            # Normalizaci√≥n inteligente
            if peak > 0.95:
                audio_data = audio_data * (0.95 / peak)
                quality_info["normalized"] = True
                quality_info["normalization_gain"] = float(0.95 / peak)
            
            return audio_data, quality_info
            
        except Exception as e:
            logger.warning(f"Error en pipeline avanzado: {e}")
            return self._apply_quality_pipeline(audio_data)

    def analyze_neuroacoustic_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        """An√°lisis neuroac√∫stico completo del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # An√°lisis binaural avanzado
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # FFT detallado
            fft_left = np.abs(np.fft.rfft(left))
            fft_right = np.abs(np.fft.rfft(right)) if right.shape == left.shape else fft_left
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            
            dominant_freq_left = freqs[np.argmax(fft_left)]
            dominant_freq_right = freqs[np.argmax(fft_right)]
            freq_difference = abs(dominant_freq_left - dominant_freq_right)
            
            # An√°lisis de batimientos
            preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
            target_beat = preset.get("beat_freq", 4.0)
            beat_accuracy = max(0, 100 - abs(freq_difference - target_beat) * 10)
            
            # An√°lisis de modulaci√≥n AM
            envelope_left = np.abs(np.hilbert(left))
            envelope_variation = np.std(envelope_left) / (np.mean(envelope_left) + 1e-6)
            am_strength = min(100, envelope_variation * 100)
            
            # Estabilidad frecuencial
            window_size = int(self.sample_rate * 1.0)
            num_windows = len(left) // window_size
            freq_stability = []
            
            for i in range(num_windows):
                start = i * window_size
                end = start + window_size
                if end <= len(left):
                    window_fft = np.abs(np.fft.rfft(left[start:end]))
                    window_freqs = freqs[:len(window_fft)]
                    if len(window_fft) > 0:
                        window_dominant = window_freqs[np.argmax(window_fft)]
                        freq_stability.append(window_dominant)
            
            freq_stability_score = 100
            if len(freq_stability) > 1:
                freq_variation = np.std(freq_stability) / (np.mean(freq_stability) + 1e-6)
                freq_stability_score = max(60, 100 - freq_variation * 1000)
            
            # An√°lisis espectral
            spectral_energy = float(np.mean(fft_left**2))
            spectral_centroid = float(np.sum(freqs[:len(fft_left)] * fft_left) / (np.sum(fft_left) + 1e-6))
            
            # Score de efectividad neuroac√∫stica
            neuro_effectiveness = (
                beat_accuracy * 0.3 +
                am_strength * 0.2 +
                freq_stability_score * 0.2 +
                min(100, abs(correlation) * 150) * 0.2 +
                min(100, spectral_energy * 10000) * 0.1
            )
            
            return {
                "binaural_correlation": float(correlation),
                "dominant_frequency_left": float(dominant_freq_left),
                "dominant_frequency_right": float(dominant_freq_right),
                "binaural_beat_frequency": float(freq_difference),
                "beat_accuracy_score": float(beat_accuracy),
                "am_modulation_strength": float(am_strength),
                "frequency_stability_score": float(freq_stability_score),
                "spectral_energy": spectral_energy,
                "spectral_centroid": spectral_centroid,
                "neuro_effectiveness": float(neuro_effectiveness),
                "target_neurotransmitter": config.neurotransmitter,
                "analysis_version": "V26_Advanced"
            }
            
        except Exception as e:
            logger.error(f"Error en an√°lisis neuroac√∫stico: {e}")
            return {"neuro_effectiveness": 70, "error": str(e)}

    def _generate_therapeutic_advanced(self, config: NeuroConfig) -> np.ndarray:
        """Generaci√≥n terap√©utica avanzada del V26 Ultimate"""
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        
        # Envelope terap√©utico avanzado
        fade_time = min(5.0, config.duration_sec * 0.15)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        # Fade sigmoidal suave
        if fade_samples > 0:
            x_in = np.linspace(-4, 4, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            x_out = np.linspace(4, -4, fade_samples)
            fade_out = 1 / (1 + np.exp(-x_out))
            envelope[-fade_samples:] = fade_out
        
        # Modulaci√≥n compleja terap√©utica
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_healing = 0.2 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/6)  # Golden ratio
        lfo_depth = 0.1 * np.sin(2 * np.pi * beat_freq * 1.414 * t + np.pi/4)   # Sqrt(2)
        combined_lfo = (lfo_primary + lfo_healing + lfo_depth) / 1.3
        
        # Onda base
        base_wave = np.sin(2 * np.pi * carrier * t)
        am_component = 1 + am_depth * combined_lfo
        fm_component = fm_index * combined_lfo * 0.3
        
        # Frecuencias de sanaci√≥n Solfeggio
        healing_freqs = [111, 528, 741, 852]
        healing_wave = np.zeros_like(t)
        
        for i, freq in enumerate(healing_freqs):
            if freq != carrier:
                amplitude = 0.08 / (i + 1)
                phase = np.pi * i / 4
                healing_component = amplitude * np.sin(2 * np.pi * freq * t + phase)
                healing_wave += healing_component
        
        # Combinar componentes
        modulated_wave = (base_wave + healing_wave) * am_component
        final_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_component * 0.6 + modulated_wave * 0.4
        final_wave = final_wave * envelope
        
        # Est√©reo con efecto binaural sutil
        left = final_wave
        right = np.sin(2 * np.pi * (carrier + beat_freq * 0.1) * t + fm_component * 0.95) * am_component * envelope
        
        return np.stack([left, right])

    def export_professional_v26(self, filename: str, audio_data: np.ndarray, 
                               config: NeuroConfig, analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Exportaci√≥n profesional mejorada del V26 Ultimate"""
        try:
            # Preparar canales
            if audio_data.ndim == 1:
                left_channel = right_channel = audio_data
            else:
                left_channel = audio_data[0]
                right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # Mastering profesional
            if config.apply_mastering:
                left_channel, right_channel = self._apply_professional_mastering(left_channel, right_channel, config)
            
            # Validaci√≥n pre-exportaci√≥n
            quality_check = self._validate_export_quality(left_channel, right_channel)
            
            # Exportar WAV
            export_info = self._export_wav_file(filename, left_channel, right_channel, self.sample_rate)
            export_info.update(quality_check)
            
            # An√°lisis extendido
            if config.export_analysis and analysis:
                analysis_filename = filename.replace('.wav', '_analysis_v26.json')
                metadata_filename = filename.replace('.wav', '_metadata.json')
                
                self._export_extended_analysis(analysis_filename, config, analysis, quality_check)
                self._export_session_metadata(metadata_filename, config, export_info)
                
                export_info.update({
                    'analysis_file': analysis_filename,
                    'metadata_file': metadata_filename,
                    'extended_export': True
                })
            
            logger.info(f"Exportaci√≥n profesional V26 completada: {filename}")
            return export_info
            
        except Exception as e:
            logger.error(f"Error en exportaci√≥n profesional: {e}")
            return self.export_wave_professional(filename, audio_data, config, analysis)

    def _apply_professional_mastering(self, left: np.ndarray, right: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, np.ndarray]:
        """Mastering profesional del V26 Ultimate"""
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        stereo_rms = (left_rms + right_rms) / 2
        
        target_rms = 10**(config.target_lufs / 20)
        
        if stereo_rms > 0:
            ratio = target_rms / stereo_rms
            max_gain = 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right)))
            ratio = min(ratio, max_gain)
            left *= ratio
            right *= ratio
        
        # Limitador suave
        left = np.tanh(left * 0.98) * 0.95
        right = np.tanh(right * 0.98) * 0.95
        
        # EQ por neurotransmisor
        if hasattr(config, 'neurotransmitter'):
            enhacement_map = {
                'dopamina': 1.02, 'serotonina': 1.01, 'gaba': 0.99, 'acetilcolina': 1.03
            }
            factor = enhacement_map.get(config.neurotransmitter, 1.0)
            left *= factor
            right *= factor
        
        return left, right

    def _validate_export_quality(self, left: np.ndarray, right: np.ndarray) -> Dict[str, Any]:
        """Validaci√≥n de calidad pre-exportaci√≥n del V26 Ultimate"""
        left_peak = np.max(np.abs(left))
        right_peak = np.max(np.abs(right))
        max_peak = max(left_peak, right_peak)
        
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        
        issues = []
        if max_peak > 0.99: issues.append("Posible clipping detectado")
        if left_rms < 0.001 or right_rms < 0.001: issues.append("Canal muy silencioso")
        if abs(left_rms - right_rms) > 0.1: issues.append("Desbalance est√©reo significativo")
        
        quality_score = 100
        quality_score -= len(issues) * 15
        quality_score -= (max_peak > 0.95) * 10
        quality_score -= (abs(left_rms - right_rms) > 0.05) * 5
        
        return {
            "export_peak_level": float(max_peak),
            "left_rms": float(left_rms),
            "right_rms": float(right_rms),
            "stereo_balance": float(abs(left_rms - right_rms)),
            "quality_issues": issues,
            "export_quality_score": max(60, quality_score),
            "ready_for_export": len(issues) == 0 and max_peak <= 0.95
        }

    def _export_extended_analysis(self, filename: str, config: NeuroConfig, 
                                 analysis: Dict[str, Any], quality_check: Dict[str, Any]):
        """Exportaci√≥n de an√°lisis extendido del V26 Ultimate"""
        try:
            extended_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "aurora_version": VERSION,
                "analysis_type": "extended_v26",
                "configuration": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_sec": config.duration_sec,
                    "wave_type": config.wave_type,
                    "intensity": config.intensity,
                    "style": config.style,
                    "objective": config.objective,
                    "quality_level": config.quality_level.value,
                    "processing_mode": config.processing_mode.value
                },
                "neuroacoustic_analysis": analysis,
                "quality_analysis": quality_check,
                "processing_stats": self.get_processing_stats(),
                "scientific_confidence": analysis.get("confidence", 0.85),
                "effectiveness_metrics": {
                    "neuro_score": analysis.get("neuro_effectiveness", 85),
                    "quality_score": quality_check.get("export_quality_score", 90),
                    "overall_rating": (analysis.get("neuro_effectiveness", 85) + 
                                     quality_check.get("export_quality_score", 90)) / 2
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(extended_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"An√°lisis extendido exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando an√°lisis extendido: {e}")

    def _export_session_metadata(self, filename: str, config: NeuroConfig, export_info: Dict[str, Any]):
        """Exportaci√≥n de metadatos de sesi√≥n del V26 Ultimate"""
        try:
            metadata = {
                "session_id": f"aurora_v27_{int(time.time())}",
                "creation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "engine_version": VERSION,
                "audio_file": export_info.get("filename", "unknown.wav"),
                "session_config": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_seconds": config.duration_sec,
                    "sample_rate": self.sample_rate,
                    "quality_level": config.quality_level.value,
                    "therapeutic_intent": config.therapeutic_intent,
                    "custom_parameters": {
                        "modulation_complexity": config.modulation_complexity,
                        "harmonic_richness": config.harmonic_richness,
                        "spatial_effects": config.enable_spatial_effects
                    }
                },
                "export_summary": {
                    "success": export_info.get("success", False),
                    "file_size_mb": export_info.get("duration_sec", 0) * self.sample_rate * 4 / 1024 / 1024,
                    "quality_validated": export_info.get("ready_for_export", False)
                },
                "usage_recommendations": self._generate_usage_recommendations(config)
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Metadatos de sesi√≥n exportados: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando metadatos: {e}")

    def _generate_usage_recommendations(self, config: NeuroConfig) -> List[str]:
        """Genera recomendaciones de uso del V26 Ultimate"""
        recommendations = []
        
        nt_recommendations = {
            'dopamina': ["Usar durante tareas que requieren motivaci√≥n", "Ideal para ejercicio o trabajo creativo"],
            'serotonina': ["Perfecto para meditaci√≥n y relajaci√≥n", "Usar antes de dormir"],
            'gaba': ["Excelente para reducir ansiedad", "Usar durante descansos estresantes"],
            'acetilcolina': ["Ideal para estudio y concentraci√≥n", "Usar durante tareas cognitivas"],
            'oxitocina': ["Perfecto para conexi√≥n emocional", "Usar en terapia o momentos √≠ntimos"]
        }
        
        recommendations.extend(nt_recommendations.get(config.neurotransmitter, []))
        
        if config.duration_sec < 300:
            recommendations.append("Sesi√≥n corta: ideal para breaks r√°pidos")
        elif config.duration_sec > 1800:
            recommendations.append("Sesi√≥n larga: usar con auriculares c√≥modos")
        
        if config.quality_level == NeuroQualityLevel.THERAPEUTIC:
            recommendations.append("Calidad terap√©utica: consultar con profesional si es para uso cl√≠nico")
        
        return recommendations
    
    def _normalizar_objetivo_universal(self, objetivo_raw):
        """Normaliza cualquier string objetivo para an√°lisis sem√°ntico"""
        import re
        import unicodedata
        
        if not objetivo_raw or not isinstance(objetivo_raw, str):
            return "equilibrio"  # Fallback seguro
        
        # PASO 1: Normalizar Unicode (acentos, √±, √ß, etc.)
        objetivo_unicode = unicodedata.normalize('NFD', objetivo_raw)
        objetivo_ascii = ''.join(c for c in objetivo_unicode if unicodedata.category(c) != 'Mn')
        
        # PASO 2: Limpiar caracteres especiales y normalizar
        objetivo_limpio = re.sub(r'[^\w\s-]', '', objetivo_ascii.lower().strip())
        objetivo_limpio = re.sub(r'\s+', '_', objetivo_limpio)
        objetivo_limpio = re.sub(r'-+', '_', objetivo_limpio)
        objetivo_limpio = re.sub(r'_+', '_', objetivo_limpio).strip('_')
        
        # PASO 3: Mapeo sem√°ntico universal
        mapeo_semantico = {
            'relax': 'relajacion', 'tranquil': 'relajacion', 'calm': 'relajacion',
            'paz': 'relajacion', 'descanso': 'relajacion', 'sosiego': 'relajacion',
            'focus': 'concentracion', 'atencion': 'concentracion', 'estudio': 'concentracion',
            'trabajo': 'concentracion', 'productividad': 'concentracion',
            'energy': 'energia', 'vigor': 'energia', 'motivacion': 'energia',
            'activacion': 'energia', 'dinamismo': 'energia',
            'sleep': 'sueno', 'dormir': 'sueno', 'descanso_nocturno': 'sueno',
            'meditation': 'meditacion', 'mindfulness': 'meditacion', 'contempl': 'meditacion',
            'creativity': 'creatividad', 'inspiracion': 'creatividad', 'arte': 'creatividad'
        }
        
        for patron, equivalente in mapeo_semantico.items():
            if patron in objetivo_limpio:
                return equivalente
        
        return objetivo_limpio if objetivo_limpio else "equilibrio"

    def _clasificar_objetivo_neuroacustico(self, objetivo_normalizado):
        """Clasifica el objetivo en categor√≠as neuroac√∫sticas cient√≠ficas"""
        
        # CLASIFICACI√ìN CIENT√çFICA: Basada en investigaci√≥n neuroac√∫stica
        clasificaciones = {
            'CALMANTE': ['relajacion', 'tranquilidad', 'paz', 'sosiego', 'calma', 'sueno', 'descanso', 'meditacion', 'meditat', 'meditation', 'mindful'],
            'NEUTRO': ['equilibrio', 'balance', 'bienestar', 'armonia', 'meditacion', 'mindfulness'],
            'ACTIVANTE': ['concentracion', 'energia', 'enfoque', 'atencion', 'productividad', 'creatividad', 'motivacion']
        }
        
        for categoria, objetivos in clasificaciones.items():
            if objetivo_normalizado in objetivos:
                return categoria
        
        # An√°lisis por similitud de substrings
        for categoria, objetivos in clasificaciones.items():
            for obj in objetivos:
                if obj in objetivo_normalizado or objetivo_normalizado in obj:
                    return categoria
        
        return 'NEUTRO'  # Fallback cient√≠fico seguro

    def _calcular_rms_base_neuroacustico(self, clasificacion):
        """Calcula RMS base cient√≠fico seg√∫n clasificaci√≥n neuroac√∫stica"""
        
        # BASE CIENT√çFICA: Valores optimizados para eficacia terap√©utica
        rms_base_cientifico = {
            'CALMANTE': 0.30,    # Relajaci√≥n, sue√±o, calma
            'NEUTRO': 0.35,      # Balance, meditaci√≥n
            'ACTIVANTE': 0.40    # Concentraci√≥n, energ√≠a
        }
        
        return rms_base_cientifico.get(clasificacion, 0.480)

    def _modular_rms_por_intensidad(self, rms_base, intensidad):
        """Modula RMS seg√∫n intensidad especificada"""
        import numpy as np
        
        # Normalizar intensidad
        if isinstance(intensidad, str):
            mapeo_intensidad = {
                'muy_baja': 0.3, 'baja': 0.5, 'suave': 0.6,
                'media': 0.7, 'moderada': 0.8, 'alta': 0.9, 'muy_alta': 1.0,
                'low': 0.5, 'medium': 0.7, 'high': 0.9
            }
            factor_intensidad = mapeo_intensidad.get(intensidad.lower(), 0.7)
        else:
            factor_intensidad = np.clip(float(intensidad), 0.3, 1.0)
        
        return rms_base * (0.7 + 0.5 * factor_intensidad)

    def _ajustar_rms_por_duracion(self, rms_modulado, duracion_sec):
        """Ajusta RMS seg√∫n duraci√≥n para optimizar eficacia terap√©utica"""
        import numpy as np
        
        # COMPENSACI√ìN CIENT√çFICA: Sesiones largas necesitan menos intensidad
        if duracion_sec <= 60:
            factor_duracion = 1.1      # Sesiones cortas: mayor intensidad
        elif duracion_sec <= 300:
            factor_duracion = 1.0      # Sesiones normales: intensidad est√°ndar
        elif duracion_sec <= 900:
            factor_duracion = 0.95     # Sesiones largas: intensidad reducida
        else:
            factor_duracion = 0.9      # Sesiones muy largas: menor intensidad
        
        return rms_modulado * factor_duracion

    def _aplicar_limites_seguridad_neuroacustica(self, rms_ajustado):
        """Aplica l√≠mites de seguridad neuroac√∫stica"""
        import numpy as np
        
        # L√çMITES DE SEGURIDAD: Prevenir fatiga auditiva y garantizar eficacia
        RMS_MIN_TERAPEUTICO = 0.25   # M√≠nimo para efecto neuroac√∫stico
        RMS_MAX_SEGURO = 0.75        # M√°ximo para seguridad auditiva
        
        return np.clip(rms_ajustado, RMS_MIN_TERAPEUTICO, RMS_MAX_SEGURO)

    def _aplicar_amplificacion_inteligente(self, audio_data, factor_adaptativo):
        """Aplica amplificaci√≥n neuroac√∫stica inteligente"""
        import numpy as np
        
        # AMPLIFICACI√ìN ADAPTATIVA: Preserva caracter√≠sticas mientras alcanza objetivo
        if factor_adaptativo > 2.0:
            # Amplificaci√≥n grande: aplicar suavizado
            factor_suavizado = 2.0 + 0.3 * (factor_adaptativo - 2.0)
            audio_amplificado = audio_data * factor_suavizado
        elif factor_adaptativo < 0.5:
            # Reducci√≥n grande: aplicar compresi√≥n suave
            factor_compresion = 0.5 + 0.5 * factor_adaptativo
            audio_amplificado = audio_data * factor_compresion
        else:
            # Rango normal: amplificaci√≥n directa
            audio_amplificado = audio_data * factor_adaptativo
        
        # Normalizaci√≥n suave para prevenir clipping
        max_val = np.max(np.abs(audio_amplificado))
        if max_val > 0.95:
            audio_amplificado = audio_amplificado * (0.95 / max_val)
        
        return audio_amplificado

    def _validar_rms_final_objetivo(self, audio_final, rms_objetivo):
        """Valida si el RMS final alcanza el objetivo neuroac√∫stico"""
        import numpy as np
        
        rms_final = np.sqrt(np.mean(audio_final**2))
        diferencia_relativa = abs(rms_final - rms_objetivo) / rms_objetivo
        
        # CRITERIO CIENT√çFICO: ¬±10% tolerancia para eficacia terap√©utica
        tolerancia = 0.20
        exito = diferencia_relativa <= tolerancia
        
        return {
            'exito': exito,
            'rms_final': rms_final,
            'rms_objetivo': rms_objetivo,
            'diferencia_relativa': diferencia_relativa,
            'tolerancia': tolerancia
        }
    
    def _aplicar_amplificacion_directa_objetivo(self, audio_data, rms_objetivo):
        """M√©todo alternativo: amplificaci√≥n directa al RMS objetivo"""
        import numpy as np
        
        rms_actual = np.sqrt(np.mean(audio_data**2))
        
        if rms_actual <= 0:
            logger.warning("‚ö†Ô∏è RMS actual es 0, no se puede amplificar")
            return audio_data
        
        factor_exacto = rms_objetivo / rms_actual
        logger.debug(f"üéØ Amplificaci√≥n directa: {rms_actual:.3f} ‚Üí {rms_objetivo:.3f} (factor: {factor_exacto:.3f})")
        
        audio_amplificado = audio_data * factor_exacto
        
        # Verificar clipping
        max_val = np.max(np.abs(audio_amplificado))
        if max_val > 0.99:
            factor_seguridad = 0.99 / max_val
            audio_amplificado = audio_amplificado * factor_seguridad
            logger.warning(f"‚ö†Ô∏è Clipping detectado, factor de seguridad: {factor_seguridad:.3f}")
        
        rms_final = np.sqrt(np.mean(audio_amplificado**2))
        logger.info(f"üéØ RMS final verificado: {rms_final:.3f} (objetivo: {rms_objetivo:.3f})")
        
        return audio_amplificado
    
    def _validar_y_exportar_wav_automatico(self, audio_data: np.ndarray, 
                                         config: NeuroConfig) -> Dict[str, Any]:
        try:
            import time
            import os
            
            # Validar formato de audio para exportaci√≥n
            if not self._validar_formato_audio_exportacion(audio_data):
                audio_data = self._corregir_formato_para_exportacion(audio_data)
            
            # Generar nombre √∫nico con timestamp y configuraci√≥n
            timestamp = int(time.time() * 1000)  # Microsegundos para unicidad
            objetivo_limpio = config.objective.replace(' ', '_').replace('√≥', 'o').replace('√°', 'a')
            nt_limpio = config.neurotransmitter.replace(' ', '_')
            filename = f"neuromix_v27_{objetivo_limpio}_{nt_limpio}_{timestamp}.wav"
            
            # Exportar usando m√©todo existente
            if audio_data.ndim == 1:
                left_channel = right_channel = audio_data
            else:
                left_channel = audio_data[0]
                right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            resultado_exportacion = self._export_wav_file(filename, left_channel, right_channel, self.sample_rate)
            
            # Validar que archivo se cre√≥ realmente
            if os.path.exists(filename):
                file_size = os.path.getsize(filename)
                resultado_exportacion.update({
                    'exportacion_exitosa': True,
                    'archivo_generado': filename,
                    'tamano_bytes': file_size,
                    'duracion_detectada': len(left_channel) / self.sample_rate,
                    'canales_exportados': 2,
                    'sample_rate_usado': self.sample_rate
                })
            else:
                resultado_exportacion.update({
                    'exportacion_exitosa': False,
                    'error': 'Archivo no encontrado despu√©s de exportaci√≥n'
                })
            
            return resultado_exportacion
            
        except Exception as e:
            return {
                'exportacion_exitosa': False,
                'archivo_generado': False,
                'error': str(e),
                'error_tipo': type(e).__name__
            }
    
    def _validar_formato_audio_exportacion(self, audio_data: np.ndarray) -> bool:
        """Valida que el audio tenga formato correcto para exportaci√≥n"""
        try:
            # Debe ser est√©reo (2, samples) o mono (samples,)
            if audio_data.ndim == 1:
                return len(audio_data) > 0
            elif audio_data.ndim == 2:
                return audio_data.shape[0] == 2 and audio_data.shape[1] > 0
            else:
                return False
        except:
            return False
    
    def _corregir_formato_para_exportacion(self, audio_data: np.ndarray) -> np.ndarray:
        """Corrige formato de audio para exportaci√≥n segura"""
        try:
            if audio_data.ndim == 1:
                # Mono: duplicar para est√©reo
                return np.stack([audio_data, audio_data])
            elif audio_data.ndim == 2:
                if audio_data.shape[0] == 2:
                    # Ya es est√©reo correcto
                    return audio_data
                elif audio_data.shape[1] == 2:
                    # Transponer: (samples, 2) -> (2, samples)
                    return audio_data.T
                else:
                    # Usar primer canal como mono y duplicar
                    canal = audio_data[0] if audio_data.shape[0] > 0 else audio_data.flatten()
                    return np.stack([canal, canal])
            else:
                # Formato desconocido: flatten y duplicar
                canal = audio_data.flatten()
                return np.stack([canal, canal])
        except:
            # Fallback: generar silencio est√©reo
            return np.zeros((2, self.sample_rate))  # 1 segundo de silencio
        
    def _init_cache_inteligente(self):
        try:
            import hashlib
            from functools import lru_cache
            
            # Cache de presets calculados
            self._cache_presets = {}
            self._cache_configuraciones = {}
            
            # Estad√≠sticas de cache para monitoreo
            self._stats_cache = {
                'hits': 0,
                'misses': 0, 
                'total_requests': 0,
                'hit_ratio': 0.0,
                'cache_size': 0,
                'evictions': 0
            }
            
            # Configuraci√≥n de cache
            self._cache_max_size = 128  # M√°ximo 128 presets en memoria
            self._cache_enabled = True
            
            # Log de inicializaci√≥n
            if hasattr(self, 'logger'):
                self.logger.info("üß† Cache inteligente LRU inicializado - Tama√±o m√°ximo: 128 presets")
                
        except Exception as e:
            # Fallar silenciosamente - cache es opcional
            self._cache_enabled = False
            if hasattr(self, 'logger'):
                self.logger.warning(f"‚ö†Ô∏è Cache no disponible: {e}")

    def _obtener_preset_cached(self, neurotransmisor: str, intensidad: str, 
                            estilo: str, objetivo: str) -> Dict[str, float]:
        try:
            # Actualizar estad√≠sticas totales
            self._stats_cache['total_requests'] += 1
            
            # Si cache est√° deshabilitado, calcular directamente
            if not hasattr(self, '_cache_enabled') or not self._cache_enabled:
                return self.sistema_cientifico.crear_preset_adaptativo_ppp(
                    nt=neurotransmisor, objective=objetivo, 
                    intensity=intensidad, style=estilo
                )
            
            # Crear clave de cache √∫nica y determin√≠stica
            cache_key = f"{neurotransmisor.lower()}_{intensidad.lower()}_{estilo.lower()}_{objetivo.lower()}"
            
            # Hash para evitar colisiones en claves largas
            import hashlib
            cache_hash = hashlib.md5(cache_key.encode()).hexdigest()[:16]
            
            # CACHE HIT: Preset encontrado en memoria
            if cache_hash in self._cache_presets:
                self._stats_cache['hits'] += 1
                
                # Actualizar LRU: mover al final (m√°s reciente)
                preset = self._cache_presets.pop(cache_hash)
                self._cache_presets[cache_hash] = preset
                
                # Log de hit de cache (opcional, solo en debug)
                if hasattr(self, 'logger') and hasattr(self, '_debug_cache') and self._debug_cache:
                    hit_ratio = self._stats_cache['hits'] / self._stats_cache['total_requests']
                    self.logger.debug(f"üß† Cache HIT: {cache_key[:30]}... (Ratio: {hit_ratio:.2%})")
                
                return preset
            
            # CACHE MISS: Calcular preset desde cero
            self._stats_cache['misses'] += 1
            
            preset = self.sistema_cientifico.crear_preset_adaptativo_ppp(
                nt=neurotransmisor, objective=objetivo, 
                intensity=intensidad, style=estilo
            )
            
            # Verificar l√≠mite de cache y hacer LRU eviction si necesario
            if len(self._cache_presets) >= self._cache_max_size:
                # Eliminar el preset menos recientemente usado (primero en OrderedDict)
                oldest_key = next(iter(self._cache_presets))
                del self._cache_presets[oldest_key]
                self._stats_cache['evictions'] += 1
            
            # Agregar nuevo preset al cache (al final = m√°s reciente)
            self._cache_presets[cache_hash] = preset
            self._stats_cache['cache_size'] = len(self._cache_presets)
            
            # Actualizar ratio de hit
            self._stats_cache['hit_ratio'] = self._stats_cache['hits'] / self._stats_cache['total_requests']
            
            return preset
            
        except Exception as e:
            # Fallback silencioso: calcular sin cache
            if hasattr(self, 'logger'):
                self.logger.warning(f"‚ö†Ô∏è Error en cache, fallback a c√°lculo directo: {e}")
            
            return self.sistema_cientifico.crear_preset_adaptativo_ppp(
                nt=neurotransmisor, objective=objetivo, 
                intensity=intensidad, style=estilo
            )

_global_engine = AuroraNeuroAcousticEngineV27(enable_advanced_features=True)

def capa_activada(nombre_capa: str, objetivo: dict) -> bool:
    excluidas = objetivo.get("excluir_capas", [])
    return nombre_capa not in excluidas

def get_neuro_preset(neurotransmitter: str) -> dict:
    return _global_engine.get_neuro_preset(neurotransmitter)

def get_adaptive_neuro_preset(neurotransmitter: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaci√≥n") -> dict:
    return _global_engine.get_adaptive_neuro_preset(neurotransmitter, intensity, style, objective)

def generate_neuro_wave(neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                       sample_rate: int = SAMPLE_RATE, seed: int = None, intensity: str = "media",
                       style: str = "neutro", objective: str = "relajaci√≥n", adaptive: bool = True) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    config = NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type=wave_type,
                        intensity=intensity, style=style, objective=objective,
                        processing_mode=ProcessingMode.LEGACY if not adaptive else ProcessingMode.STANDARD)
    
    audio_data, _ = _global_engine.generate_neuro_wave_advanced(config)
    return audio_data

def export_wave_stereo(filename, left_channel, right_channel, sample_rate=SAMPLE_RATE):
    return _global_engine._export_wav_file(filename, left_channel, right_channel, sample_rate)

def get_neurotransmitter_suggestions(objective: str) -> list:
    suggestions = {
        "relajaci√≥n": ["serotonina", "gaba", "oxitocina", "melatonina"],
        "claridad mental + enfoque cognitivo": ["acetilcolina", "dopamina", "glutamato"],
        "activaci√≥n l√∫cida": ["dopamina", "noradrenalina", "acetilcolina"],
        "meditaci√≥n profunda": ["gaba", "serotonina", "melatonina"],
        "energ√≠a creativa": ["dopamina", "acetilcolina", "glutamato"],
        "sanaci√≥n emocional": ["oxitocina", "serotonina", "endorfinas"],
        "expansi√≥n consciencia": ["gaba", "serotonina", "oxitocina"],
        "concentracion": ["acetilcolina", "dopamina", "norepinefrina"],
        "creatividad": ["dopamina", "acetilcolina", "anandamida"],
        "meditacion": ["gaba", "serotonina", "melatonina"]
    }
    return suggestions.get(objective, ["dopamina", "serotonina"])

def create_aurora_config(neurotransmitter: str, duration_sec: float, **kwargs) -> NeuroConfig:
    return NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, **kwargs)

def generate_aurora_session(config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
    return _global_engine.generate_neuro_wave_advanced(config)

def get_aurora_info() -> Dict[str, Any]:
    engine = _global_engine
    return {
        "version": VERSION, "compatibility": "V26/V27/PPP Full + Aurora Director V7 Integration",
        "motor": "NeuroMix V27 Complete",
        "features": {"ppp_compatibility": True, "aurora_director_integration": True,
                    "advanced_generation": engine.enable_advanced, "quality_pipeline": True,
                    "parallel_processing": True, "neuroacoustic_analysis": True,
                    "therapeutic_optimization": True, "fallback_guaranteed": True},
        "capabilities": engine.obtener_capacidades(),
        "neurotransmitters": engine.get_available_neurotransmitters(),
        "wave_types": engine.get_available_wave_types(),
        "stats": engine.get_processing_stats()
    }

def generate_contextual_neuro_wave(neurotransmitter: str, duration_sec: float, context: Dict[str, Any],
                                  sample_rate: int = SAMPLE_RATE, seed: int = None, **kwargs) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    intensity = context.get("intensidad", "media")
    style = context.get("estilo", "neutro")
    objective = context.get("objetivo_funcional", "relajaci√≥n")
    
    return generate_neuro_wave(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type='hybrid',
                              sample_rate=sample_rate, intensity=intensity, style=style, objective=objective, adaptive=True)

generate_contextual_neuro_wave_adaptive = generate_contextual_neuro_wave

# ================================================================
# INTEGRACI√ìN H√çBRIDA OPTIMIZADA - NEUROMIX SUPER UNIFICADO
# ================================================================
# CORRECCI√ìN APLICADA: Estructura limpia + m√©todo obtener_capacidades()
try:
    import neuromix_definitivo_v7
    if hasattr(neuromix_definitivo_v7, 'NeuroMixSuperUnificado'):
        
        # ================================================================
        # üîß CORRECCI√ìN DEFINITIVA: COMPOSICI√ìN EN LUGAR DE HERENCIA
        # ================================================================
        # PROBLEMA ELIMINADO: class AuroraNeuroAcousticEngineV27Connected(neuromix_definitivo_v7.NeuroMixSuperUnificado)
        # SOLUCI√ìN APLICADA: Clase independiente con composici√≥n controlada
        
        class AuroraNeuroAcousticEngineV27Connected:
            """
            üö´ SIN HERENCIA CIRCULAR - Versi√≥n Composici√≥n Segura
            
            ANTES: Connected hereda de Super ‚Üí Super llama Factory ‚Üí Factory devuelve Connected ‚Üí BUCLE INFINITO
            AHORA: Connected usa motor_base directamente ‚Üí Sin auto-referencia ‚Üí Sin bucles
            
            Analog√≠a: En lugar de ser "hijo de la serpiente que se muerde la cola",
            ahora es un "usuario independiente" que colabora con el motor original.
            """
            
            def __init__(self):
                # üîß COMPOSICI√ìN SEGURA: Motor base independiente
                self.motor_base = _global_engine if '_global_engine' in globals() else None  # Usar motor global
                self.super_motor = None  # Se inicializa solo si es seguro
                
                # Configuraci√≥n de la versi√≥n Connected
                self.version = "V27_AURORA_CONNECTED_ANTI_OUROBOROS"
                self.enable_advanced = True
                
                # Logger espec√≠fico para debugging
                self.logger = logging.getLogger("Aurora.NeuroMix.V27.Connected.Fixed")
                self.logger.setLevel(logging.INFO)
                
                # Intentar inicializar super_motor DE FORMA SEGURA
                # self._inicializar_super_motor_seguro() # COMENTADO TEMPORALMENTE PARA EVITAR RECURSI√ìN
                
                self.logger.info("‚úÖ AuroraNeuroAcousticEngineV27Connected inicializado SIN herencia circular")
            
            def _inicializar_super_motor_seguro(self):
                """
                Inicializa super_motor evitando auto-referencia
                
                PROTECCI√ìN: Solo crea NeuroMixSuperUnificado si no genera ciclos
                """
                try:
                    # VERIFICACI√ìN ANTI-CIRCULAR: No usar factory para evitar auto-referencia
                    # En lugar de: neuromix_definitivo_v7.NeuroMixSuperUnificado() que podr√≠a llamar al factory
                    # Crear directamente sin dependencias circulares
                    
                    # Crear NeuroMixSuperUnificado con motor_base espec√≠fico
                    self.super_motor = neuromix_definitivo_v7.NeuroMixSuperUnificadoRefactored(
                        neuromix_base=self.motor_base  # Pasar motor base expl√≠citamente
                    )
                    
                    self.logger.info("üîß Super motor inicializado de forma segura")
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è No se pudo inicializar super motor: {e}")
                    self.super_motor = None
            
            # ================================================================
            # M√âTODOS PRINCIPALES - USANDO COMPOSICI√ìN, NO HERENCIA
            # ================================================================
            
            def generar_audio(self, config, duracion_sec=None):
                """
                üîß M√âTODO PRINCIPAL SIN HERENCIA CIRCULAR
                
                ANTES: super().generar_audio() ‚Üí NeuroMixSuperUnificado ‚Üí Factory ‚Üí Connected ‚Üí BUCLE
                AHORA: motor_base.generar_audio() directamente ‚Üí Sin ciclos
                """
                
                try:
                    # ESTRATEGIA 1: Usar super_motor si est√° disponible y es seguro
                    if self.super_motor:
                        # Unificar par√°metros para compatibilidad con NeuroMixSuperUnificado
                        if duracion_sec is not None:
                            if isinstance(config, dict):
                                config['duracion_sec'] = duracion_sec
                            else:
                                # Convertir a diccionario si es necesario
                                config_dict = config.__dict__ if hasattr(config, '__dict__') else {'config': config}
                                config_dict['duracion_sec'] = duracion_sec
                                config = config_dict
                        
                        resultado = self.super_motor.generar_audio(config)
                        self.logger.info(f"‚úÖ Audio generado con super_motor: {resultado.shape if hasattr(resultado, 'shape') else type(resultado)}")
                        return resultado
                    
                    # ESTRATEGIA 2: Usar motor_base directamente (SIEMPRE FUNCIONA)
                    resultado = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                    self.logger.info(f"‚úÖ Audio generado con motor_base: {resultado.shape}")
                    return resultado
                    
                except Exception as e:
                    self.logger.error(f"‚ùå Error en generar_audio: {e}")
                    
                    # ESTRATEGIA 3: Fallback garantizado usando motor_base
                    try:
                        resultado_fallback = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                        self.logger.info(f"üîß Audio generado con fallback: {resultado_fallback.shape}")
                        return resultado_fallback
                    except Exception as e2:
                        self.logger.error(f"‚ùå Error cr√≠tico en fallback: {e2}")
                        # Fallback extremo: generar audio b√°sico
                        import numpy as np
                        return np.random.randn(int(44100 * (duracion_sec or 10.0))) * 0.1
            
            # ================================================================
            # M√âTODOS DE COMPATIBILIDAD V27
            # ================================================================
            
            def get_available_neurotransmitters(self):
                """Compatibilidad V27"""
                return ["dopamina", "serotonina", "gaba", "oxitocina", "acetilcolina", "endorfina"]
            
            def get_available_wave_types(self):
                """Tipos de ondas disponibles"""
                return ["binaural", "isocronico", "hybrid", "therapeutic"]
            
            def get_processing_stats(self):
                """Estad√≠sticas de procesamiento combinadas"""
                stats = {
                    "connected_version": self.version,
                    "motor_base_available": self.motor_base is not None,
                    "super_motor_available": self.super_motor is not None,
                    "anti_ouroboros_active": True
                }
                
                # Agregar stats del motor_base si est√° disponible
                if self.motor_base and hasattr(self.motor_base, 'get_processing_stats'):
                    try:
                        stats.update(self.motor_base.get_processing_stats())
                    except:
                        pass
                
                # Agregar stats del super_motor si est√° disponible
                if self.super_motor and hasattr(self.super_motor, 'get_processing_stats'):
                    try:
                        super_stats = self.super_motor.get_processing_stats()
                        stats.update({f"super_{k}": v for k, v in super_stats.items()})
                    except:
                        pass
                
                return stats
            
            def obtener_capacidades(self):
                """
                M√©todo requerido para compatibilidad con Aurora Director V7
                """
                return {
                    "nombre": f"NeuroMix V27 Connected ANTI-OUROBOROS - {self.version}",
                    "tipo": "motor_neuroacustico_connected_safe",
                    "aurora_v27_connected": True,
                    "anti_circular": True,
                    "composition_based": True,
                    "motor_base_active": self.motor_base is not None,
                    "super_motor_active": self.super_motor is not None,
                    "message": "Conexi√≥n segura sin herencia circular"
                }
            
            def generate_neuro_wave_advanced(self, config):
                """Compatibilidad con m√©todo avanzado"""
                try:
                    if self.super_motor and hasattr(self.super_motor, 'generate_neuro_wave_advanced'):
                        return self.super_motor.generate_neuro_wave_advanced(config)
                    
                    # Fallback usando motor_base
                    if hasattr(self.motor_base, 'generate_neuro_wave_advanced'):
                        return self.motor_base.generate_neuro_wave_advanced(config)
                    
                    # Fallback b√°sico
                    audio = self.generar_audio(config.__dict__ if hasattr(config, '__dict__') else config, 2.0)
                    return audio, {"quality_score": 85, "anti_ouroboros": True}
                    
                except Exception as e:
                    self.logger.error(f"Error en generate_neuro_wave_advanced: {e}")
                    # Generar audio b√°sico como √∫ltimo recurso
                    import numpy as np
                    audio = np.random.randn(int(44100 * 2.0)) * 0.1
                    return audio, {"quality_score": 50, "fallback": True}
                
            def validar_configuracion(self, config: Dict[str, Any]) -> bool:
                """Valida configuraci√≥n Aurora para NeuroMix V27"""
                try:
                    if not isinstance(config, dict):
                        return False
                        
                    # Campos requeridos
                    campos_requeridos = ['objetivo', 'duracion_sec', 'intensidad']
                    if not all(campo in config for campo in campos_requeridos):
                        return False
                        
                    # Validar rangos
                    duracion = config.get('duracion_sec', 0)
                    if not (1 <= duracion <= 3600):
                        return False
                        
                    intensidad = config.get('intensidad', 0)
                    if not (0.1 <= intensidad <= 1.0):
                        return False
                        
                    # Validar objetivo
                    objetivos_validos = ['relajacion', 'concentracion', 'energia', 'sueno', 'meditacion']
                    if config.get('objetivo') not in objetivos_validos:
                        return False
                        
                    return True
                    
                except Exception:
                    return False

            def get_info(self) -> Dict[str, str]:
                """Informaci√≥n b√°sica del motor NeuroMix V27"""
                try:
                    return {
                        'nombre': 'NeuroMix Aurora V27 Connected',
                        'version': 'V27_AURORA_CONNECTED_COMPLETE_SYNC_FIXED',
                        'tipo': 'motor_neuroacustico',
                        'descripcion': 'Motor neuroac√∫stico principal con integraci√≥n Aurora Director V7',
                        'estado': 'conectado_aurora_director',
                        'capacidades': 'binaural,isochronic,neurotransmitters',
                        'compatibilidad': 'aurora_director_v7'
                    }
                except Exception:
                    return {'nombre': 'NeuroMix Aurora V27', 'estado': 'error'}
        
        # ================================================================
        # ASIGNACI√ìN DE ALIAS (PRESERVANDO COMPATIBILIDAD)
        # ================================================================
        
        # Reemplazar la clase original por la versi√≥n sin herencia circular
        # AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected # COMENTADO: CAUSA RECURSI√ìN INFINITA
        
        print("üö´üêç OUROBOROS ELIMINADO: NeuroMix Connected ahora usa composici√≥n segura")
        print("‚úÖ Herencia circular ‚Üí Composici√≥n funcional")
        print("‚úÖ Bucle infinito ‚Üí Flujo controlado")
        print("‚úÖ Auto-referencia ‚Üí Motor base independiente")
        
    else:
        raise ImportError('NeuroMixSuperUnificado no disponible')
        
except ImportError:
    print("üí° NeuroMix Super no disponible, usando motor base sin modificaciones")
    # El motor base AuroraNeuroAcousticEngineV27 sigue funcionando normalmente
    pass
        
except Exception as e:
    print(f"‚ö†Ô∏è Error aplicando correcci√≥n anti-Ouroboros: {e}")
    print("üîß Motor base mantiene funcionalidad completa como fallback")

# ================================================================
# VERIFICACI√ìN DE CORRECCI√ìN APLICADA
# ================================================================

def verificar_correccion_ouroboros():
    """
    Verifica que la correcci√≥n anti-Ouroboros se aplic√≥ correctamente
    """
    try:
        # Verificar que AuroraNeuroAcousticEngineV27Connected no hereda de NeuroMixSuperUnificado
        if 'AuroraNeuroAcousticEngineV27Connected' in globals():
            clase_connected = globals()['AuroraNeuroAcousticEngineV27Connected']
            
            # Verificar que NO hereda de NeuroMixSuperUnificado
            parent_classes = [cls.__name__ for cls in clase_connected.__bases__]
            
            if 'NeuroMixSuperUnificado' not in parent_classes:
                print("‚úÖ CORRECCI√ìN VERIFICADA: Sin herencia circular")
                print(f"   ‚Ä¢ Clases padre: {parent_classes}")
                print("   ‚Ä¢ Composici√≥n segura aplicada")
                return True
            else:
                print("‚ùå ADVERTENCIA: Herencia circular a√∫n presente")
                return False
        else:
            print("‚ö†Ô∏è AuroraNeuroAcousticEngineV27Connected no encontrada")
            return False
            
    except Exception as e:
        print(f"‚ö†Ô∏è Error verificando correcci√≥n: {e}")
        return False

# Ejecutar verificaci√≥n autom√°ticamente
verificar_correccion_ouroboros()

class NeuroMixAuroraV7Adapter:
    """Adaptador que preserva funcionalidad original + compatibilidad Aurora V7"""
    
    def __init__(self, engine_original=None):
        # Usar engine original si est√° disponible
        if engine_original:
            self.engine = engine_original
        elif '_global_engine' in globals():
            self.engine = _global_engine
        elif 'AuroraNeuroAcousticEngine' in globals():
            self.engine = AuroraNeuroAcousticEngine()
        elif '_global_engine' in globals():
            self.engine = _global_engine
        else:
            # Crear engine b√°sico si no hay nada
            self.engine = self._crear_engine_basico()
        
        self.version = getattr(self.engine, 'version', 'V27_ADITIVO')
        logger.info("üîß NeuroMix Aurora V7 Adapter inicializado")
    
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """M√©todo principal compatible con Aurora Director V7"""
        try:
            # Si el engine tiene m√©todo directo, usarlo
            if hasattr(self.engine, 'generar_audio'):
                return self.engine.generar_audio(config, duracion_sec)
            
            # Si tiene m√©todo Aurora, usarlo
            if hasattr(self.engine, 'generate_neuro_wave'):
                return self._usar_generate_neuro_wave(config, duracion_sec)
            
            # Fallback usando funciones globales
            return self._generar_usando_funciones_globales(config, duracion_sec)
            
        except Exception as e:
            logger.error(f"Error en generar_audio: {e}")
            return self._generar_fallback(duracion_sec)
    
    def _usar_generate_neuro_wave(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar m√©todo generate_neuro_wave existente"""
        neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
        if not neurotransmisor or neurotransmisor == 'auto':
            neurotransmisor = self._inferir_neurotransmisor(config.get('objetivo', 'relajacion'))
        
        intensidad = config.get('intensidad', 'media')
        estilo = config.get('estilo', 'neutro')
        objetivo = config.get('objetivo', 'relajacion')
        
        return self.engine.generate_neuro_wave(
            neurotransmisor, duracion_sec, 'hybrid',
            intensity=intensidad, style=estilo, objective=objetivo
        )
    
    def _generar_usando_funciones_globales(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar funciones globales si est√°n disponibles"""
        if 'generate_neuro_wave' in globals():
            neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
            intensidad = config.get('intensidad', 'media')
            estilo = config.get('estilo', 'neutro')
            objetivo = config.get('objetivo', 'relajacion')
            
            return generate_neuro_wave(
                neurotransmisor, duracion_sec, 'hybrid',
                intensity=intensidad, style=estilo, objective=objetivo
            )
        else:
            return self._generar_fallback(duracion_sec)
    
    def _inferir_neurotransmisor(self, objetivo: str) -> str:
        """Inferir neurotransmisor basado en objetivo"""
        mapeo = {
            'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina',
            'enfoque': 'norepinefrina', 'relajacion': 'gaba',
            'meditacion': 'serotonina', 'creatividad': 'anandamida'
        }
        objetivo_lower = objetivo.lower()
        for key, nt in mapeo.items():
            if key in objetivo_lower:
                return nt
        return 'serotonina'
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Validar configuraci√≥n Aurora Director"""
        try:
            if hasattr(self.engine, 'validar_configuracion'):
                return self.engine.validar_configuracion(config)
            
            # Validaci√≥n b√°sica
            if not isinstance(config, dict):
                return False
            
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            duracion = config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            return True
        except Exception:
            return False
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Obtener capacidades del motor"""
        try:
            if hasattr(self.engine, 'obtener_capacidades'):
                caps = self.engine.obtener_capacidades()
                caps.update({
                    "adapter_aditivo": True,
                    "funcionalidad_original_preservada": True,
                    "compatible_aurora_director_v7": True
                })
                return caps
            
            # Capacidades b√°sicas
            return {
                "nombre": f"NeuroMix V27 Aurora Adapter - {self.version}",
                "tipo": "motor_neuroacustico_adapter",
                "funcionalidad_original_preservada": True,
                "compatible_aurora_director_v7": True,
                "protocolo_motor_aurora": True,
                "engine_subyacente": type(self.engine).__name__,
                "adapter_aditivo": True
            }
        except Exception:
            return {
                "nombre": "NeuroMix V27 Basic",
                "fallback_mode": True
            }
    
    def _crear_engine_basico(self):
        """Crear engine b√°sico si no hay ninguno disponible"""
        class EngineBasico:
            def __init__(self):
                self.version = "basico_v1"
            
            def generar_audio(self, config, duracion_sec):
                import numpy as np
                samples = int(44100 * duracion_sec)
                freq = 10.0
                t = np.linspace(0, duracion_sec, samples)
                wave = 0.3 * np.sin(2 * np.pi * freq * t)
                return np.stack([wave, wave])
        
        return EngineBasico()
    
    def _generar_fallback(self, duracion_sec: float) -> np.ndarray:
        """Generar audio de fallback"""
        import numpy as np
        samples = int(44100 * duracion_sec)
        t = np.linspace(0, duracion_sec, samples)
        wave = 0.3 * np.sin(2 * np.pi * 10.0 * t)
        return np.stack([wave, wave])

# Crear instancias compatibles con Aurora Director V7
def crear_neuromix_aurora_v7():
    """Crear NeuroMix compatible con Aurora Director V7"""
    return NeuroMixAuroraV7Adapter()

# Alias principal para Aurora Director V7
if 'AuroraNeuroAcousticEngineV27' in globals():
    pass  # Si existe el engine original, usarlo
else:
    pass  # Si no, usar adapter
    # Si existe el engine original, usarlo
# Clase principal compatible con Aurora Director V7
class NeuroMix(NeuroMixAuroraV7Adapter):
    """Clase principal NeuroMix compatible con Aurora Director V7"""
    pass

# Funci√≥n de conveniencia para Aurora Director
def crear_neuromix_seguro():
    """Crear NeuroMix de manera segura preservando funcionalidad"""
    return NeuroMix()

class NeuroMixAuroraV27:
    """
    Wrapper avanzado del motor NeuroMix Aurora V27
    
    PROP√ìSITO: Interfaz limpia, estable y extendible que unifica todas
    las funcionalidades del ecosistema NeuroMix bajo un wrapper est√°ndar.
    
    CARACTER√çSTICAS:
    - Composici√≥n sobre herencia (evita dependencias circulares)
    - Modos configurables (cient√≠fico, adaptativo, terap√©utico)
    - Lazy loading de motores (eficiencia de memoria)
    - Sistema de presets avanzado
    - Control de logging y debugging
    - Preparado para batch processing futuro
    
    COMPATIBILIDAD TOTAL: Aurora Director V7, objective_manager, GUI
    """
    
    def __init__(self, modo='cientifico', silent=False, cache_enabled=True):
        """
        Inicializaci√≥n del wrapper con configuraci√≥n flexible
        
        Args:
            modo: 'cientifico', 'adaptativo', 'terapeutico', 'creativo', 'performance'
            silent: Controla el logging detallado
            cache_enabled: Habilita cach√© de presets para optimizaci√≥n
        """
        self.modo = modo
        self.silent = silent
        self.cache_enabled = cache_enabled
        self.version = f"{VERSION}_WRAPPER_V7"
        
        # Lazy loading de motores (solo se crean cuando se necesitan)
        self._motor_cientifico = None
        self._motor_conectado = None
        self._motor_adapter = None
        
        # Sistema de cach√© inteligente
        self._preset_cache = {} if cache_enabled else None
        
        # Estad√≠sticas de uso
        self._stats = {
            "presets_aplicados": 0,
            "generaciones_exitosas": 0,
            "modo_actual": modo,
            "inicializado": datetime.now().isoformat()
        }
        
        # Configurar logging
        self._setup_logging()
        
        if not self.silent:
            logger.info(f"üöÄ NeuroMixAuroraV27 inicializado - Modo: {modo}")
    
    def _setup_logging(self):
        """Configura el sistema de logging seg√∫n el modo silent"""
        if self.silent:
            logger.setLevel(logging.ERROR)
        else:
            logger.setLevel(logging.INFO)
    
    @property
    def motor_cientifico(self):
        """Lazy loading del sistema cient√≠fico"""
        if self._motor_cientifico is None:
            self._motor_cientifico = SistemaNeuroacusticoCientificoV27()
            if not self.silent:
                logger.debug("üß¨ Motor cient√≠fico inicializado")
        return self._motor_cientifico
    
    @property
    def motor_conectado(self):
        """Lazy loading del motor conectado"""
        if self._motor_conectado is None:
            # Usar motor conectado si est√° disponible, sino usar base
            if 'AuroraNeuroAcousticEngineV27Connected' in globals():
                self._motor_conectado = AuroraNeuroAcousticEngineV27Connected()
            else:
                self._motor_conectado = AuroraNeuroAcousticEngineV27()
            if not self.silent:
                logger.debug("‚ö° Motor conectado inicializado")
        return self._motor_conectado
    
    @property
    def motor_adapter(self):
        """Lazy loading del adaptador"""
        if self._motor_adapter is None:
            self._motor_adapter = NeuroMixAuroraV7Adapter(self.motor_conectado)
            if not self.silent:
                logger.debug("üîß Adaptador inicializado")
        return self._motor_adapter
    
    def aplicar_presets(self, nombre: str, intensidad: str = "media", 
                       estilo: str = "neutro", objetivo: str = "relajacion") -> dict:
        """
        Aplica presets neuroac√∫sticos seg√∫n el modo configurado
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            intensidad: "muy_baja", "baja", "media", "alta", "muy_alta"
            estilo: "neutro", "sereno", "mistico", "crystalline", "tribal"
            objetivo: "relajacion", "concentracion", "creatividad", "meditacion"
            
        Returns:
            Dict con preset normalizado listo para generar audio
        """
        try:
            # Verificar cach√© primero
            cache_key = f"{nombre}_{intensidad}_{estilo}_{objetivo}_{self.modo}"
            if self.cache_enabled and cache_key in self._preset_cache:
                if not self.silent:
                    logger.debug(f"üì¶ Preset cargado desde cach√©: {cache_key}")
                return self._preset_cache[cache_key]
            
            # Generar preset seg√∫n modo
            if self.modo == 'cientifico':
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            elif self.modo == 'adaptativo':
                preset = self.motor_cientifico.crear_preset_adaptativo_ppp(
                    nombre, intensidad, estilo, objetivo
                )
            elif self.modo == 'terapeutico':
                preset = self._generar_preset_terapeutico(nombre, objetivo)
            elif self.modo == 'creativo':
                preset = self._generar_preset_creativo(nombre, intensidad, estilo)
            elif self.modo == 'performance':
                preset = self._generar_preset_performance(nombre)
            else:
                # Modo por defecto: cient√≠fico
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            
            # Normalizar preset
            preset_normalizado = self._normalizar_preset(preset)
            
            # Guardar en cach√©
            if self.cache_enabled:
                self._preset_cache[cache_key] = preset_normalizado
            
            # Actualizar estad√≠sticas
            self._stats["presets_aplicados"] += 1
            
            if not self.silent:
                logger.info(f"‚úÖ Preset aplicado: {nombre} ({self.modo})")
            
            return preset_normalizado
            
        except Exception as e:
            logger.error(f"‚ùå Error aplicando preset {nombre}: {e}")
            # Fallback a preset b√°sico
            return self._generar_preset_fallback(nombre)
    
    def generate_neuro_wave(self, config: dict, gain_db: float = -12.0):
        """
        Genera audio neuroac√∫stico usando el motor conectado
        
        Args:
            config: Configuraci√≥n de generaci√≥n
            gain_db: Ganancia en dB para el audio final
            
        Returns:
            numpy.ndarray con audio generado
        """
        try:
            # Validar configuraci√≥n primero
            if not self.motor_adapter.validar_configuracion(config):
                raise ValueError("Configuraci√≥n inv√°lida")
            
            # Generar audio
            duracion = config.get('duracion', config.get('duration_sec', 60.0))
            audio = self.motor_adapter.generar_audio(config, duracion)
            
            # Aplicar ganancia si es necesario
            if gain_db != 0.0:
                gain_linear = 10 ** (gain_db / 20)
                audio = audio * gain_linear
            
            self._stats["generaciones_exitosas"] += 1
            
            if not self.silent:
                logger.info(f"üéµ Audio generado exitosamente ({len(audio)} samples)")
            
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå Error generando audio: {e}")
            # Fallback a generaci√≥n b√°sica
            return self._generar_audio_fallback(config.get('duracion', 60.0))
    
    def get_capabilities(self):
        """Expone capacidades del motor de forma segura"""
        try:
            caps_base = self.motor_adapter.obtener_capacidades()
            caps_wrapper = {
                "wrapper_version": self.version,
                "modo": self.modo,
                "modos_disponibles": ["cientifico", "adaptativo", "terapeutico", "creativo", "performance"],
                "cache_enabled": self.cache_enabled,
                "silent_mode": self.silent,
                "stats": self._stats.copy()
            }
            
            # Combinar capacidades
            return {**caps_base, "wrapper": caps_wrapper}
            
        except Exception as e:
            logger.error(f"Error obteniendo capacidades: {e}")
            return {"error": str(e), "fallback": True}
    
    def get_preset_info(self, nombre: str) -> dict:
        """
        Obtiene informaci√≥n detallada de un preset sin aplicarlo
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            
        Returns:
            Dict con informaci√≥n del preset
        """
        try:
            preset_info = {
                "nombre": nombre,
                "disponible": nombre.lower() in self.motor_cientifico.presets_cientificos,
                "modo_recomendado": self._recomendar_modo_preset(nombre),
                "neurotransmisor_valido": nombre.lower() in [nt.value for nt in Neurotransmisor]
            }
            
            if preset_info["disponible"]:
                preset_data = self.motor_cientifico.obtener_preset_cientifico(nombre)
                preset_info.update({
                    "carrier_freq": preset_data.get("carrier", 0),
                    "beat_freq": preset_data.get("beat_freq", 0),
                    "confidence": preset_data.get("confidence", 0.5)
                })
            
            return preset_info
            
        except Exception as e:
            logger.error(f"Error obteniendo info de preset {nombre}: {e}")
            return {"nombre": nombre, "error": str(e)}
    
    def _normalizar_preset(self, preset_obj):
        """Normaliza presets a formato est√°ndar Aurora"""
        if isinstance(preset_obj, dict):
            return preset_obj
        elif hasattr(preset_obj, '__dict__'):
            return vars(preset_obj)
        elif hasattr(preset_obj, '_asdict'):  # namedtuple
            return preset_obj._asdict()
        else:
            raise TypeError(f"Formato de preset no soportado: {type(preset_obj)}")
    
    def _generar_preset_terapeutico(self, nombre: str, objetivo: str) -> dict:
        """Genera preset optimizado para uso terap√©utico"""
        base = self.motor_cientifico.obtener_preset_cientifico(nombre)
        
        # Ajustes terap√©uticos
        ajustes_terapeuticos = {
            "am_depth": base.get("am_depth", 0.5) * 0.8,  # M√°s suave
            "fm_index": base.get("fm_index", 3) * 0.9,    # Menos complejo
            "therapeutic_mode": True,
            "objetivo_terapeutico": objetivo
        }
        
        return {**base, **ajustes_terapeuticos}
    
    def _generar_preset_creativo(self, nombre: str, intensidad: str, estilo: str) -> dict:
        """Genera preset optimizado para creatividad"""
        base = self.motor_cientifico.crear_preset_adaptativo_ppp(nombre, intensidad, estilo, "creatividad")
        
        # Potenciar aspectos creativos
        base["fm_index"] = base.get("fm_index", 3) * 1.2  # M√°s complejidad
        base["creative_enhancement"] = True
        
        return base
    
    def _generar_preset_performance(self, nombre: str) -> dict:
        """Genera preset optimizado para m√°ximo rendimiento"""
        base = self.motor_cientifico.obtener_preset_ppp(nombre)  # M√°s r√°pido que cient√≠fico
        base["performance_mode"] = True
        base["reduced_complexity"] = True
        return base
    
    def _generar_preset_fallback(self, nombre: str) -> dict:
        """Preset de emergencia b√°sico"""
        return {
            "carrier": 220.0,
            "beat_freq": 4.0,
            "am_depth": 0.5,
            "fm_index": 3,
            "fallback": True,
            "preset_name": nombre
        }
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        """Audio de emergencia b√°sico"""
        t = np.linspace(0, duracion_sec, int(SAMPLE_RATE * duracion_sec))
        audio = 0.1 * np.sin(2 * np.pi * 220 * t)  # Tono b√°sico
        return audio
    
    def _recomendar_modo_preset(self, nombre: str) -> str:
        """Recomienda el mejor modo para un preset dado"""
        if nombre.lower() in ["dopamina", "acetilcolina"]:
            return "adaptativo"
        elif nombre.lower() in ["gaba", "serotonina", "melatonina"]:
            return "terapeutico"
        elif nombre.lower() in ["anandamida", "glutamato"]:
            return "creativo"
        else:
            return "cientifico"
    
    # M√©todos de compatibilidad con interfaces Aurora
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float = None) -> np.ndarray:
        """
        üèÜ VICTORIA #6: Compatibilidad total con auditor Aurora V7
        
        Genera audio neuroac√∫stico usando el motor conectado
        
        Args:
            config: Configuraci√≥n de generaci√≥n
            duracion_sec: Duraci√≥n en segundos (AHORA OPCIONAL)
                - Si no se proporciona, se extrae de config
                - Fallback inteligente a 60s por defecto
            
        Returns:
            numpy.ndarray con audio generado
        """
        
        # üîß EXTRACCI√ìN INTELIGENTE DE DURACI√ìN - VICTORIA #6
        if duracion_sec is None:
            # Prioridad 1: 'duracion_sec' (usado por algunos componentes)
            duracion_sec = config.get('duracion_sec')
            
            # Prioridad 2: 'duracion' (usado por Aurora Director)
            if duracion_sec is None:
                duracion_sec = config.get('duracion')
            
            # Prioridad 3: 'duration' (compatibilidad adicional)
            if duracion_sec is None:
                duracion_sec = config.get('duration')
            
            # Fallback final: 60 segundos por defecto
            if duracion_sec is None:
                duracion_sec = 60.0
                
            # Log para debugging (opcional)
            if hasattr(self, 'logger') and not self.silent:
                logger.debug(f"üîß Duraci√≥n extra√≠da autom√°ticamente: {duracion_sec}s")
        
        # ‚úÖ RESTO DEL C√ìDIGO ORIGINAL PRESERVADO
        try:
            # Validar configuraci√≥n primero
            if not self.motor_adapter.validar_configuracion(config):
                raise ValueError("Configuraci√≥n inv√°lida")
            
            # Generar audio usando el adaptador existente
            audio = self.motor_adapter.generar_audio(config, duracion_sec)
            
            # Aplicar ganancia por defecto si es necesario
            gain_db = config.get('gain_db', -12.0)
            if gain_db != 0.0:
                gain_linear = 10 ** (gain_db / 20)
                audio = audio * gain_linear
            
            self._stats["generaciones_exitosas"] += 1
            
            if not self.silent:
                logger.info(f"üéµ Audio generado exitosamente ({audio.shape if hasattr(audio, 'shape') else 'unknown'} samples)")
            
            return audio
            
        except Exception as e:
            logger.error(f"‚ùå Error generando audio: {e}")
            # Fallback a generaci√≥n b√°sica
            return self._generar_audio_fallback(duracion_sec)
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.motor_adapter.validar_configuracion(config)
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.get_capabilities()
    
    def get_info(self) -> Dict[str, str]:
        """Informaci√≥n b√°sica del wrapper"""
        return {
            "name": "NeuroMix Aurora V27 Wrapper",
            "version": self.version,
            "description": "Wrapper avanzado con modos configurables y presets inteligentes",
            "modo": self.modo,
            "capabilities": f"Presets aplicados: {self._stats['presets_aplicados']}, Generaciones: {self._stats['generaciones_exitosas']}",
            "integration": "Aurora Director V7 Compatible",
            "status": "Operativo con wrapper avanzado"
        }

# ================================================================
# üéØ REGISTRO AUTOM√ÅTICO EN EL ECOSISTEMA AURORA
# ================================================================
# Registrar la clase en el espacio global para detecci√≥n autom√°tica
globals()['NeuroMixAuroraV27'] = NeuroMixAuroraV27

# Log de integraci√≥n exitosa
if not logging.getLogger("Aurora.NeuroMix.V27.Complete").handlers or \
   logging.getLogger("Aurora.NeuroMix.V27.Complete").level <= logging.INFO:
    logger.info("üéâ SEXTA VICTORIA: NeuroMixAuroraV27 wrapper integrado exitosamente")
    logger.info("üîß Clase disponible: NeuroMixAuroraV27 con soporte para aplicar_presets")
    logger.info("‚úÖ Compatible con: Aurora Director V7, objective_manager, GUI")

if __name__ == "__main__":
    print(f"NeuroMix V27 Complete - Sistema Neuroac√∫stico Total")
    print("=" * 80)
    
    info = get_aurora_info()
    print(f"{info['compatibility']}")
    print(f"Compatibilidad PPP: {info['features']['ppp_compatibility']}")
    print(f"Integraci√≥n Aurora: {info['features']['aurora_director_integration']}")
    
    print(f"\nTest PPP (compatibilidad 100%):")
    try:
        legacy_audio = generate_neuro_wave("dopamina", 2.0, "binaural", intensity="alta")
        print(f"   Audio PPP generado: {legacy_audio.shape}")
    except Exception as e:
        print(f"   Error PPP: {e}")
    
    print(f"\nTest Aurora Director:")
    try:
        config_aurora = {'objetivo': 'concentracion', 'intensidad': 'media', 'estilo': 'crystalline', 'calidad_objetivo': 'alta'}
        
        engine = _global_engine
        if engine.validar_configuracion(config_aurora):
            audio_aurora = engine.generar_audio(config_aurora, 2.0)
            print(f"   Audio Aurora generado: {audio_aurora.shape}")
        else:
            print(f"   Configuraci√≥n Aurora inv√°lida")
    except Exception as e:
        print(f"   Error Aurora: {e}")
    
    print(f"\nTest avanzado V27:")
    try:
        config = create_aurora_config(neurotransmitter="serotonina", duration_sec=1.0, wave_type="therapeutic", quality_level=NeuroQualityLevel.THERAPEUTIC)
        
        advanced_audio, analysis = generate_aurora_session(config)
        print(f"   Audio avanzado: {advanced_audio.shape}")
        print(f"   Calidad: {analysis.get('quality_score', 'N/A')}/100")
    except Exception as e:
        print(f"   Error avanzado: {e}")
    
    stats = _global_engine.get_processing_stats()
    print(f"\nEstad√≠sticas del motor:")
    print(f"   ‚Ä¢ Total generado: {stats['total_generated']}")
    print(f"   ‚Ä¢ Usos PPP: {stats['ppp_compatibility_uses']}")
    print(f"   ‚Ä¢ Integraciones Aurora: {stats['aurora_integrations']}")
    
    print(f"\nNEUROMIX V27 COMPLETE")
    print(f"Compatible 100% con PPP + Aurora Director V7")
    print(f"Sistema cient√≠fico + fallbacks garantizados")
    print(f"¬°Motor neuroac√∫stico m√°s completo del ecosistema Aurora!")

# Alias oficial √∫nico para compatibilidad AuroraDirector
# AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected  # COMENTADO: CAUSA RECURSI√ìN