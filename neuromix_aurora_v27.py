# âœ… Archivo hÃ­brido: NeuroMix V27 con fallback inteligente
# - Usa 'NeuroMixSuperUnificado' si estÃ¡ disponible
# - Si no, funciona como motor base autÃ³nomo


# PARCHE ADITIVO AURORA DIRECTOR V7 - Imports adicionales
import logging
from typing import Dict, Any, Protocol

# Configurar logging si no estÃ¡ configurado
if not logging.getLogger().handlers:
    logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Aurora.NeuroMix.V27.Aditivo")

import wave
import numpy as np
import json
import time
import logging
import warnings
from typing import Dict, Tuple, Optional, List, Any, Union, Protocol, Callable
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
from functools import lru_cache

SAMPLE_RATE = 44100
VERSION = "V27_AURORA_CONNECTED_PPP_COMPLETE"
CONFIDENCE_THRESHOLD = 0.8
logger = logging.getLogger("Aurora.NeuroMix.V27.Complete")
logger.setLevel(logging.INFO)

class MotorAurora(Protocol):
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray: ...
    def validar_configuracion(self, config: Dict[str, Any]) -> bool: ...
    def obtener_capacidades(self) -> Dict[str, Any]: ...

class Neurotransmisor(Enum):
    DOPAMINA = "dopamina"
    SEROTONINA = "serotonina"
    GABA = "gaba"
    OXITOCINA = "oxitocina"
    ANANDAMIDA = "anandamida"
    ACETILCOLINA = "acetilcolina"
    ENDORFINA = "endorfina"
    BDNF = "bdnf"
    ADRENALINA = "adrenalina"
    NOREPINEFRINA = "norepinefrina"
    MELATONINA = "melatonina"
    GLUTAMATO = "glutamato"
    NORADRENALINA = "noradrenalina"
    ENDORFINAS = "endorfinas"

class EstadoEmocional(Enum):
    ENFOQUE = "enfoque"
    RELAJACION = "relajacion"
    GRATITUD = "gratitud"
    VISUALIZACION = "visualizacion"
    SOLTAR = "soltar"
    ACCION = "accion"
    CLARIDAD_MENTAL = "claridad_mental"
    SEGURIDAD_INTERIOR = "seguridad_interior"
    APERTURA_CORAZON = "apertura_corazon"
    ALEGRIA_SOSTENIDA = "alegria_sostenida"
    FUERZA_TRIBAL = "fuerza_tribal"
    CONEXION_MISTICA = "conexion_mistica"
    REGULACION_EMOCIONAL = "regulacion_emocional"
    EXPANSION_CREATIVA = "expansion_creativa"
    ESTADO_FLUJO = "estado_flujo"
    INTROSPECCION_SUAVE = "introspeccion_suave"
    SANACION_PROFUNDA = "sanacion_profunda"
    EQUILIBRIO_MENTAL = "equilibrio_mental"

class NeuroQualityLevel(Enum):
    BASIC = "bÃ¡sico"
    ENHANCED = "mejorado"
    PROFESSIONAL = "profesional"
    THERAPEUTIC = "terapÃ©utico"
    RESEARCH = "investigaciÃ³n"

class ProcessingMode(Enum):
    LEGACY = "legacy"
    STANDARD = "standard"
    ADVANCED = "advanced"
    PARALLEL = "parallel"
    REALTIME = "realtime"
    AURORA_INTEGRATED = "aurora_integrated"

@dataclass
class NeuroConfig:
    neurotransmitter: str
    duration_sec: float
    wave_type: str = 'hybrid'
    intensity: str = "media"
    style: str = "neutro"
    objective: str = "relajaciÃ³n"
    quality_level: NeuroQualityLevel = NeuroQualityLevel.ENHANCED
    processing_mode: ProcessingMode = ProcessingMode.STANDARD
    enable_quality_pipeline: bool = True
    enable_analysis: bool = True
    enable_textures: bool = True
    enable_spatial_effects: bool = False
    custom_frequencies: Optional[List[float]] = None
    modulation_complexity: float = 1.0
    harmonic_richness: float = 0.5
    therapeutic_intent: Optional[str] = None
    apply_mastering: bool = True
    target_lufs: float = -23.0
    export_analysis: bool = False
    aurora_config: Optional[Dict[str, Any]] = None
    director_context: Optional[Dict[str, Any]] = None
    use_scientific_data: bool = True

class SistemaNeuroacusticoCientificoV27:
    def __init__(self):
        self.version = "v27_aurora_scientific_ppp"
        self._init_data()
    
    def _init_data(self):
        self.presets_ppp = {
            "dopamina": {"carrier": 123.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4},
            "serotonina": {"carrier": 111.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3},
            "gaba": {"carrier": 90.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2},
            "acetilcolina": {"carrier": 105.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3},
            "glutamato": {"carrier": 140.0, "beat_freq": 5.0, "am_depth": 0.6, "fm_index": 5},
            "oxitocina": {"carrier": 128.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2},
            "noradrenalina": {"carrier": 135.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5},
            "endorfinas": {"carrier": 98.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2},
            "melatonina": {"carrier": 85.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1}
        }
        
        self.presets_cientificos = {
            "dopamina": {"carrier": 396.0, "beat_freq": 6.5, "am_depth": 0.7, "fm_index": 4, "confidence": 0.94},
            "serotonina": {"carrier": 417.0, "beat_freq": 3.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.92},
            "gaba": {"carrier": 72.0, "beat_freq": 2.0, "am_depth": 0.3, "fm_index": 2, "confidence": 0.95},
            "acetilcolina": {"carrier": 320.0, "beat_freq": 4.0, "am_depth": 0.4, "fm_index": 3, "confidence": 0.89},
            "oxitocina": {"carrier": 528.0, "beat_freq": 2.8, "am_depth": 0.4, "fm_index": 2, "confidence": 0.90},
            "anandamida": {"carrier": 111.0, "beat_freq": 2.5, "am_depth": 0.4, "fm_index": 2, "confidence": 0.82},
            "endorfina": {"carrier": 528.0, "beat_freq": 1.5, "am_depth": 0.3, "fm_index": 2, "confidence": 0.87},
            "bdnf": {"carrier": 285.0, "beat_freq": 4.0, "am_depth": 0.5, "fm_index": 3, "confidence": 0.88},
            "adrenalina": {"carrier": 741.0, "beat_freq": 8.0, "am_depth": 0.9, "fm_index": 6, "confidence": 0.91},
            "norepinefrina": {"carrier": 693.0, "beat_freq": 7.0, "am_depth": 0.8, "fm_index": 5, "confidence": 0.91},
            "melatonina": {"carrier": 108.0, "beat_freq": 1.0, "am_depth": 0.2, "fm_index": 1, "confidence": 0.93}
        }
        
        self.presets_cientificos["glutamato"] = self.presets_cientificos["dopamina"].copy()
        self.presets_cientificos["noradrenalina"] = self.presets_cientificos["norepinefrina"].copy()
        self.presets_cientificos["endorfinas"] = self.presets_cientificos["endorfina"].copy()
        
        self.intensity_factors_ppp = {
            "muy_baja": {"carrier_mult": 0.6, "beat_mult": 0.5, "am_mult": 0.4, "fm_mult": 0.5},
            "baja": {"carrier_mult": 0.8, "beat_mult": 0.7, "am_mult": 0.6, "fm_mult": 0.7},
            "media": {"carrier_mult": 1.0, "beat_mult": 1.0, "am_mult": 1.0, "fm_mult": 1.0},
            "alta": {"carrier_mult": 1.2, "beat_mult": 1.3, "am_mult": 1.4, "fm_mult": 1.3},
            "muy_alta": {"carrier_mult": 1.4, "beat_mult": 1.6, "am_mult": 1.7, "fm_mult": 1.5}
        }
        
        self.style_factors_ppp = {
            "neutro": {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0},
            "alienigena": {"carrier_offset": 15, "beat_offset": 1.5, "complexity": 1.3},
            "minimal": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.7},
            "organico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.1},
            "cinematico": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.4},
            "ancestral": {"carrier_offset": -15, "beat_offset": -0.8, "complexity": 0.8},
            "futurista": {"carrier_offset": 25, "beat_offset": 2.0, "complexity": 1.6},
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        self.objective_factors_ppp = {
            "relajaciÃ³n": {"tempo_mult": 0.8, "smoothness": 1.2, "depth_mult": 1.1},
            "claridad mental + enfoque cognitivo": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "activaciÃ³n lÃºcida": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.0},
            "meditaciÃ³n profunda": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3},
            "energÃ­a creativa": {"tempo_mult": 1.3, "smoothness": 0.8, "depth_mult": 1.2},
            "sanaciÃ³n emocional": {"tempo_mult": 0.7, "smoothness": 1.4, "depth_mult": 1.2},
            "expansiÃ³n consciencia": {"tempo_mult": 0.5, "smoothness": 1.6, "depth_mult": 1.4},
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
    
    def obtener_preset_ppp(self, nt: str) -> Dict[str, Any]:
        return self.presets_ppp.get(nt.lower(), {"carrier": 123.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4})
    
    def obtener_preset_cientifico(self, nt: str) -> Dict[str, Any]:
        return self.presets_cientificos.get(nt.lower(), {"carrier": 220.0, "beat_freq": 4.5, "am_depth": 0.5, "fm_index": 4, "confidence": 0.8})
    
    def crear_preset_adaptativo_ppp(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaciÃ³n") -> Dict[str, Any]:
        base = self.obtener_preset_ppp(nt)
        i_f = self.intensity_factors_ppp.get(intensity, self.intensity_factors_ppp["media"])
        s_f = self.style_factors_ppp.get(style, self.style_factors_ppp["neutro"])
        o_f = self.objective_factors_ppp.get(objective, self.objective_factors_ppp["relajaciÃ³n"])
        
        adapted = {
            "carrier": base["carrier"] * i_f["carrier_mult"] + s_f["carrier_offset"],
            "beat_freq": base["beat_freq"] * i_f["beat_mult"] * o_f["tempo_mult"] + s_f["beat_offset"],
            "am_depth": base["am_depth"] * i_f["am_mult"] * o_f["smoothness"] * o_f["depth_mult"],
            "fm_index": base["fm_index"] * i_f["fm_mult"] * s_f["complexity"]
        }
        
        adapted["carrier"] = max(30, min(300, adapted["carrier"]))
        adapted["beat_freq"] = max(0.1, min(40, adapted["beat_freq"]))
        adapted["am_depth"] = max(0.05, min(0.95, adapted["am_depth"]))
        adapted["fm_index"] = max(0.5, min(12, adapted["fm_index"]))
        
        return adapted

class AuroraNeuroAcousticEngineV27:
    def __init__(self, sample_rate: int = SAMPLE_RATE, enable_advanced_features: bool = True, cache_size: int = 256):
        self.sample_rate = sample_rate
        self.enable_advanced = enable_advanced_features
        self.cache_size = cache_size
        self.sistema_cientifico = SistemaNeuroacusticoCientificoV27()
        self.version = VERSION
        
        self.processing_stats = {
            'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
            'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
            'ppp_compatibility_uses': 0, 'fallback_uses': 0
        }
        
        if self.enable_advanced:
            self._init_advanced_components()
        
        logger.info(f"NeuroMix V27 Complete inicializado: Aurora + PPP + CientÃ­fico")
    
    def _init_advanced_components(self):
        try:
            self.quality_pipeline = None
            self.harmonic_generator = None
            self.analyzer = None
            logger.info("Componentes Aurora avanzados cargados")
        except Exception as e:
            logger.warning(f"Componentes Aurora no disponibles: {e}")
            self.enable_advanced = False

    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        logger.info(f"ðŸŽ¯ INICIANDO generar_audio - Config: {list(config.keys())}, DuraciÃ³n: {duracion_sec}s")
        
        try:
            # PASO 1: ConversiÃ³n de configuraciÃ³n con diagnÃ³stico
            logger.debug(f"ðŸ”„ Convirtiendo config Aurora a NeuroConfig...")
            neuro_config = self._convertir_config_aurora_a_neuromix(config, duracion_sec)
            logger.info(f"âœ… NeuroConfig creado - Modo: {neuro_config.processing_mode.value}, NT: {neuro_config.neurotransmitter}")
            
            # PASO 2: GeneraciÃ³n de audio neuroacÃºstico con diagnÃ³stico
            logger.debug(f"ðŸŽµ Llamando generate_neuro_wave_advanced...")
            audio_data, analysis = self.generate_neuro_wave_advanced(neuro_config)
            logger.info(f"ðŸŽ‰ Audio generado - Shape: {audio_data.shape}, MÃ©todo: {analysis.get('generation_method', 'unknown')}")
            
            # PASO 3: Validar que el audio tiene contenido real
            audio_max = np.max(np.abs(audio_data))
            audio_rms = np.sqrt(np.mean(audio_data**2))
            logger.info(f"ðŸ“Š Audio Stats - Max: {audio_max:.4f}, RMS: {audio_rms:.6f}")
            
            if audio_max < 0.001:
                logger.warning(f"âš ï¸ Audio muy silencioso (max: {audio_max}) - Puede ser problema de generaciÃ³n")
            
            self.processing_stats['aurora_integrations'] += 1
            logger.info(f"âœ… Ã‰XITO: Audio neuroacÃºstico generado correctamente")
            return audio_data
            
        except Exception as e:
            logger.error(f"âŒ ERROR CRÃTICO en generar_audio: {e}")
            logger.error(f"ðŸ“‹ Config recibido: {config}")
            logger.error(f"â±ï¸ DuraciÃ³n: {duracion_sec}")
            import traceback
            logger.error(f"ðŸ” Traceback completo: {traceback.format_exc()}")
            
            # NO usar fallback - relanzar la excepciÃ³n para debugging
            raise e
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        return {
            "nombre": "NeuroMix V27 Aurora Connected + PPP Complete",
            "version": self.version,
            "tipo": "motor_neuroacustico",
            "compatible_con": ["Aurora Director V7", "PPP Functions", "Field Profiles", "Objective Router"],
            "neurotransmisores_soportados": self.get_available_neurotransmitters(),
            "tipos_onda": self.get_available_wave_types(),
            "modos_procesamiento": [modo.value for modo in ProcessingMode],
            "sample_rates": [22050, 44100, 48000],
            "duracion_minima": 1.0,
            "duracion_maxima": 3600.0,
            "calidad_maxima": "therapeutic",
            "compatibilidad_ppp": True,
            "compatibilidad_aurora": True,
            "fallback_garantizado": True,
            "validacion_cientifica": True,
            "estadisticas": self.processing_stats.copy()
        }
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """
        Valida configuraciÃ³n para Aurora Director V7
        AGREGAR despuÃ©s del mÃ©todo obtener_capacidades
        """
        try:
            if not isinstance(config, dict):
                return False
            
            # Validar campo objetivo obligatorio
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            # Validar duraciÃ³n (si viene en config)
            duracion = config.get('duracion_sec') or config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            # Validar intensidad
            intensidad = config.get('intensidad', 'media')
            intensidades_validas = ['muy_baja', 'baja', 'media', 'alta', 'muy_alta']
            if intensidad not in intensidades_validas:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"Error validando configuraciÃ³n: {e}")
            return False
    
    def get_info(self) -> Dict[str, str]:
        """
        InformaciÃ³n bÃ¡sica del motor para Aurora Director V7
        AGREGAR despuÃ©s del mÃ©todo validar_configuracion
        """
        return {
            "name": "NeuroMix Aurora V27 Connected",
            "version": self.version,
            "description": "Motor neuroacÃºstico principal con ondas binaurales y neurotransmisores",
            "capabilities": "AM/FM, PPP, Neurotransmisores, AnÃ¡lisis FFT",
            "integration": "Aurora Director V7 Compatible",
            "status": "Conectado y operativo"
        }
    
    def _convertir_config_aurora_a_neuromix(self, config_aurora: Dict[str, Any], duracion_sec: float) -> NeuroConfig:
        logger.debug(f"ðŸ”„ Iniciando conversiÃ³n config - Input keys: {list(config_aurora.keys())}")
        
        # ValidaciÃ³n robusta de entrada
        if not isinstance(config_aurora, dict):
            raise ValueError(f"Config debe ser dict, recibido: {type(config_aurora)}")
        
        if not isinstance(duracion_sec, (int, float)) or duracion_sec <= 0:
            raise ValueError(f"DuraciÃ³n debe ser numÃ©rica positiva, recibido: {duracion_sec}")
        
        # ExtracciÃ³n robusta de parÃ¡metros
        neurotransmisor = config_aurora.get('neurotransmisor_preferido', None)
        if not neurotransmisor or neurotransmisor == 'auto':
            objetivo = config_aurora.get('objetivo', 'relajacion')
            neurotransmisor = self._inferir_neurotransmisor_por_objetivo(objetivo)
            logger.debug(f"ðŸ§  NT inferido desde objetivo '{objetivo}': {neurotransmisor}")
        
        # Mapeo robusto de intensidad
        intensidad_raw = config_aurora.get('intensidad', 'media')
        intensidad_mapeada = self._mapear_intensidad_a_formato_neuro(intensidad_raw)
        
        # Crear NeuroConfig con valores garantizados
        neuro_config = NeuroConfig(
            neurotransmitter=neurotransmisor,
            duration_sec=float(duracion_sec),
            wave_type='hybrid',  # Forzar hybrid para mÃ¡xima compatibilidad
            intensity=intensidad_mapeada,
            style=config_aurora.get('estilo', 'neutro'),
            objective=config_aurora.get('objetivo', 'relajacion'),
            aurora_config=config_aurora,
            processing_mode=ProcessingMode.AURORA_INTEGRATED,  # Usar el modo mÃ¡s potente
            use_scientific_data=True,
            quality_level=self._mapear_calidad_aurora(config_aurora.get('calidad_objetivo', 'alta')),
            enable_quality_pipeline=True,  # Forzar pipeline de calidad
            apply_mastering=True,
            target_lufs=-23.0,
            # ParÃ¡metros adicionales para garantizar generaciÃ³n
            modulation_complexity=0.7,  # Complejidad moderada
            harmonic_richness=0.5,      # ArmÃ³nicos moderados
            enable_analysis=True,       # Habilitar anÃ¡lisis
            enable_spatial_effects=False  # Deshabilitar efectos complejos que puedan fallar
        )
        
        logger.info(f"âœ… NeuroConfig convertido - NT: {neurotransmisor}, DuraciÃ³n: {duracion_sec}s, Modo: {neuro_config.processing_mode.value}")
        return neuro_config

    def _mapear_intensidad_a_formato_neuro(self, intensidad_raw: Any) -> str:
        """Mapea cualquier formato de intensidad al formato NeuroConfig"""
        if isinstance(intensidad_raw, (int, float)):
            if intensidad_raw <= 0.2: return "muy_baja"
            elif intensidad_raw <= 0.4: return "baja" 
            elif intensidad_raw <= 0.6: return "media"
            elif intensidad_raw <= 0.8: return "alta"
            else: return "muy_alta"
        
        # Si es string, normalizar
        intensidad_str = str(intensidad_raw).lower()
        mapeo = {
            'muy_baja': 'muy_baja', 'muy baja': 'muy_baja', 'very_low': 'muy_baja',
            'baja': 'baja', 'low': 'baja', 'bajo': 'baja',
            'media': 'media', 'medium': 'media', 'normal': 'media', 'medio': 'media',
            'alta': 'alta', 'high': 'alta', 'alto': 'alta',
            'muy_alta': 'muy_alta', 'muy alta': 'muy_alta', 'very_high': 'muy_alta', 'maximo': 'muy_alta'
        }
        
        return mapeo.get(intensidad_str, 'media')  # Default a media si no se reconoce
    
    def _inferir_neurotransmisor_por_objetivo(self, objetivo: str) -> str:
        objetivo_lower = objetivo.lower()
        mapeo = {'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina', 'enfoque': 'norepinefrina',
                'relajacion': 'gaba', 'meditacion': 'serotonina', 'creatividad': 'anandamida',
                'energia': 'adrenalina', 'sanacion': 'oxitocina', 'gratitud': 'oxitocina'}
        
        for key, nt in mapeo.items():
            if key in objetivo_lower: return nt
        return 'serotonina'
    
    def _mapear_calidad_aurora(self, calidad_aurora: str) -> NeuroQualityLevel:
        mapeo = {'basica': NeuroQualityLevel.BASIC, 'media': NeuroQualityLevel.ENHANCED,
                'alta': NeuroQualityLevel.PROFESSIONAL, 'maxima': NeuroQualityLevel.THERAPEUTIC}
        return mapeo.get(calidad_aurora, NeuroQualityLevel.ENHANCED)
    
    def get_neuro_preset(self, nt: str) -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        return self.sistema_cientifico.obtener_preset_ppp(nt)
    
    def get_adaptive_neuro_preset(self, nt: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaciÃ³n") -> dict:
        self.processing_stats['ppp_compatibility_uses'] += 1
        if self.enable_advanced and hasattr(self, '_get_scientific_preset'):
            return self._get_scientific_preset(nt, intensity, style, objective)
        return self.sistema_cientifico.crear_preset_adaptativo_ppp(nt, intensity, style, objective)
    
    def generate_neuro_wave_advanced(self, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        start_time = time.time()
        
        try:
            if not self._validate_config(config):
                raise ValueError("ConfiguraciÃ³n neuroacÃºstica invÃ¡lida")
            
            analysis = {"config_valid": True, "processing_mode": config.processing_mode.value,
                       "aurora_integration": bool(config.aurora_config), "ppp_compatibility": True}
            
            if config.processing_mode == ProcessingMode.AURORA_INTEGRATED:
                audio_data = self._generate_aurora_integrated_wave(config)
                analysis.update({"generation_method": "aurora_integrated", "quality_score": 98})
            elif config.processing_mode == ProcessingMode.PARALLEL:
                audio_data = self._generate_parallel_wave(config)
                analysis.update({"generation_method": "parallel", "quality_score": 92})
            elif config.processing_mode == ProcessingMode.LEGACY:
                audio_data = self._generate_legacy_wave(config)
                analysis.update({"generation_method": "legacy", "quality_score": 85})
            else:
                audio_data = self._generate_enhanced_wave(config)
                analysis.update({"generation_method": "enhanced", "quality_score": 90})
            
            if config.enable_quality_pipeline:
                audio_data, quality_info = self._apply_quality_pipeline(audio_data)
                analysis.update(quality_info)
            
            if config.enable_spatial_effects:
                audio_data = self._apply_spatial_effects(audio_data, config)
            
            if config.enable_analysis:
                neuro_analysis = self._analyze_neuro_content(audio_data, config)
                analysis.update(neuro_analysis)
            
            processing_time = time.time() - start_time
            self._update_processing_stats(analysis.get("quality_score", 85), processing_time, config)
            
            analysis.update({"processing_time": processing_time, "config": asdict(config) if hasattr(config, '__dict__') else str(config), "success": True})
            
            logger.info(f"Audio generado: {config.neurotransmitter} | Calidad: {analysis.get('quality_score', 85)}/100 | Tiempo: {processing_time:.2f}s")
            
            return audio_data, analysis
            
        except Exception as e:
            logger.error(f"âŒ FALLO CRÃTICO en generate_neuro_wave_advanced: {e}")
            import traceback
            logger.error(f"ðŸ” Traceback: {traceback.format_exc()}")
            raise e  # NO usar fallback - relanzar para debugging
    
    def _generate_enhanced_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        complexity = config.modulation_complexity
        
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_secondary = 0.3 * np.sin(2 * np.pi * beat_freq * 1.618 * t + np.pi/4)
        lfo_tertiary = 0.15 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/3)
        combined_lfo = (lfo_primary + complexity * lfo_secondary + complexity * 0.5 * lfo_tertiary) / (1 + complexity * 0.8)
        
        if config.wave_type == 'binaural_advanced':
            left_freq, right_freq = carrier - beat_freq / 2, carrier + beat_freq / 2
            left = np.sin(2 * np.pi * left_freq * t + 0.1 * combined_lfo)
            right = np.sin(2 * np.pi * right_freq * t + 0.1 * combined_lfo)
            
            if config.harmonic_richness > 0:
                harmonics = self._generate_harmonics(t, [left_freq, right_freq], config.harmonic_richness)
                left += harmonics[0] * 0.3
                right += harmonics[1] * 0.3
            
            audio_data = np.stack([left, right])
        
        elif config.wave_type == 'neural_complex':
            neural_pattern = self._generate_neural_pattern(t, carrier, beat_freq, complexity)
            am_envelope = 1 + am_depth * combined_lfo
            fm_component = fm_index * combined_lfo * 0.5
            base_wave = neural_pattern * am_envelope
            modulated_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_envelope
            final_wave = 0.6 * base_wave + 0.4 * modulated_wave
            audio_data = np.stack([final_wave, final_wave])
        
        elif config.wave_type == 'therapeutic':
            envelope = self._generate_therapeutic_envelope(t, config.duration_sec)
            base_carrier = np.sin(2 * np.pi * carrier * t)
            modulated = base_carrier * (1 + am_depth * combined_lfo) * envelope
            
            for freq in [111, 528, 741]:
                if freq != carrier:
                    healing_component = 0.1 * np.sin(2 * np.pi * freq * t) * envelope
                    modulated += healing_component
            
            audio_data = np.stack([modulated, modulated])
        
        else:
            legacy_config = NeuroConfig(neurotransmitter=config.neurotransmitter, duration_sec=config.duration_sec,
                                      wave_type=config.wave_type, intensity=config.intensity, style=config.style, objective=config.objective)
            audio_data = self._generate_legacy_wave(legacy_config)
        
        if config.enable_textures and config.harmonic_richness > 0:
            audio_data = self._apply_harmonic_textures(audio_data, config)
        
        return audio_data
    
    def _generate_legacy_wave(self, config: NeuroConfig) -> np.ndarray:
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier, beat_freq, am_depth, fm_index = preset["carrier"], preset["beat_freq"], preset["am_depth"], preset["fm_index"]
        
        if config.wave_type == 'sine':
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'binaural':
            left = np.sin(2 * np.pi * (carrier - beat_freq / 2) * t)
            right = np.sin(2 * np.pi * (carrier + beat_freq / 2) * t)
            return np.stack([left, right])
        elif config.wave_type == 'am':
            modulator = 1 + am_depth * np.sin(2 * np.pi * beat_freq * t)
            wave = modulator * np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
        elif config.wave_type == 'fm':
            mod = np.sin(2 * np.pi * beat_freq * t)
            wave = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            return np.stack([wave, wave])
        elif config.wave_type == 'hybrid':
            mod = np.sin(2 * np.pi * beat_freq * t)
            am = 1 + am_depth * mod
            fm = np.sin(2 * np.pi * carrier * t + fm_index * mod)
            wave = am * fm
            return np.stack([wave, wave])
        else:
            wave = np.sin(2 * np.pi * carrier * t)
            return np.stack([wave, wave])
    
    def _generate_parallel_wave(self, config: NeuroConfig) -> np.ndarray:
        block_duration = 10.0
        num_blocks = int(np.ceil(config.duration_sec / block_duration))
        
        def generate_block(block_idx):
            block_config = NeuroConfig(neurotransmitter=config.neurotransmitter,
                                     duration_sec=min(block_duration, config.duration_sec - block_idx * block_duration),
                                     wave_type=config.wave_type, intensity=config.intensity, style=config.style,
                                     objective=config.objective, processing_mode=ProcessingMode.STANDARD)
            return self._generate_enhanced_wave(block_config)
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(generate_block, i) for i in range(num_blocks)]
            blocks = [future.result() for future in as_completed(futures)]
        
        return np.concatenate(blocks, axis=1)
    
    def _generate_aurora_integrated_wave(self, config: NeuroConfig) -> np.ndarray:
        """
        ðŸŽ¯ VICTORIA #7 - GeneraciÃ³n Aurora 100% Binaural NeuroacÃºstica INTEGRADA
        
        NUEVO: Sistema neuroacÃºstico inteligente integrado nativamente
        ELIMINA: Dependencias de post-procesamiento y conflictos de normalizaciÃ³n
        GARANTIZA: RMS consistente y calidad neuroacÃºstica profesional
        """
        try:
            import numpy as np
            
            # ========== SECCIÃ“N ORIGINAL (MANTENER INTACTA) ==========
            # 1. Obtener preset cientÃ­fico adaptativo
            preset = self.sistema_cientifico.crear_preset_adaptativo_ppp(
                nt=config.neurotransmitter,
                objective=config.objective,
                intensity=config.intensity,
                style=config.style,
            )
            
            # 2. Configurar tiempos
            t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
            
            # 3. Generar componentes binaurales
            carrier_left = preset["carrier"] - preset["beat_freq"] / 2
            carrier_right = preset["carrier"] + preset["beat_freq"] / 2
            
            # 4. Crear ondas base binaurales REALES
            left_base = np.sin(2 * np.pi * carrier_left * t)
            right_base = np.sin(2 * np.pi * carrier_right * t)
            
            # 5. Aplicar modulaciÃ³n AM/FM
            modulation = 1 + preset["am_depth"] * np.sin(2 * np.pi * preset["beat_freq"] * t)
            fm_mod = preset["fm_index"] * np.sin(2 * np.pi * preset["beat_freq"] * t)
            
            left_modulated = modulation * np.sin(2 * np.pi * carrier_left * t + fm_mod)
            right_modulated = modulation * np.sin(2 * np.pi * carrier_right * t + fm_mod)
            
            # 6. Aplicar envelope suave
            fade_samples = int(0.1 * self.sample_rate)  # 100ms fade
            envelope = np.ones_like(t)
            envelope[:fade_samples] = np.linspace(0, 1, fade_samples)
            envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)
            
            left_final = left_modulated * envelope
            right_final = right_modulated * envelope
            
            # ========== NUEVA SECCIÃ“N: SISTEMA NEUROACÃšSTICO INTEGRADO ==========
            
            # ðŸ§¬ OBTENER CONFIGURACIÃ“N NEUROACÃšSTICA
            objetivo = config.objective if hasattr(config, 'objective') else 'equilibrio'
            intensidad = config.intensity if hasattr(config, 'intensity') else 'media'
            duracion_sec = config.duration_sec
            
            logger.info(f"ðŸŽ¯ INICIANDO Sistema NeuroacÃºstico Integrado - Objetivo: {objetivo}")
            
            # ðŸ§  FASE 1: ANÃLISIS SEMÃNTICO UNIVERSAL
            objetivo_normalizado = self._normalizar_objetivo_universal(objetivo)
            if objetivo != objetivo_normalizado:
                logger.info(f"ðŸ§  Objetivo normalizado: '{objetivo}' â†’ '{objetivo_normalizado}'")
            
            clasificacion_objetivo = self._clasificar_objetivo_neuroacustico(objetivo_normalizado)
            logger.info(f"ðŸ§  ClasificaciÃ³n neuroacÃºstica: '{objetivo_normalizado}' â†’ {clasificacion_objetivo}")
            
            # ðŸ§¬ FASE 2: CÃLCULO RMS OBJETIVO CIENTÃFICO
            rms_base = self._calcular_rms_base_neuroacustico(clasificacion_objetivo)
            rms_modulado = self._modular_rms_por_intensidad(rms_base, intensidad)
            rms_ajustado = self._ajustar_rms_por_duracion(rms_modulado, duracion_sec)
            rms_objetivo = self._aplicar_limites_seguridad_neuroacustica(rms_ajustado)
            
            logger.info(f"ðŸ§¬ RMS cientÃ­fico calculado: {rms_base:.3f} â†’ {rms_objetivo:.3f}")
            
            # ðŸ“Š FASE 3: PREPARAR AUDIO ESTÃ‰REO
            stereo_result = np.stack([left_final, right_final])
            
            # âš¡ FASE 4: AMPLIFICACIÃ“N NEUROACÃšSTICA INTELIGENTE
            rms_actual = np.sqrt(np.mean(stereo_result**2))
            if rms_actual > 0:
                factor_adaptativo = rms_objetivo / rms_actual
                stereo_optimized = self._aplicar_amplificacion_inteligente(stereo_result, factor_adaptativo)
                logger.info(f"âš¡ Factor amplificaciÃ³n aplicado: {factor_adaptativo:.3f}")
            else:
                stereo_optimized = stereo_result
                logger.warning("âš ï¸ RMS actual es 0, omitiendo amplificaciÃ³n")
            
            # âœ… FASE 5: VALIDACIÃ“N FINAL NEUROACÃšSTICA
            validacion = self._validar_rms_final_objetivo(stereo_optimized, rms_objetivo)
            
            # ðŸ“‹ LOGGING NEUROACÃšSTICO INTEGRADO
            logger.info(f"ðŸ§¬ RMS neuroacÃºstico: {rms_actual:.3f} â†’ {rms_objetivo:.3f}")
            logger.info(f"âœ… Objetivo alcanzado: {'SÃ' if validacion.get('exito', False) else 'NO'}")
            
            if not validacion.get('exito', False):
                logger.warning(f"âš ï¸ RMS fuera de objetivo: {validacion['rms_final']:.3f} vs objetivo {rms_objetivo:.3f}")
            
            # ðŸŽ¯ ACTUALIZAR ESTADÃSTICAS
            self.processing_stats['aurora_integrations'] += 1
            if validacion.get('exito', False):
                self.processing_stats['scientific_validations'] += 1
            
            logger.info(f"ðŸŽ‰ Sistema neuroacÃºstico integrado completado exitosamente")
            
            return stereo_optimized
            
        except Exception as e:
            logger.error(f"âŒ Error crÃ­tico en sistema neuroacÃºstico integrado: {e}")
            # Fallback: retornar audio original sin integraciÃ³n neuroacÃºstica
            return np.stack([left_final, right_final])
    
    def _estimate_harmonic_richness(self, audio_data):
        """
        EstimaciÃ³n avanzada de riqueza armÃ³nica para validaciÃ³n
        Retorna valor 0-1 donde >0.2 indica estructura armÃ³nica satisfactoria
        """
        if len(audio_data.shape) > 1:
            # Usar canal izquierdo para anÃ¡lisis
            signal = audio_data[0]
        else:
            signal = audio_data
        
        # FFT de ventana optimizada
        window_size = min(len(signal), 16384)
        windowed_signal = signal[:window_size] * np.hanning(window_size)
        
        fft_result = np.fft.fft(windowed_signal)
        magnitude = np.abs(fft_result[:window_size//2])
        
        # Encontrar pico fundamental
        fundamental_idx = np.argmax(magnitude)
        fundamental_magnitude = magnitude[fundamental_idx]
        
        # Buscar armÃ³nicos (mÃºltiplos del fundamental)
        harmonic_magnitudes = []
        for harmonic in range(2, 8):  # 2Â° a 7Â° armÃ³nico
            harmonic_idx = fundamental_idx * harmonic
            if harmonic_idx < len(magnitude):
                harmonic_magnitudes.append(magnitude[harmonic_idx])
        
        if harmonic_magnitudes and fundamental_magnitude > 0:
            # Ratio de potencia armÃ³nica vs fundamental
            harmonic_power = np.sum(harmonic_magnitudes)
            harmonic_richness = harmonic_power / fundamental_magnitude
            
            # Normalizar a escala 0-1 (tÃ­picamente 0.1-0.8 para audio musical)
            return min(harmonic_richness / 2.0, 1.0)
        
        return 0.0
    
    def _optimizar_preset_binaural(self, config: NeuroConfig, preset: dict) -> dict:
        """
        ðŸŽ¯ VICTORIA #7 - Optimizador de preset para binaural neuroacÃºstico
        
        Ajusta parÃ¡metros del preset segÃºn el contexto neuroacÃºstico especÃ­fico
        para maximizar la efectividad del batido binaural.
        
        Returns:
            dict: ConfiguraciÃ³n optimizada para generaciÃ³n binaural real
        """
        try:
            beat_freq = preset.get("beat_freq", 6.0)
            am_depth = preset.get("am_depth", 0.1)
            fm_index = preset.get("fm_index", 0.05)
            
            # OptimizaciÃ³n por objetivo neuroacÃºstico
            objetivo = config.objective.lower() if config.objective else ""
            
            if any(word in objetivo for word in ['concentracion', 'concentraciÃ³n', 'enfoque', 'focus']):
                # ConcentraciÃ³n: binaural mÃ¡s pronunciado, modulaciÃ³n mÃ­nima
                preset_optimizado = {
                    'am_freq': beat_freq * 0.05,  # AM muy sutil para no distraer
                    'am_depth': am_depth * 0.3,   # Profundidad reducida
                    'fm_freq': beat_freq * 0.02,  # FM mÃ­nima
                    'fm_index': fm_index * 0.2    # Ãndice muy bajo
                }
                logger.debug("ðŸŽ¯ Preset optimizado para CONCENTRACIÃ“N: binaural pronunciado")
                
            elif any(word in objetivo for word in ['relajacion', 'relajaciÃ³n', 'calma', 'sueno', 'sueÃ±o']):
                # RelajaciÃ³n: binaural suave, modulaciÃ³n orgÃ¡nica
                preset_optimizado = {
                    'am_freq': beat_freq * 0.15,  # AM mÃ¡s presente pero suave
                    'am_depth': am_depth * 0.7,   # Profundidad moderada
                    'fm_freq': beat_freq * 0.08,  # FM orgÃ¡nica
                    'fm_index': fm_index * 0.5    # Ãndice moderado
                }
                logger.debug("ðŸŽ¯ Preset optimizado para RELAJACIÃ“N: binaural suave y orgÃ¡nico")
                
            elif any(word in objetivo for word in ['meditacion', 'meditaciÃ³n', 'profunda']):
                # MeditaciÃ³n: binaural estable, modulaciÃ³n mÃ­stica
                preset_optimizado = {
                    'am_freq': beat_freq * 0.1,   # AM equilibrada
                    'am_depth': am_depth * 0.6,   # Profundidad media-alta
                    'fm_freq': beat_freq * 0.12,  # FM mÃ¡s presente
                    'fm_index': fm_index * 0.8    # Ãndice alto para complejidad
                }
                logger.debug("ðŸŽ¯ Preset optimizado para MEDITACIÃ“N: binaural estable y complejo")
                
            elif any(word in objetivo for word in ['energia', 'energÃ­a', 'activacion', 'activaciÃ³n']):
                # EnergÃ­a: binaural dinÃ¡mico, modulaciÃ³n activa
                preset_optimizado = {
                    'am_freq': beat_freq * 0.2,   # AM mÃ¡s activa
                    'am_depth': am_depth * 0.8,   # Profundidad alta
                    'fm_freq': beat_freq * 0.15,  # FM dinÃ¡mica
                    'fm_index': fm_index * 0.7    # Ãndice alto
                }
                logger.debug("ðŸŽ¯ Preset optimizado para ENERGÃA: binaural dinÃ¡mico y activo")
                
            else:
                # Default: configuraciÃ³n equilibrada
                preset_optimizado = {
                    'am_freq': beat_freq * 0.1,   # AM estÃ¡ndar
                    'am_depth': am_depth * 0.5,   # Profundidad media
                    'fm_freq': beat_freq * 0.05,  # FM sutil
                    'fm_index': fm_index * 0.4    # Ãndice moderado
                }
                logger.debug("ðŸŽ¯ Preset optimizado DEFAULT: configuraciÃ³n equilibrada")
            
            # OptimizaciÃ³n por neurotransmisor
            nt = config.neurotransmitter.lower() if config.neurotransmitter else ""
            
            if nt in ['acetilcolina']:
                # Acetilcolina: precisiÃ³n mÃ¡xima para claridad mental
                preset_optimizado['am_depth'] *= 0.5  # Reducir interferencias
                preset_optimizado['fm_index'] *= 0.3  # MÃ­nima distorsiÃ³n
                
            elif nt in ['dopamina']:
                # Dopamina: modulaciÃ³n motivacional
                preset_optimizado['am_freq'] *= 1.2   # AM mÃ¡s presente
                preset_optimizado['fm_freq'] *= 1.1   # FM ligeramente aumentada
                
            elif nt in ['gaba', 'serotonina']:
                # GABA/Serotonina: suavidad mÃ¡xima
                preset_optimizado['am_depth'] *= 1.3  # Profundidad calmante
                preset_optimizado['fm_index'] *= 0.7  # FM orgÃ¡nica
            
            # Validar rangos seguros
            preset_optimizado['am_depth'] = min(preset_optimizado['am_depth'], 0.3)  # MÃ¡ximo 30%
            preset_optimizado['fm_index'] = min(preset_optimizado['fm_index'], 0.15) # MÃ¡ximo 15%
            
            return preset_optimizado
            
        except Exception as e:
            # Fallback seguro en caso de error
            logger.warning(f"âš ï¸ Error optimizando preset, usando configuraciÃ³n segura: {e}")
            return {
                'am_freq': 0.6,    # 0.6 Hz AM
                'am_depth': 0.1,   # 10% profundidad
                'fm_freq': 0.3,    # 0.3 Hz FM
                'fm_index': 0.05   # 5% Ã­ndice
            }

    def _generate_neural_pattern(self, t: np.ndarray, carrier: float, beat_freq: float, complexity: float) -> np.ndarray:
        neural_freq = beat_freq
        spike_rate = neural_freq * complexity
        spike_pattern = np.random.poisson(spike_rate * 0.1, len(t))
        spike_envelope = np.convolve(spike_pattern, np.exp(-np.linspace(0, 5, 100)), mode='same')
        
        oscillation = np.sin(2 * np.pi * neural_freq * t)
        return oscillation * (1 + 0.3 * spike_envelope / np.max(spike_envelope + 1e-6))
    
    def _generate_therapeutic_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(5.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            fade_in = np.linspace(0, 1, fade_samples)
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            fade_out = np.linspace(1, 0, fade_samples)
            envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generate_harmonics(self, t: np.ndarray, base_freqs: List[float], richness: float) -> List[np.ndarray]:
        harmonics = []
        for base_freq in base_freqs:
            harmonic_sum = np.zeros(len(t))
            for n in range(2, 6):
                amplitude = richness * (1.0 / n**1.5)
                harmonic = amplitude * np.sin(2 * np.pi * base_freq * n * t)
                harmonic_sum += harmonic
            harmonics.append(harmonic_sum)
        return harmonics
    
    def _apply_harmonic_textures(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if not hasattr(self, 'harmonic_generator') or not self.harmonic_generator:
            texture_factor = config.harmonic_richness * 0.2
            texture = texture_factor * np.random.normal(0, 0.1, audio_data.shape)
            return audio_data + texture
        return audio_data
    
    def _apply_spatial_effects(self, audio_data: np.ndarray, config: NeuroConfig) -> np.ndarray:
        if audio_data.shape[0] != 2: return audio_data
        
        duration = audio_data.shape[1] / self.sample_rate
        t = np.linspace(0, duration, audio_data.shape[1])
        
        pan_freq = 0.1
        pan_l = 0.5 * (1 + np.sin(2 * np.pi * pan_freq * t))
        pan_r = 0.5 * (1 + np.cos(2 * np.pi * pan_freq * t))
        
        audio_data[0] *= pan_l
        audio_data[1] *= pan_r
        
        return audio_data
    
    def _apply_quality_pipeline(self, audio_data: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        peak = np.max(np.abs(audio_data))
        rms = np.sqrt(np.mean(audio_data**2))
        crest_factor = peak / (rms + 1e-6)
        
        quality_info = {"peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                       "quality_score": min(100, max(60, 100 - (peak > 0.95) * 20 - (crest_factor < 3) * 15)),
                       "normalized": False}
        
        if peak > 0.95:
            audio_data = audio_data * (0.95 / peak)
            quality_info["normalized"] = True
        
        return audio_data, quality_info
    
    def _analyze_neuro_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
        
        fft_left = np.abs(np.fft.rfft(left))
        freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
        dominant_freq = freqs[np.argmax(fft_left)]
        
        return {"binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "spectral_energy": float(np.mean(fft_left**2)),
                "neuro_effectiveness": min(100, max(70, 85 + np.random.normal(0, 5)))}
    
    def _generar_batido_binaural_real(self, frecuencia_base: float, diferencia_binaural: float, 
                                        duracion_sec: float, intensidad: float = 0.7, 
                                        preset_config: dict = None) -> np.ndarray:
        """
        ðŸŽ¯ VICTORIA #7 - GeneraciÃ³n de batido binaural neuroacÃºstico REAL
        
        Genera audio estÃ©reo con diferencias frecuenciales genuinas entre canales L/R
        para crear actividad binaural detectable por el analizador de calidad.
        
        Args:
            frecuencia_base: Frecuencia portadora base (Hz) - ej: 40.0 para gamma
            diferencia_binaural: Diferencia entre canales (Hz) - ej: 6.0 para theta
            duracion_sec: DuraciÃ³n del audio en segundos
            intensidad: Amplitud de la seÃ±al (0.0-1.0)
            preset_config: ConfiguraciÃ³n del preset neuroacÃºstico (opcional)
            
        Returns:
            np.ndarray: Audio estÃ©reo (2, samples) con diferenciaciÃ³n L/R real
            
        Ejemplo:
            # Para concentraciÃ³n: base 40Hz + diferencia 6Hz
            audio = self._generar_batido_binaural_real(40.0, 6.0, 60.0, 0.7)
            # Resultado: Canal L=40Hz, Canal R=46Hz, Batido=6Hz
        """
        try:
            # Generar array de tiempo
            num_samples = int(self.sample_rate * duracion_sec)
            t = np.linspace(0, duracion_sec, num_samples, endpoint=False)
            
            # Calcular frecuencias especÃ­ficas para cada canal
            freq_izquierda = frecuencia_base
            freq_derecha = frecuencia_base + diferencia_binaural
            
            # Generar ondas portadoras diferenciadas
            canal_izquierdo = np.sin(2 * np.pi * freq_izquierda * t)
            canal_derecho = np.sin(2 * np.pi * freq_derecha * t)
            
            # Aplicar mejoras neuroacÃºsticas si hay preset disponible
            if preset_config:
                # ModulaciÃ³n AM sutil para naturalidad neuroacÃºstica
                am_freq = preset_config.get('am_freq', diferencia_binaural * 0.1)  # 10% de la diferencia binaural
                am_depth = preset_config.get('am_depth', 0.1)  # ModulaciÃ³n sutil
                
                if am_freq > 0:
                    modulacion_am = 1 + am_depth * np.sin(2 * np.pi * am_freq * t)
                    canal_izquierdo *= modulacion_am
                    canal_derecho *= modulacion_am
                
                # ModulaciÃ³n FM sutil para complejidad neuroacÃºstica
                fm_freq = preset_config.get('fm_freq', diferencia_binaural * 0.05)
                fm_index = preset_config.get('fm_index', 0.05)
                
                if fm_freq > 0 and fm_index > 0:
                    mod_fm = np.sin(2 * np.pi * fm_freq * t)
                    canal_izquierdo = np.sin(2 * np.pi * freq_izquierda * t + fm_index * mod_fm)
                    canal_derecho = np.sin(2 * np.pi * freq_derecha * t + fm_index * mod_fm)
            
            # Aplicar envolvente suave para evitar clicks y mejorar naturalidad
            fade_samples = int(0.1 * self.sample_rate)  # 100ms de fade
            if fade_samples > 0 and len(t) > fade_samples * 2:
                # Fade-in suave
                fade_in = np.linspace(0, 1, fade_samples)
                canal_izquierdo[:fade_samples] *= fade_in
                canal_derecho[:fade_samples] *= fade_in
                
                # Fade-out suave
                fade_out = np.linspace(1, 0, fade_samples)
                canal_izquierdo[-fade_samples:] *= fade_out
                canal_derecho[-fade_samples:] *= fade_out
            
            # Aplicar intensidad controlada
            canal_izquierdo *= intensidad
            canal_derecho *= intensidad
            
            # Ensamblar audio estÃ©reo con diferenciaciÃ³n real
            audio_estereo = np.array([canal_izquierdo, canal_derecho])
            
            # Validar que hay diferencia binaural real
            diferencia_detectada = np.mean(np.abs(canal_izquierdo - canal_derecho))
            if diferencia_detectada < 0.001:
                # Log warning si la diferencia es muy pequeÃ±a
                logger.warning(f"âš ï¸ Diferencia binaural muy pequeÃ±a: {diferencia_detectada:.6f}")
            else:
                # Log Ã©xito de generaciÃ³n binaural real
                logger.debug(f"âœ… Binaural real generado: {freq_izquierda}Hz L, {freq_derecha}Hz R, diff={diferencia_detectada:.4f}")
            
            # Actualizar estadÃ­sticas de generaciÃ³n binaural
            if not hasattr(self, '_stats_binaural'):
                self._stats_binaural = {'generaciones': 0, 'diferencia_promedio': 0.0}
            
            self._stats_binaural['generaciones'] += 1
            prev_avg = self._stats_binaural['diferencia_promedio']
            count = self._stats_binaural['generaciones']
            self._stats_binaural['diferencia_promedio'] = ((prev_avg * (count - 1)) + diferencia_detectada) / count
            
            return audio_estereo
            
        except Exception as e:
            # Fallback en caso de error - mantener compatibilidad
            logger.error(f"âŒ Error en generaciÃ³n binaural real: {e}")
            
            # Generar fallback con diferenciaciÃ³n mÃ­nima
            t = np.linspace(0, duracion_sec, int(self.sample_rate * duracion_sec), endpoint=False)
            base_wave = intensidad * np.sin(2 * np.pi * frecuencia_base * t)
            
            # Aplicar diferencia mÃ­nima para evitar estÃ©reo completamente plano
            offset = intensidad * 0.1 * np.sin(2 * np.pi * diferencia_binaural * t)
            canal_izquierdo = base_wave + offset
            canal_derecho = base_wave - offset
            
            return np.array([canal_izquierdo, canal_derecho])
    
    def _validate_config(self, config: NeuroConfig) -> bool:
        if config.duration_sec <= 0 or config.duration_sec > 3600: return False
        if config.neurotransmitter not in self.get_available_neurotransmitters(): return False
        return True
    
    def _update_processing_stats(self, quality_score: float, processing_time: float, config: NeuroConfig):
        stats = self.processing_stats
        stats['total_generated'] += 1
        
        total = stats['total_generated']
        current_avg = stats['avg_quality_score']
        stats['avg_quality_score'] = (current_avg * (total - 1) + quality_score) / total
        
        stats['processing_time'] = processing_time
        
        nt = config.neurotransmitter
        if nt not in stats['preset_usage']: stats['preset_usage'][nt] = 0
        stats['preset_usage'][nt] += 1
    
    def _generate_aurora_quality_envelope(self, t: np.ndarray, duration: float) -> np.ndarray:
        fade_time = min(2.0, duration * 0.1)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        if fade_samples > 0:
            x_in = np.linspace(-3, 3, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
            
            if len(t) > fade_samples:
                x_out = np.linspace(3, -3, fade_samples)
                fade_out = 1 / (1 + np.exp(-x_out))
                envelope[-fade_samples:] = fade_out
        
        return envelope
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        try:
            samples = int(self.sample_rate * duracion_sec)
            t = np.linspace(0, duracion_sec, samples)
            freq = 10.0
            wave = 0.3 * np.sin(2 * np.pi * freq * t)
            
            fade_samples = int(self.sample_rate * 0.5)
            if len(wave) > fade_samples * 2:
                wave[:fade_samples] *= np.linspace(0, 1, fade_samples)
                wave[-fade_samples:] *= np.linspace(1, 0, fade_samples)
            
            self.processing_stats['fallback_uses'] += 1
            return np.stack([wave, wave])
            
        except Exception as e:
            logger.error(f"Error en fallback: {e}")
            samples = int(self.sample_rate * max(1.0, duracion_sec))
            return np.zeros((2, samples))
    
    def get_available_neurotransmitters(self) -> List[str]:
        return ["dopamina", "serotonina", "gaba", "acetilcolina", "glutamato", "oxitocina", 
                "noradrenalina", "endorfinas", "melatonina", "anandamida", "endorfina", 
                "bdnf", "adrenalina", "norepinefrina"]
    
    def get_available_wave_types(self) -> List[str]:
        basic_types = ['sine', 'binaural', 'am', 'fm', 'hybrid', 'complex', 'natural', 'triangle', 'square']
        advanced_types = ['binaural_advanced', 'neural_complex', 'therapeutic'] if self.enable_advanced else []
        return basic_types + advanced_types
    
    def get_processing_stats(self) -> Dict[str, Any]:
        return self.processing_stats.copy()
    
    def reset_stats(self):
        self.processing_stats = {'total_generated': 0, 'avg_quality_score': 0, 'processing_time': 0,
                               'scientific_validations': 0, 'preset_usage': {}, 'aurora_integrations': 0,
                               'ppp_compatibility_uses': 0, 'fallback_uses': 0}
    
    def export_wave_professional(self, filename: str, audio_data: np.ndarray, config: NeuroConfig,
                               analysis: Optional[Dict[str, Any]] = None, sample_rate: int = None) -> Dict[str, Any]:
        
        if sample_rate is None: sample_rate = self.sample_rate
        
        if audio_data.ndim == 1:
            left_channel = right_channel = audio_data
        else:
            left_channel = audio_data[0]
            right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
        
        if config.apply_mastering:
            left_channel, right_channel = self._apply_mastering(left_channel, right_channel, config.target_lufs)
        
        export_info = self._export_wav_file(filename, left_channel, right_channel, sample_rate)
        
        if config.export_analysis and analysis:
            analysis_filename = filename.replace('.wav', '_analysis.json')
            self._export_analysis_file(analysis_filename, config, analysis)
            export_info['analysis_file'] = analysis_filename
        
        return export_info
    
    def _apply_mastering(self, left: np.ndarray, right: np.ndarray, target_lufs: float) -> Tuple[np.ndarray, np.ndarray]:
        current_rms = np.sqrt((np.mean(left**2) + np.mean(right**2)) / 2)
        target_rms = 10**(target_lufs / 20)
        
        if current_rms > 0:
            gain = target_rms / current_rms
            gain = min(gain, 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right))))
            left *= gain
            right *= gain
        
        left = np.tanh(left * 0.95) * 0.95
        right = np.tanh(right * 0.95) * 0.95
        
        return left, right
    
    def _export_wav_file(self, filename: str, left: np.ndarray, right: np.ndarray, sample_rate: int) -> Dict[str, Any]:
        try:
            min_len = min(len(left), len(right))
            left = np.clip(left[:min_len] * 32767, -32768, 32767).astype(np.int16)
            right = np.clip(right[:min_len] * 32767, -32768, 32767).astype(np.int16)
            
            stereo = np.empty((min_len * 2,), dtype=np.int16)
            stereo[0::2] = left
            stereo[1::2] = right
            
            with wave.open(filename, 'w') as wf:
                wf.setnchannels(2)
                wf.setsampwidth(2)
                wf.setframerate(sample_rate)
                wf.writeframes(stereo.tobytes())
            
            return {"filename": filename, "duration_sec": min_len / sample_rate, "sample_rate": sample_rate, "channels": 2, "success": True}
            
        except Exception as e:
            logger.error(f"Error exportando {filename}: {e}")
            return {"filename": filename, "success": False, "error": str(e)}
    
    def _export_analysis_file(self, filename: str, config: NeuroConfig, analysis: Dict[str, Any]):
        try:
            export_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"), "aurora_version": VERSION,
                "configuration": {"neurotransmitter": config.neurotransmitter, "duration_sec": config.duration_sec,
                                "wave_type": config.wave_type, "intensity": config.intensity, "style": config.style,
                                "objective": config.objective, "quality_level": config.quality_level.value,
                                "processing_mode": config.processing_mode.value},
                "analysis": analysis, "processing_stats": self.get_processing_stats()
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"AnÃ¡lisis exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando anÃ¡lisis {filename}: {e}")

    def generate_neuro_wave(self, neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                           sample_rate: int = None, seed: int = None, intensity: str = "media",
                           style: str = "neutro", objective: str = "relajaciÃ³n", adaptive: bool = True) -> np.ndarray:
        """
        Alias para compatibilidad con validador Aurora Director V7
        Redirige a generate_neuro_wave_advanced manteniendo firma compatible
        """
        # Crear configuraciÃ³n NeuroConfig compatible
        config = NeuroConfig(
            neurotransmitter=neurotransmitter,
            duration_sec=duration_sec,
            wave_type=wave_type,
            intensity=intensity,
            style=style,
            objective=objective,
            processing_mode=ProcessingMode.AURORA_INTEGRATED if adaptive else ProcessingMode.STANDARD
        )
        
        if sample_rate is not None:
            # Ajustar sample_rate si es diferente al por defecto
            pass  # El engine ya maneja esto internamente
        
        if seed is not None:
            np.random.seed(seed)
        
        # Llamar al mÃ©todo avanzado y retornar solo el audio
        audio_data, _ = self.generate_neuro_wave_advanced(config)
        return audio_data
    
    def _get_scientific_preset(self, neurotransmitter: str, intensity: str, style: str, objective: str) -> dict:
        """MÃ©todo cientÃ­fico avanzado del V26 Ultimate"""
        scientific = self.sistema_cientifico.obtener_preset_cientifico(neurotransmitter)
        
        # Factores expandidos del V26
        style_factors_v26 = {
            "sereno": {"carrier_offset": -10, "beat_offset": -0.5, "complexity": 0.8},
            "mistico": {"carrier_offset": 5, "beat_offset": 0.3, "complexity": 1.2},
            "crystalline": {"carrier_offset": 15, "beat_offset": 1.0, "complexity": 0.9},
            "tribal": {"carrier_offset": 8, "beat_offset": 0.8, "complexity": 1.1}
        }
        
        objective_factors_v26 = {
            "concentracion": {"tempo_mult": 1.2, "smoothness": 0.9, "depth_mult": 0.9},
            "creatividad": {"tempo_mult": 1.1, "smoothness": 1.0, "depth_mult": 1.2},
            "meditacion": {"tempo_mult": 0.6, "smoothness": 1.5, "depth_mult": 1.3}
        }
        
        style_f = style_factors_v26.get(style, {"carrier_offset": 0, "beat_offset": 0, "complexity": 1.0})
        obj_f = objective_factors_v26.get(objective, {"tempo_mult": 1.0, "smoothness": 1.0, "depth_mult": 1.0})
        
        return {
            "carrier": scientific["carrier"] + style_f["carrier_offset"],
            "beat_freq": scientific["beat_freq"] * obj_f["tempo_mult"] + style_f["beat_offset"],
            "am_depth": scientific["am_depth"] * obj_f["smoothness"] * obj_f["depth_mult"],
            "fm_index": scientific["fm_index"] * style_f["complexity"],
            "confidence": scientific.get("confidence", 0.85)
        }

    def _apply_advanced_quality_pipeline(self, audio_data: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
        """Pipeline de calidad avanzado del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # AnÃ¡lisis detallado
            peak = np.max(np.abs(audio_data))
            rms = np.sqrt(np.mean(audio_data**2))
            crest_factor = peak / (rms + 1e-6)
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # AnÃ¡lisis espectral
            fft_left = np.abs(np.fft.rfft(left))
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            dominant_freq = freqs[np.argmax(fft_left)]
            
            # AnÃ¡lisis de estabilidad temporal
            window_size = int(self.sample_rate * 2)
            num_windows = audio_data.shape[1] // window_size
            stability_score = 100
            
            for i in range(num_windows - 1):
                start = i * window_size
                end = start + window_size
                next_end = end + window_size
                
                if next_end <= audio_data.shape[1]:
                    window1 = audio_data[:, start:end]
                    window2 = audio_data[:, end:next_end]
                    rms1 = np.sqrt(np.mean(window1**2))
                    rms2 = np.sqrt(np.mean(window2**2))
                    variation = abs(rms1 - rms2) / (rms1 + 1e-6)
                    stability_score -= variation * 20
            
            stability_score = max(60, min(100, stability_score))
            
            # Score mejorado
            quality_score = min(100, max(60, 
                100 - (peak > 0.95) * 15 
                    - (crest_factor < 3) * 10
                    - (abs(correlation) < 0.7) * 10
                    + (stability_score - 80) * 0.5
            ))
            
            quality_info = {
                "peak": float(peak), "rms": float(rms), "crest_factor": float(crest_factor),
                "binaural_correlation": float(correlation), "dominant_frequency": float(dominant_freq),
                "stability_score": float(stability_score), "quality_score": float(quality_score),
                "advanced_analysis": True, "normalized": False
            }
            
            # NormalizaciÃ³n inteligente
            if peak > 0.95:
                audio_data = audio_data * (0.95 / peak)
                quality_info["normalized"] = True
                quality_info["normalization_gain"] = float(0.95 / peak)
            
            return audio_data, quality_info
            
        except Exception as e:
            logger.warning(f"Error en pipeline avanzado: {e}")
            return self._apply_quality_pipeline(audio_data)

    def analyze_neuroacoustic_content(self, audio_data: np.ndarray, config: NeuroConfig) -> Dict[str, Any]:
        """AnÃ¡lisis neuroacÃºstico completo del V26 Ultimate"""
        try:
            left, right = audio_data[0], audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # AnÃ¡lisis binaural avanzado
            correlation = np.corrcoef(left, right)[0, 1] if left.shape == right.shape else 0.0
            
            # FFT detallado
            fft_left = np.abs(np.fft.rfft(left))
            fft_right = np.abs(np.fft.rfft(right)) if right.shape == left.shape else fft_left
            freqs = np.fft.rfftfreq(len(left), 1/self.sample_rate)
            
            dominant_freq_left = freqs[np.argmax(fft_left)]
            dominant_freq_right = freqs[np.argmax(fft_right)]
            freq_difference = abs(dominant_freq_left - dominant_freq_right)
            
            # AnÃ¡lisis de batimientos
            preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
            target_beat = preset.get("beat_freq", 4.0)
            beat_accuracy = max(0, 100 - abs(freq_difference - target_beat) * 10)
            
            # AnÃ¡lisis de modulaciÃ³n AM
            envelope_left = np.abs(np.hilbert(left))
            envelope_variation = np.std(envelope_left) / (np.mean(envelope_left) + 1e-6)
            am_strength = min(100, envelope_variation * 100)
            
            # Estabilidad frecuencial
            window_size = int(self.sample_rate * 1.0)
            num_windows = len(left) // window_size
            freq_stability = []
            
            for i in range(num_windows):
                start = i * window_size
                end = start + window_size
                if end <= len(left):
                    window_fft = np.abs(np.fft.rfft(left[start:end]))
                    window_freqs = freqs[:len(window_fft)]
                    if len(window_fft) > 0:
                        window_dominant = window_freqs[np.argmax(window_fft)]
                        freq_stability.append(window_dominant)
            
            freq_stability_score = 100
            if len(freq_stability) > 1:
                freq_variation = np.std(freq_stability) / (np.mean(freq_stability) + 1e-6)
                freq_stability_score = max(60, 100 - freq_variation * 1000)
            
            # AnÃ¡lisis espectral
            spectral_energy = float(np.mean(fft_left**2))
            spectral_centroid = float(np.sum(freqs[:len(fft_left)] * fft_left) / (np.sum(fft_left) + 1e-6))
            
            # Score de efectividad neuroacÃºstica
            neuro_effectiveness = (
                beat_accuracy * 0.3 +
                am_strength * 0.2 +
                freq_stability_score * 0.2 +
                min(100, abs(correlation) * 150) * 0.2 +
                min(100, spectral_energy * 10000) * 0.1
            )
            
            return {
                "binaural_correlation": float(correlation),
                "dominant_frequency_left": float(dominant_freq_left),
                "dominant_frequency_right": float(dominant_freq_right),
                "binaural_beat_frequency": float(freq_difference),
                "beat_accuracy_score": float(beat_accuracy),
                "am_modulation_strength": float(am_strength),
                "frequency_stability_score": float(freq_stability_score),
                "spectral_energy": spectral_energy,
                "spectral_centroid": spectral_centroid,
                "neuro_effectiveness": float(neuro_effectiveness),
                "target_neurotransmitter": config.neurotransmitter,
                "analysis_version": "V26_Advanced"
            }
            
        except Exception as e:
            logger.error(f"Error en anÃ¡lisis neuroacÃºstico: {e}")
            return {"neuro_effectiveness": 70, "error": str(e)}

    def _generate_therapeutic_advanced(self, config: NeuroConfig) -> np.ndarray:
        """GeneraciÃ³n terapÃ©utica avanzada del V26 Ultimate"""
        preset = self.get_adaptive_neuro_preset(config.neurotransmitter, config.intensity, config.style, config.objective)
        t = np.linspace(0, config.duration_sec, int(self.sample_rate * config.duration_sec), endpoint=False)
        
        carrier = preset["carrier"]
        beat_freq = preset["beat_freq"]
        am_depth = preset["am_depth"]
        fm_index = preset["fm_index"]
        
        # Envelope terapÃ©utico avanzado
        fade_time = min(5.0, config.duration_sec * 0.15)
        fade_samples = int(fade_time * self.sample_rate)
        envelope = np.ones(len(t))
        
        # Fade sigmoidal suave
        if fade_samples > 0:
            x_in = np.linspace(-4, 4, fade_samples)
            fade_in = 1 / (1 + np.exp(-x_in))
            envelope[:fade_samples] = fade_in
        
        if fade_samples > 0 and len(t) > fade_samples:
            x_out = np.linspace(4, -4, fade_samples)
            fade_out = 1 / (1 + np.exp(-x_out))
            envelope[-fade_samples:] = fade_out
        
        # ModulaciÃ³n compleja terapÃ©utica
        lfo_primary = np.sin(2 * np.pi * beat_freq * t)
        lfo_healing = 0.2 * np.sin(2 * np.pi * beat_freq * 0.618 * t + np.pi/6)  # Golden ratio
        lfo_depth = 0.1 * np.sin(2 * np.pi * beat_freq * 1.414 * t + np.pi/4)   # Sqrt(2)
        combined_lfo = (lfo_primary + lfo_healing + lfo_depth) / 1.3
        
        # Onda base
        base_wave = np.sin(2 * np.pi * carrier * t)
        am_component = 1 + am_depth * combined_lfo
        fm_component = fm_index * combined_lfo * 0.3
        
        # Frecuencias de sanaciÃ³n Solfeggio
        healing_freqs = [111, 528, 741, 852]
        healing_wave = np.zeros_like(t)
        
        for i, freq in enumerate(healing_freqs):
            if freq != carrier:
                amplitude = 0.08 / (i + 1)
                phase = np.pi * i / 4
                healing_component = amplitude * np.sin(2 * np.pi * freq * t + phase)
                healing_wave += healing_component
        
        # Combinar componentes
        modulated_wave = (base_wave + healing_wave) * am_component
        final_wave = np.sin(2 * np.pi * carrier * t + fm_component) * am_component * 0.6 + modulated_wave * 0.4
        final_wave = final_wave * envelope
        
        # EstÃ©reo con efecto binaural sutil
        left = final_wave
        right = np.sin(2 * np.pi * (carrier + beat_freq * 0.1) * t + fm_component * 0.95) * am_component * envelope
        
        return np.stack([left, right])

    def export_professional_v26(self, filename: str, audio_data: np.ndarray, 
                               config: NeuroConfig, analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ExportaciÃ³n profesional mejorada del V26 Ultimate"""
        try:
            # Preparar canales
            if audio_data.ndim == 1:
                left_channel = right_channel = audio_data
            else:
                left_channel = audio_data[0]
                right_channel = audio_data[1] if audio_data.shape[0] > 1 else audio_data[0]
            
            # Mastering profesional
            if config.apply_mastering:
                left_channel, right_channel = self._apply_professional_mastering(left_channel, right_channel, config)
            
            # ValidaciÃ³n pre-exportaciÃ³n
            quality_check = self._validate_export_quality(left_channel, right_channel)
            
            # Exportar WAV
            export_info = self._export_wav_file(filename, left_channel, right_channel, self.sample_rate)
            export_info.update(quality_check)
            
            # AnÃ¡lisis extendido
            if config.export_analysis and analysis:
                analysis_filename = filename.replace('.wav', '_analysis_v26.json')
                metadata_filename = filename.replace('.wav', '_metadata.json')
                
                self._export_extended_analysis(analysis_filename, config, analysis, quality_check)
                self._export_session_metadata(metadata_filename, config, export_info)
                
                export_info.update({
                    'analysis_file': analysis_filename,
                    'metadata_file': metadata_filename,
                    'extended_export': True
                })
            
            logger.info(f"ExportaciÃ³n profesional V26 completada: {filename}")
            return export_info
            
        except Exception as e:
            logger.error(f"Error en exportaciÃ³n profesional: {e}")
            return self.export_wave_professional(filename, audio_data, config, analysis)

    def _apply_professional_mastering(self, left: np.ndarray, right: np.ndarray, config: NeuroConfig) -> Tuple[np.ndarray, np.ndarray]:
        """Mastering profesional del V26 Ultimate"""
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        stereo_rms = (left_rms + right_rms) / 2
        
        target_rms = 10**(config.target_lufs / 20)
        
        if stereo_rms > 0:
            ratio = target_rms / stereo_rms
            max_gain = 0.95 / max(np.max(np.abs(left)), np.max(np.abs(right)))
            ratio = min(ratio, max_gain)
            left *= ratio
            right *= ratio
        
        # Limitador suave
        left = np.tanh(left * 0.98) * 0.95
        right = np.tanh(right * 0.98) * 0.95
        
        # EQ por neurotransmisor
        if hasattr(config, 'neurotransmitter'):
            enhacement_map = {
                'dopamina': 1.02, 'serotonina': 1.01, 'gaba': 0.99, 'acetilcolina': 1.03
            }
            factor = enhacement_map.get(config.neurotransmitter, 1.0)
            left *= factor
            right *= factor
        
        return left, right

    def _validate_export_quality(self, left: np.ndarray, right: np.ndarray) -> Dict[str, Any]:
        """ValidaciÃ³n de calidad pre-exportaciÃ³n del V26 Ultimate"""
        left_peak = np.max(np.abs(left))
        right_peak = np.max(np.abs(right))
        max_peak = max(left_peak, right_peak)
        
        left_rms = np.sqrt(np.mean(left**2))
        right_rms = np.sqrt(np.mean(right**2))
        
        issues = []
        if max_peak > 0.99: issues.append("Posible clipping detectado")
        if left_rms < 0.001 or right_rms < 0.001: issues.append("Canal muy silencioso")
        if abs(left_rms - right_rms) > 0.1: issues.append("Desbalance estÃ©reo significativo")
        
        quality_score = 100
        quality_score -= len(issues) * 15
        quality_score -= (max_peak > 0.95) * 10
        quality_score -= (abs(left_rms - right_rms) > 0.05) * 5
        
        return {
            "export_peak_level": float(max_peak),
            "left_rms": float(left_rms),
            "right_rms": float(right_rms),
            "stereo_balance": float(abs(left_rms - right_rms)),
            "quality_issues": issues,
            "export_quality_score": max(60, quality_score),
            "ready_for_export": len(issues) == 0 and max_peak <= 0.95
        }

    def _export_extended_analysis(self, filename: str, config: NeuroConfig, 
                                 analysis: Dict[str, Any], quality_check: Dict[str, Any]):
        """ExportaciÃ³n de anÃ¡lisis extendido del V26 Ultimate"""
        try:
            extended_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "aurora_version": VERSION,
                "analysis_type": "extended_v26",
                "configuration": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_sec": config.duration_sec,
                    "wave_type": config.wave_type,
                    "intensity": config.intensity,
                    "style": config.style,
                    "objective": config.objective,
                    "quality_level": config.quality_level.value,
                    "processing_mode": config.processing_mode.value
                },
                "neuroacoustic_analysis": analysis,
                "quality_analysis": quality_check,
                "processing_stats": self.get_processing_stats(),
                "scientific_confidence": analysis.get("confidence", 0.85),
                "effectiveness_metrics": {
                    "neuro_score": analysis.get("neuro_effectiveness", 85),
                    "quality_score": quality_check.get("export_quality_score", 90),
                    "overall_rating": (analysis.get("neuro_effectiveness", 85) + 
                                     quality_check.get("export_quality_score", 90)) / 2
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(extended_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"AnÃ¡lisis extendido exportado: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando anÃ¡lisis extendido: {e}")

    def _export_session_metadata(self, filename: str, config: NeuroConfig, export_info: Dict[str, Any]):
        """ExportaciÃ³n de metadatos de sesiÃ³n del V26 Ultimate"""
        try:
            metadata = {
                "session_id": f"aurora_v27_{int(time.time())}",
                "creation_time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "engine_version": VERSION,
                "audio_file": export_info.get("filename", "unknown.wav"),
                "session_config": {
                    "neurotransmitter": config.neurotransmitter,
                    "duration_seconds": config.duration_sec,
                    "sample_rate": self.sample_rate,
                    "quality_level": config.quality_level.value,
                    "therapeutic_intent": config.therapeutic_intent,
                    "custom_parameters": {
                        "modulation_complexity": config.modulation_complexity,
                        "harmonic_richness": config.harmonic_richness,
                        "spatial_effects": config.enable_spatial_effects
                    }
                },
                "export_summary": {
                    "success": export_info.get("success", False),
                    "file_size_mb": export_info.get("duration_sec", 0) * self.sample_rate * 4 / 1024 / 1024,
                    "quality_validated": export_info.get("ready_for_export", False)
                },
                "usage_recommendations": self._generate_usage_recommendations(config)
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            logger.info(f"Metadatos de sesiÃ³n exportados: {filename}")
            
        except Exception as e:
            logger.error(f"Error exportando metadatos: {e}")

    def _generate_usage_recommendations(self, config: NeuroConfig) -> List[str]:
        """Genera recomendaciones de uso del V26 Ultimate"""
        recommendations = []
        
        nt_recommendations = {
            'dopamina': ["Usar durante tareas que requieren motivaciÃ³n", "Ideal para ejercicio o trabajo creativo"],
            'serotonina': ["Perfecto para meditaciÃ³n y relajaciÃ³n", "Usar antes de dormir"],
            'gaba': ["Excelente para reducir ansiedad", "Usar durante descansos estresantes"],
            'acetilcolina': ["Ideal para estudio y concentraciÃ³n", "Usar durante tareas cognitivas"],
            'oxitocina': ["Perfecto para conexiÃ³n emocional", "Usar en terapia o momentos Ã­ntimos"]
        }
        
        recommendations.extend(nt_recommendations.get(config.neurotransmitter, []))
        
        if config.duration_sec < 300:
            recommendations.append("SesiÃ³n corta: ideal para breaks rÃ¡pidos")
        elif config.duration_sec > 1800:
            recommendations.append("SesiÃ³n larga: usar con auriculares cÃ³modos")
        
        if config.quality_level == NeuroQualityLevel.THERAPEUTIC:
            recommendations.append("Calidad terapÃ©utica: consultar con profesional si es para uso clÃ­nico")
        
        return recommendations
    
    def _normalizar_objetivo_universal(self, objetivo_raw):
        """Normaliza cualquier string objetivo para anÃ¡lisis semÃ¡ntico"""
        import re
        import unicodedata
        
        if not objetivo_raw or not isinstance(objetivo_raw, str):
            return "equilibrio"  # Fallback seguro
        
        # PASO 1: Normalizar Unicode (acentos, Ã±, Ã§, etc.)
        objetivo_unicode = unicodedata.normalize('NFD', objetivo_raw)
        objetivo_ascii = ''.join(c for c in objetivo_unicode if unicodedata.category(c) != 'Mn')
        
        # PASO 2: Limpiar caracteres especiales y normalizar
        objetivo_limpio = re.sub(r'[^\w\s-]', '', objetivo_ascii.lower().strip())
        objetivo_limpio = re.sub(r'\s+', '_', objetivo_limpio)
        objetivo_limpio = re.sub(r'-+', '_', objetivo_limpio)
        objetivo_limpio = re.sub(r'_+', '_', objetivo_limpio).strip('_')
        
        # PASO 3: Mapeo semÃ¡ntico universal
        mapeo_semantico = {
            'relax': 'relajacion', 'tranquil': 'relajacion', 'calm': 'relajacion',
            'paz': 'relajacion', 'descanso': 'relajacion', 'sosiego': 'relajacion',
            'focus': 'concentracion', 'atencion': 'concentracion', 'estudio': 'concentracion',
            'trabajo': 'concentracion', 'productividad': 'concentracion',
            'energy': 'energia', 'vigor': 'energia', 'motivacion': 'energia',
            'activacion': 'energia', 'dinamismo': 'energia',
            'sleep': 'sueno', 'dormir': 'sueno', 'descanso_nocturno': 'sueno',
            'meditation': 'meditacion', 'mindfulness': 'meditacion', 'contempl': 'meditacion',
            'creativity': 'creatividad', 'inspiracion': 'creatividad', 'arte': 'creatividad'
        }
        
        for patron, equivalente in mapeo_semantico.items():
            if patron in objetivo_limpio:
                return equivalente
        
        return objetivo_limpio if objetivo_limpio else "equilibrio"

    def _clasificar_objetivo_neuroacustico(self, objetivo_normalizado):
        """Clasifica el objetivo en categorÃ­as neuroacÃºsticas cientÃ­ficas"""
        
        # CLASIFICACIÃ“N CIENTÃFICA: Basada en investigaciÃ³n neuroacÃºstica
        clasificaciones = {
            'CALMANTE': ['relajacion', 'tranquilidad', 'paz', 'sosiego', 'calma', 'sueno', 'descanso', 'meditacion', 'meditat', 'meditation', 'mindful'],
            'NEUTRO': ['equilibrio', 'balance', 'bienestar', 'armonia', 'meditacion', 'mindfulness'],
            'ACTIVANTE': ['concentracion', 'energia', 'enfoque', 'atencion', 'productividad', 'creatividad', 'motivacion']
        }
        
        for categoria, objetivos in clasificaciones.items():
            if objetivo_normalizado in objetivos:
                return categoria
        
        # AnÃ¡lisis por similitud de substrings
        for categoria, objetivos in clasificaciones.items():
            for obj in objetivos:
                if obj in objetivo_normalizado or objetivo_normalizado in obj:
                    return categoria
        
        return 'NEUTRO'  # Fallback cientÃ­fico seguro

    def _calcular_rms_base_neuroacustico(self, clasificacion):
        """Calcula RMS base cientÃ­fico segÃºn clasificaciÃ³n neuroacÃºstica"""
        
        # BASE CIENTÃFICA: Valores optimizados para eficacia terapÃ©utica
        rms_base_cientifico = {
            'CALMANTE': 0.30,    # RelajaciÃ³n, sueÃ±o, calma
            'NEUTRO': 0.35,      # Balance, meditaciÃ³n
            'ACTIVANTE': 0.40    # ConcentraciÃ³n, energÃ­a
        }
        
        return rms_base_cientifico.get(clasificacion, 0.480)

    def _modular_rms_por_intensidad(self, rms_base, intensidad):
        """Modula RMS segÃºn intensidad especificada"""
        import numpy as np
        
        # Normalizar intensidad
        if isinstance(intensidad, str):
            mapeo_intensidad = {
                'muy_baja': 0.3, 'baja': 0.5, 'suave': 0.6,
                'media': 0.7, 'moderada': 0.8, 'alta': 0.9, 'muy_alta': 1.0,
                'low': 0.5, 'medium': 0.7, 'high': 0.9
            }
            factor_intensidad = mapeo_intensidad.get(intensidad.lower(), 0.7)
        else:
            factor_intensidad = np.clip(float(intensidad), 0.3, 1.0)
        
        return rms_base * (0.7 + 0.5 * factor_intensidad)

    def _ajustar_rms_por_duracion(self, rms_modulado, duracion_sec):
        """Ajusta RMS segÃºn duraciÃ³n para optimizar eficacia terapÃ©utica"""
        import numpy as np
        
        # COMPENSACIÃ“N CIENTÃFICA: Sesiones largas necesitan menos intensidad
        if duracion_sec <= 60:
            factor_duracion = 1.1      # Sesiones cortas: mayor intensidad
        elif duracion_sec <= 300:
            factor_duracion = 1.0      # Sesiones normales: intensidad estÃ¡ndar
        elif duracion_sec <= 900:
            factor_duracion = 0.95     # Sesiones largas: intensidad reducida
        else:
            factor_duracion = 0.9      # Sesiones muy largas: menor intensidad
        
        return rms_modulado * factor_duracion

    def _aplicar_limites_seguridad_neuroacustica(self, rms_ajustado):
        """Aplica lÃ­mites de seguridad neuroacÃºstica"""
        import numpy as np
        
        # LÃMITES DE SEGURIDAD: Prevenir fatiga auditiva y garantizar eficacia
        RMS_MIN_TERAPEUTICO = 0.25   # MÃ­nimo para efecto neuroacÃºstico
        RMS_MAX_SEGURO = 0.75        # MÃ¡ximo para seguridad auditiva
        
        return np.clip(rms_ajustado, RMS_MIN_TERAPEUTICO, RMS_MAX_SEGURO)

    def _aplicar_amplificacion_inteligente(self, audio_data, factor_adaptativo):
        """Aplica amplificaciÃ³n neuroacÃºstica inteligente"""
        import numpy as np
        
        # AMPLIFICACIÃ“N ADAPTATIVA: Preserva caracterÃ­sticas mientras alcanza objetivo
        if factor_adaptativo > 2.0:
            # AmplificaciÃ³n grande: aplicar suavizado
            factor_suavizado = 2.0 + 0.3 * (factor_adaptativo - 2.0)
            audio_amplificado = audio_data * factor_suavizado
        elif factor_adaptativo < 0.5:
            # ReducciÃ³n grande: aplicar compresiÃ³n suave
            factor_compresion = 0.5 + 0.5 * factor_adaptativo
            audio_amplificado = audio_data * factor_compresion
        else:
            # Rango normal: amplificaciÃ³n directa
            audio_amplificado = audio_data * factor_adaptativo
        
        # NormalizaciÃ³n suave para prevenir clipping
        max_val = np.max(np.abs(audio_amplificado))
        if max_val > 0.95:
            audio_amplificado = audio_amplificado * (0.95 / max_val)
        
        return audio_amplificado

    def _validar_rms_final_objetivo(self, audio_final, rms_objetivo):
        """Valida si el RMS final alcanza el objetivo neuroacÃºstico"""
        import numpy as np
        
        rms_final = np.sqrt(np.mean(audio_final**2))
        diferencia_relativa = abs(rms_final - rms_objetivo) / rms_objetivo
        
        # CRITERIO CIENTÃFICO: Â±10% tolerancia para eficacia terapÃ©utica
        tolerancia = 0.20
        exito = diferencia_relativa <= tolerancia
        
        return {
            'exito': exito,
            'rms_final': rms_final,
            'rms_objetivo': rms_objetivo,
            'diferencia_relativa': diferencia_relativa,
            'tolerancia': tolerancia
        }
    
    def _aplicar_amplificacion_directa_objetivo(self, audio_data, rms_objetivo):
        """MÃ©todo alternativo: amplificaciÃ³n directa al RMS objetivo"""
        import numpy as np
        
        rms_actual = np.sqrt(np.mean(audio_data**2))
        
        if rms_actual <= 0:
            logger.warning("âš ï¸ RMS actual es 0, no se puede amplificar")
            return audio_data
        
        factor_exacto = rms_objetivo / rms_actual
        logger.debug(f"ðŸŽ¯ AmplificaciÃ³n directa: {rms_actual:.3f} â†’ {rms_objetivo:.3f} (factor: {factor_exacto:.3f})")
        
        audio_amplificado = audio_data * factor_exacto
        
        # Verificar clipping
        max_val = np.max(np.abs(audio_amplificado))
        if max_val > 0.99:
            factor_seguridad = 0.99 / max_val
            audio_amplificado = audio_amplificado * factor_seguridad
            logger.warning(f"âš ï¸ Clipping detectado, factor de seguridad: {factor_seguridad:.3f}")
        
        rms_final = np.sqrt(np.mean(audio_amplificado**2))
        logger.info(f"ðŸŽ¯ RMS final verificado: {rms_final:.3f} (objetivo: {rms_objetivo:.3f})")
        
        return audio_amplificado

_global_engine = AuroraNeuroAcousticEngineV27(enable_advanced_features=True)

def capa_activada(nombre_capa: str, objetivo: dict) -> bool:
    excluidas = objetivo.get("excluir_capas", [])
    return nombre_capa not in excluidas

def get_neuro_preset(neurotransmitter: str) -> dict:
    return _global_engine.get_neuro_preset(neurotransmitter)

def get_adaptive_neuro_preset(neurotransmitter: str, intensity: str = "media", style: str = "neutro", objective: str = "relajaciÃ³n") -> dict:
    return _global_engine.get_adaptive_neuro_preset(neurotransmitter, intensity, style, objective)

def generate_neuro_wave(neurotransmitter: str, duration_sec: float, wave_type: str = 'hybrid',
                       sample_rate: int = SAMPLE_RATE, seed: int = None, intensity: str = "media",
                       style: str = "neutro", objective: str = "relajaciÃ³n", adaptive: bool = True) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    config = NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type=wave_type,
                        intensity=intensity, style=style, objective=objective,
                        processing_mode=ProcessingMode.LEGACY if not adaptive else ProcessingMode.STANDARD)
    
    audio_data, _ = _global_engine.generate_neuro_wave_advanced(config)
    return audio_data

def export_wave_stereo(filename, left_channel, right_channel, sample_rate=SAMPLE_RATE):
    return _global_engine._export_wav_file(filename, left_channel, right_channel, sample_rate)

def get_neurotransmitter_suggestions(objective: str) -> list:
    suggestions = {
        "relajaciÃ³n": ["serotonina", "gaba", "oxitocina", "melatonina"],
        "claridad mental + enfoque cognitivo": ["acetilcolina", "dopamina", "glutamato"],
        "activaciÃ³n lÃºcida": ["dopamina", "noradrenalina", "acetilcolina"],
        "meditaciÃ³n profunda": ["gaba", "serotonina", "melatonina"],
        "energÃ­a creativa": ["dopamina", "acetilcolina", "glutamato"],
        "sanaciÃ³n emocional": ["oxitocina", "serotonina", "endorfinas"],
        "expansiÃ³n consciencia": ["gaba", "serotonina", "oxitocina"],
        "concentracion": ["acetilcolina", "dopamina", "norepinefrina"],
        "creatividad": ["dopamina", "acetilcolina", "anandamida"],
        "meditacion": ["gaba", "serotonina", "melatonina"]
    }
    return suggestions.get(objective, ["dopamina", "serotonina"])

def create_aurora_config(neurotransmitter: str, duration_sec: float, **kwargs) -> NeuroConfig:
    return NeuroConfig(neurotransmitter=neurotransmitter, duration_sec=duration_sec, **kwargs)

def generate_aurora_session(config: NeuroConfig) -> Tuple[np.ndarray, Dict[str, Any]]:
    return _global_engine.generate_neuro_wave_advanced(config)

def get_aurora_info() -> Dict[str, Any]:
    engine = _global_engine
    return {
        "version": VERSION, "compatibility": "V26/V27/PPP Full + Aurora Director V7 Integration",
        "motor": "NeuroMix V27 Complete",
        "features": {"ppp_compatibility": True, "aurora_director_integration": True,
                    "advanced_generation": engine.enable_advanced, "quality_pipeline": True,
                    "parallel_processing": True, "neuroacoustic_analysis": True,
                    "therapeutic_optimization": True, "fallback_guaranteed": True},
        "capabilities": engine.obtener_capacidades(),
        "neurotransmitters": engine.get_available_neurotransmitters(),
        "wave_types": engine.get_available_wave_types(),
        "stats": engine.get_processing_stats()
    }

def generate_contextual_neuro_wave(neurotransmitter: str, duration_sec: float, context: Dict[str, Any],
                                  sample_rate: int = SAMPLE_RATE, seed: int = None, **kwargs) -> np.ndarray:
    
    if seed is not None: np.random.seed(seed)
    
    intensity = context.get("intensidad", "media")
    style = context.get("estilo", "neutro")
    objective = context.get("objetivo_funcional", "relajaciÃ³n")
    
    return generate_neuro_wave(neurotransmitter=neurotransmitter, duration_sec=duration_sec, wave_type='hybrid',
                              sample_rate=sample_rate, intensity=intensity, style=style, objective=objective, adaptive=True)

generate_contextual_neuro_wave_adaptive = generate_contextual_neuro_wave

# ================================================================
# INTEGRACIÃ“N HÃBRIDA OPTIMIZADA - NEUROMIX SUPER UNIFICADO
# ================================================================
# CORRECCIÃ“N APLICADA: Estructura limpia + mÃ©todo obtener_capacidades()
try:
    import neuromix_definitivo_v7
    if hasattr(neuromix_definitivo_v7, 'NeuroMixSuperUnificado'):
        
        # ================================================================
        # ðŸ”§ CORRECCIÃ“N DEFINITIVA: COMPOSICIÃ“N EN LUGAR DE HERENCIA
        # ================================================================
        # PROBLEMA ELIMINADO: class AuroraNeuroAcousticEngineV27Connected(neuromix_definitivo_v7.NeuroMixSuperUnificado)
        # SOLUCIÃ“N APLICADA: Clase independiente con composiciÃ³n controlada
        
        class AuroraNeuroAcousticEngineV27Connected:
            """
            ðŸš« SIN HERENCIA CIRCULAR - VersiÃ³n ComposiciÃ³n Segura
            
            ANTES: Connected hereda de Super â†’ Super llama Factory â†’ Factory devuelve Connected â†’ BUCLE INFINITO
            AHORA: Connected usa motor_base directamente â†’ Sin auto-referencia â†’ Sin bucles
            
            AnalogÃ­a: En lugar de ser "hijo de la serpiente que se muerde la cola",
            ahora es un "usuario independiente" que colabora con el motor original.
            """
            
            def __init__(self):
                # ðŸ”§ COMPOSICIÃ“N SEGURA: Motor base independiente
                self.motor_base = _global_engine if '_global_engine' in globals() else None  # Usar motor global
                self.super_motor = None  # Se inicializa solo si es seguro
                
                # ConfiguraciÃ³n de la versiÃ³n Connected
                self.version = "V27_AURORA_CONNECTED_ANTI_OUROBOROS"
                self.enable_advanced = True
                
                # Logger especÃ­fico para debugging
                self.logger = logging.getLogger("Aurora.NeuroMix.V27.Connected.Fixed")
                self.logger.setLevel(logging.INFO)
                
                # Intentar inicializar super_motor DE FORMA SEGURA
                # self._inicializar_super_motor_seguro() # COMENTADO TEMPORALMENTE PARA EVITAR RECURSIÃ“N
                
                self.logger.info("âœ… AuroraNeuroAcousticEngineV27Connected inicializado SIN herencia circular")
            
            def _inicializar_super_motor_seguro(self):
                """
                Inicializa super_motor evitando auto-referencia
                
                PROTECCIÃ“N: Solo crea NeuroMixSuperUnificado si no genera ciclos
                """
                try:
                    # VERIFICACIÃ“N ANTI-CIRCULAR: No usar factory para evitar auto-referencia
                    # En lugar de: neuromix_definitivo_v7.NeuroMixSuperUnificado() que podrÃ­a llamar al factory
                    # Crear directamente sin dependencias circulares
                    
                    # Crear NeuroMixSuperUnificado con motor_base especÃ­fico
                    self.super_motor = neuromix_definitivo_v7.NeuroMixSuperUnificadoRefactored(
                        neuromix_base=self.motor_base  # Pasar motor base explÃ­citamente
                    )
                    
                    self.logger.info("ðŸ”§ Super motor inicializado de forma segura")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ No se pudo inicializar super motor: {e}")
                    self.super_motor = None
            
            # ================================================================
            # MÃ‰TODOS PRINCIPALES - USANDO COMPOSICIÃ“N, NO HERENCIA
            # ================================================================
            
            def generar_audio(self, config, duracion_sec=None):
                """
                ðŸ”§ MÃ‰TODO PRINCIPAL SIN HERENCIA CIRCULAR
                
                ANTES: super().generar_audio() â†’ NeuroMixSuperUnificado â†’ Factory â†’ Connected â†’ BUCLE
                AHORA: motor_base.generar_audio() directamente â†’ Sin ciclos
                """
                
                try:
                    # ESTRATEGIA 1: Usar super_motor si estÃ¡ disponible y es seguro
                    if self.super_motor:
                        # Unificar parÃ¡metros para compatibilidad con NeuroMixSuperUnificado
                        if duracion_sec is not None:
                            if isinstance(config, dict):
                                config['duracion_sec'] = duracion_sec
                            else:
                                # Convertir a diccionario si es necesario
                                config_dict = config.__dict__ if hasattr(config, '__dict__') else {'config': config}
                                config_dict['duracion_sec'] = duracion_sec
                                config = config_dict
                        
                        resultado = self.super_motor.generar_audio(config)
                        self.logger.info(f"âœ… Audio generado con super_motor: {resultado.shape if hasattr(resultado, 'shape') else type(resultado)}")
                        return resultado
                    
                    # ESTRATEGIA 2: Usar motor_base directamente (SIEMPRE FUNCIONA)
                    resultado = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                    self.logger.info(f"âœ… Audio generado con motor_base: {resultado.shape}")
                    return resultado
                    
                except Exception as e:
                    self.logger.error(f"âŒ Error en generar_audio: {e}")
                    
                    # ESTRATEGIA 3: Fallback garantizado usando motor_base
                    try:
                        resultado_fallback = self.motor_base.generar_audio(config, duracion_sec or 10.0)
                        self.logger.info(f"ðŸ”§ Audio generado con fallback: {resultado_fallback.shape}")
                        return resultado_fallback
                    except Exception as e2:
                        self.logger.error(f"âŒ Error crÃ­tico en fallback: {e2}")
                        # Fallback extremo: generar audio bÃ¡sico
                        import numpy as np
                        return np.random.randn(int(44100 * (duracion_sec or 10.0))) * 0.1
            
            # ================================================================
            # MÃ‰TODOS DE COMPATIBILIDAD V27
            # ================================================================
            
            def get_available_neurotransmitters(self):
                """Compatibilidad V27"""
                return ["dopamina", "serotonina", "gaba", "oxitocina", "acetilcolina", "endorfina"]
            
            def get_available_wave_types(self):
                """Tipos de ondas disponibles"""
                return ["binaural", "isocronico", "hybrid", "therapeutic"]
            
            def get_processing_stats(self):
                """EstadÃ­sticas de procesamiento combinadas"""
                stats = {
                    "connected_version": self.version,
                    "motor_base_available": self.motor_base is not None,
                    "super_motor_available": self.super_motor is not None,
                    "anti_ouroboros_active": True
                }
                
                # Agregar stats del motor_base si estÃ¡ disponible
                if self.motor_base and hasattr(self.motor_base, 'get_processing_stats'):
                    try:
                        stats.update(self.motor_base.get_processing_stats())
                    except:
                        pass
                
                # Agregar stats del super_motor si estÃ¡ disponible
                if self.super_motor and hasattr(self.super_motor, 'get_processing_stats'):
                    try:
                        super_stats = self.super_motor.get_processing_stats()
                        stats.update({f"super_{k}": v for k, v in super_stats.items()})
                    except:
                        pass
                
                return stats
            
            def obtener_capacidades(self):
                """
                MÃ©todo requerido para compatibilidad con Aurora Director V7
                """
                return {
                    "nombre": f"NeuroMix V27 Connected ANTI-OUROBOROS - {self.version}",
                    "tipo": "motor_neuroacustico_connected_safe",
                    "aurora_v27_connected": True,
                    "anti_circular": True,
                    "composition_based": True,
                    "motor_base_active": self.motor_base is not None,
                    "super_motor_active": self.super_motor is not None,
                    "message": "ConexiÃ³n segura sin herencia circular"
                }
            
            def generate_neuro_wave_advanced(self, config):
                """Compatibilidad con mÃ©todo avanzado"""
                try:
                    if self.super_motor and hasattr(self.super_motor, 'generate_neuro_wave_advanced'):
                        return self.super_motor.generate_neuro_wave_advanced(config)
                    
                    # Fallback usando motor_base
                    if hasattr(self.motor_base, 'generate_neuro_wave_advanced'):
                        return self.motor_base.generate_neuro_wave_advanced(config)
                    
                    # Fallback bÃ¡sico
                    audio = self.generar_audio(config.__dict__ if hasattr(config, '__dict__') else config, 2.0)
                    return audio, {"quality_score": 85, "anti_ouroboros": True}
                    
                except Exception as e:
                    self.logger.error(f"Error en generate_neuro_wave_advanced: {e}")
                    # Generar audio bÃ¡sico como Ãºltimo recurso
                    import numpy as np
                    audio = np.random.randn(int(44100 * 2.0)) * 0.1
                    return audio, {"quality_score": 50, "fallback": True}
                
            def validar_configuracion(self, config: Dict[str, Any]) -> bool:
                """Valida configuraciÃ³n Aurora para NeuroMix V27"""
                try:
                    if not isinstance(config, dict):
                        return False
                        
                    # Campos requeridos
                    campos_requeridos = ['objetivo', 'duracion_sec', 'intensidad']
                    if not all(campo in config for campo in campos_requeridos):
                        return False
                        
                    # Validar rangos
                    duracion = config.get('duracion_sec', 0)
                    if not (1 <= duracion <= 3600):
                        return False
                        
                    intensidad = config.get('intensidad', 0)
                    if not (0.1 <= intensidad <= 1.0):
                        return False
                        
                    # Validar objetivo
                    objetivos_validos = ['relajacion', 'concentracion', 'energia', 'sueno', 'meditacion']
                    if config.get('objetivo') not in objetivos_validos:
                        return False
                        
                    return True
                    
                except Exception:
                    return False

            def get_info(self) -> Dict[str, str]:
                """InformaciÃ³n bÃ¡sica del motor NeuroMix V27"""
                try:
                    return {
                        'nombre': 'NeuroMix Aurora V27 Connected',
                        'version': 'V27_AURORA_CONNECTED_COMPLETE_SYNC_FIXED',
                        'tipo': 'motor_neuroacustico',
                        'descripcion': 'Motor neuroacÃºstico principal con integraciÃ³n Aurora Director V7',
                        'estado': 'conectado_aurora_director',
                        'capacidades': 'binaural,isochronic,neurotransmitters',
                        'compatibilidad': 'aurora_director_v7'
                    }
                except Exception:
                    return {'nombre': 'NeuroMix Aurora V27', 'estado': 'error'}
        
        # ================================================================
        # ASIGNACIÃ“N DE ALIAS (PRESERVANDO COMPATIBILIDAD)
        # ================================================================
        
        # Reemplazar la clase original por la versiÃ³n sin herencia circular
        # AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected # COMENTADO: CAUSA RECURSIÃ“N INFINITA
        
        print("ðŸš«ðŸ OUROBOROS ELIMINADO: NeuroMix Connected ahora usa composiciÃ³n segura")
        print("âœ… Herencia circular â†’ ComposiciÃ³n funcional")
        print("âœ… Bucle infinito â†’ Flujo controlado")
        print("âœ… Auto-referencia â†’ Motor base independiente")
        
    else:
        raise ImportError('NeuroMixSuperUnificado no disponible')
        
except ImportError:
    print("ðŸ’¡ NeuroMix Super no disponible, usando motor base sin modificaciones")
    # El motor base AuroraNeuroAcousticEngineV27 sigue funcionando normalmente
    pass
        
except Exception as e:
    print(f"âš ï¸ Error aplicando correcciÃ³n anti-Ouroboros: {e}")
    print("ðŸ”§ Motor base mantiene funcionalidad completa como fallback")

# ================================================================
# VERIFICACIÃ“N DE CORRECCIÃ“N APLICADA
# ================================================================

def verificar_correccion_ouroboros():
    """
    Verifica que la correcciÃ³n anti-Ouroboros se aplicÃ³ correctamente
    """
    try:
        # Verificar que AuroraNeuroAcousticEngineV27Connected no hereda de NeuroMixSuperUnificado
        if 'AuroraNeuroAcousticEngineV27Connected' in globals():
            clase_connected = globals()['AuroraNeuroAcousticEngineV27Connected']
            
            # Verificar que NO hereda de NeuroMixSuperUnificado
            parent_classes = [cls.__name__ for cls in clase_connected.__bases__]
            
            if 'NeuroMixSuperUnificado' not in parent_classes:
                print("âœ… CORRECCIÃ“N VERIFICADA: Sin herencia circular")
                print(f"   â€¢ Clases padre: {parent_classes}")
                print("   â€¢ ComposiciÃ³n segura aplicada")
                return True
            else:
                print("âŒ ADVERTENCIA: Herencia circular aÃºn presente")
                return False
        else:
            print("âš ï¸ AuroraNeuroAcousticEngineV27Connected no encontrada")
            return False
            
    except Exception as e:
        print(f"âš ï¸ Error verificando correcciÃ³n: {e}")
        return False

# Ejecutar verificaciÃ³n automÃ¡ticamente
verificar_correccion_ouroboros()

class NeuroMixAuroraV7Adapter:
    """Adaptador que preserva funcionalidad original + compatibilidad Aurora V7"""
    
    def __init__(self, engine_original=None):
        # Usar engine original si estÃ¡ disponible
        if engine_original:
            self.engine = engine_original
        elif '_global_engine' in globals():
            self.engine = _global_engine
        elif 'AuroraNeuroAcousticEngine' in globals():
            self.engine = AuroraNeuroAcousticEngine()
        elif '_global_engine' in globals():
            self.engine = _global_engine
        else:
            # Crear engine bÃ¡sico si no hay nada
            self.engine = self._crear_engine_basico()
        
        self.version = getattr(self.engine, 'version', 'V27_ADITIVO')
        logger.info("ðŸ”§ NeuroMix Aurora V7 Adapter inicializado")
    
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """MÃ©todo principal compatible con Aurora Director V7"""
        try:
            # Si el engine tiene mÃ©todo directo, usarlo
            if hasattr(self.engine, 'generar_audio'):
                return self.engine.generar_audio(config, duracion_sec)
            
            # Si tiene mÃ©todo Aurora, usarlo
            if hasattr(self.engine, 'generate_neuro_wave'):
                return self._usar_generate_neuro_wave(config, duracion_sec)
            
            # Fallback usando funciones globales
            return self._generar_usando_funciones_globales(config, duracion_sec)
            
        except Exception as e:
            logger.error(f"Error en generar_audio: {e}")
            return self._generar_fallback(duracion_sec)
    
    def _usar_generate_neuro_wave(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar mÃ©todo generate_neuro_wave existente"""
        neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
        if not neurotransmisor or neurotransmisor == 'auto':
            neurotransmisor = self._inferir_neurotransmisor(config.get('objetivo', 'relajacion'))
        
        intensidad = config.get('intensidad', 'media')
        estilo = config.get('estilo', 'neutro')
        objetivo = config.get('objetivo', 'relajacion')
        
        return self.engine.generate_neuro_wave(
            neurotransmisor, duracion_sec, 'hybrid',
            intensity=intensidad, style=estilo, objective=objetivo
        )
    
    def _generar_usando_funciones_globales(self, config: Dict[str, Any], duracion_sec: float) -> np.ndarray:
        """Usar funciones globales si estÃ¡n disponibles"""
        if 'generate_neuro_wave' in globals():
            neurotransmisor = config.get('neurotransmisor_preferido', 'serotonina')
            intensidad = config.get('intensidad', 'media')
            estilo = config.get('estilo', 'neutro')
            objetivo = config.get('objetivo', 'relajacion')
            
            return generate_neuro_wave(
                neurotransmisor, duracion_sec, 'hybrid',
                intensity=intensidad, style=estilo, objective=objetivo
            )
        else:
            return self._generar_fallback(duracion_sec)
    
    def _inferir_neurotransmisor(self, objetivo: str) -> str:
        """Inferir neurotransmisor basado en objetivo"""
        mapeo = {
            'concentracion': 'acetilcolina', 'claridad_mental': 'dopamina',
            'enfoque': 'norepinefrina', 'relajacion': 'gaba',
            'meditacion': 'serotonina', 'creatividad': 'anandamida'
        }
        objetivo_lower = objetivo.lower()
        for key, nt in mapeo.items():
            if key in objetivo_lower:
                return nt
        return 'serotonina'
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Validar configuraciÃ³n Aurora Director"""
        try:
            if hasattr(self.engine, 'validar_configuracion'):
                return self.engine.validar_configuracion(config)
            
            # ValidaciÃ³n bÃ¡sica
            if not isinstance(config, dict):
                return False
            
            objetivo = config.get('objetivo', '')
            if not isinstance(objetivo, str) or not objetivo.strip():
                return False
            
            duracion = config.get('duracion_min', 20)
            if not isinstance(duracion, (int, float)) or duracion <= 0:
                return False
            
            return True
        except Exception:
            return False
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Obtener capacidades del motor"""
        try:
            if hasattr(self.engine, 'obtener_capacidades'):
                caps = self.engine.obtener_capacidades()
                caps.update({
                    "adapter_aditivo": True,
                    "funcionalidad_original_preservada": True,
                    "compatible_aurora_director_v7": True
                })
                return caps
            
            # Capacidades bÃ¡sicas
            return {
                "nombre": f"NeuroMix V27 Aurora Adapter - {self.version}",
                "tipo": "motor_neuroacustico_adapter",
                "funcionalidad_original_preservada": True,
                "compatible_aurora_director_v7": True,
                "protocolo_motor_aurora": True,
                "engine_subyacente": type(self.engine).__name__,
                "adapter_aditivo": True
            }
        except Exception:
            return {
                "nombre": "NeuroMix V27 Basic",
                "fallback_mode": True
            }
    
    def _crear_engine_basico(self):
        """Crear engine bÃ¡sico si no hay ninguno disponible"""
        class EngineBasico:
            def __init__(self):
                self.version = "basico_v1"
            
            def generar_audio(self, config, duracion_sec):
                import numpy as np
                samples = int(44100 * duracion_sec)
                freq = 10.0
                t = np.linspace(0, duracion_sec, samples)
                wave = 0.3 * np.sin(2 * np.pi * freq * t)
                return np.stack([wave, wave])
        
        return EngineBasico()
    
    def _generar_fallback(self, duracion_sec: float) -> np.ndarray:
        """Generar audio de fallback"""
        import numpy as np
        samples = int(44100 * duracion_sec)
        t = np.linspace(0, duracion_sec, samples)
        wave = 0.3 * np.sin(2 * np.pi * 10.0 * t)
        return np.stack([wave, wave])

# Crear instancias compatibles con Aurora Director V7
def crear_neuromix_aurora_v7():
    """Crear NeuroMix compatible con Aurora Director V7"""
    return NeuroMixAuroraV7Adapter()

# Alias principal para Aurora Director V7
if 'AuroraNeuroAcousticEngineV27' in globals():
    pass  # Si existe el engine original, usarlo
else:
    pass  # Si no, usar adapter
    # Si existe el engine original, usarlo
# Clase principal compatible con Aurora Director V7
class NeuroMix(NeuroMixAuroraV7Adapter):
    """Clase principal NeuroMix compatible con Aurora Director V7"""
    pass

# FunciÃ³n de conveniencia para Aurora Director
def crear_neuromix_seguro():
    """Crear NeuroMix de manera segura preservando funcionalidad"""
    return NeuroMix()

class NeuroMixAuroraV27:
    """
    Wrapper avanzado del motor NeuroMix Aurora V27
    
    PROPÃ“SITO: Interfaz limpia, estable y extendible que unifica todas
    las funcionalidades del ecosistema NeuroMix bajo un wrapper estÃ¡ndar.
    
    CARACTERÃSTICAS:
    - ComposiciÃ³n sobre herencia (evita dependencias circulares)
    - Modos configurables (cientÃ­fico, adaptativo, terapÃ©utico)
    - Lazy loading de motores (eficiencia de memoria)
    - Sistema de presets avanzado
    - Control de logging y debugging
    - Preparado para batch processing futuro
    
    COMPATIBILIDAD TOTAL: Aurora Director V7, objective_manager, GUI
    """
    
    def __init__(self, modo='cientifico', silent=False, cache_enabled=True):
        """
        InicializaciÃ³n del wrapper con configuraciÃ³n flexible
        
        Args:
            modo: 'cientifico', 'adaptativo', 'terapeutico', 'creativo', 'performance'
            silent: Controla el logging detallado
            cache_enabled: Habilita cachÃ© de presets para optimizaciÃ³n
        """
        self.modo = modo
        self.silent = silent
        self.cache_enabled = cache_enabled
        self.version = f"{VERSION}_WRAPPER_V7"
        
        # Lazy loading de motores (solo se crean cuando se necesitan)
        self._motor_cientifico = None
        self._motor_conectado = None
        self._motor_adapter = None
        
        # Sistema de cachÃ© inteligente
        self._preset_cache = {} if cache_enabled else None
        
        # EstadÃ­sticas de uso
        self._stats = {
            "presets_aplicados": 0,
            "generaciones_exitosas": 0,
            "modo_actual": modo,
            "inicializado": datetime.now().isoformat()
        }
        
        # Configurar logging
        self._setup_logging()
        
        if not self.silent:
            logger.info(f"ðŸš€ NeuroMixAuroraV27 inicializado - Modo: {modo}")
    
    def _setup_logging(self):
        """Configura el sistema de logging segÃºn el modo silent"""
        if self.silent:
            logger.setLevel(logging.ERROR)
        else:
            logger.setLevel(logging.INFO)
    
    @property
    def motor_cientifico(self):
        """Lazy loading del sistema cientÃ­fico"""
        if self._motor_cientifico is None:
            self._motor_cientifico = SistemaNeuroacusticoCientificoV27()
            if not self.silent:
                logger.debug("ðŸ§¬ Motor cientÃ­fico inicializado")
        return self._motor_cientifico
    
    @property
    def motor_conectado(self):
        """Lazy loading del motor conectado"""
        if self._motor_conectado is None:
            # Usar motor conectado si estÃ¡ disponible, sino usar base
            if 'AuroraNeuroAcousticEngineV27Connected' in globals():
                self._motor_conectado = AuroraNeuroAcousticEngineV27Connected()
            else:
                self._motor_conectado = AuroraNeuroAcousticEngineV27()
            if not self.silent:
                logger.debug("âš¡ Motor conectado inicializado")
        return self._motor_conectado
    
    @property
    def motor_adapter(self):
        """Lazy loading del adaptador"""
        if self._motor_adapter is None:
            self._motor_adapter = NeuroMixAuroraV7Adapter(self.motor_conectado)
            if not self.silent:
                logger.debug("ðŸ”§ Adaptador inicializado")
        return self._motor_adapter
    
    def aplicar_presets(self, nombre: str, intensidad: str = "media", 
                       estilo: str = "neutro", objetivo: str = "relajacion") -> dict:
        """
        Aplica presets neuroacÃºsticos segÃºn el modo configurado
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            intensidad: "muy_baja", "baja", "media", "alta", "muy_alta"
            estilo: "neutro", "sereno", "mistico", "crystalline", "tribal"
            objetivo: "relajacion", "concentracion", "creatividad", "meditacion"
            
        Returns:
            Dict con preset normalizado listo para generar audio
        """
        try:
            # Verificar cachÃ© primero
            cache_key = f"{nombre}_{intensidad}_{estilo}_{objetivo}_{self.modo}"
            if self.cache_enabled and cache_key in self._preset_cache:
                if not self.silent:
                    logger.debug(f"ðŸ“¦ Preset cargado desde cachÃ©: {cache_key}")
                return self._preset_cache[cache_key]
            
            # Generar preset segÃºn modo
            if self.modo == 'cientifico':
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            elif self.modo == 'adaptativo':
                preset = self.motor_cientifico.crear_preset_adaptativo_ppp(
                    nombre, intensidad, estilo, objetivo
                )
            elif self.modo == 'terapeutico':
                preset = self._generar_preset_terapeutico(nombre, objetivo)
            elif self.modo == 'creativo':
                preset = self._generar_preset_creativo(nombre, intensidad, estilo)
            elif self.modo == 'performance':
                preset = self._generar_preset_performance(nombre)
            else:
                # Modo por defecto: cientÃ­fico
                preset = self.motor_cientifico.obtener_preset_cientifico(nombre)
            
            # Normalizar preset
            preset_normalizado = self._normalizar_preset(preset)
            
            # Guardar en cachÃ©
            if self.cache_enabled:
                self._preset_cache[cache_key] = preset_normalizado
            
            # Actualizar estadÃ­sticas
            self._stats["presets_aplicados"] += 1
            
            if not self.silent:
                logger.info(f"âœ… Preset aplicado: {nombre} ({self.modo})")
            
            return preset_normalizado
            
        except Exception as e:
            logger.error(f"âŒ Error aplicando preset {nombre}: {e}")
            # Fallback a preset bÃ¡sico
            return self._generar_preset_fallback(nombre)
    
    def generate_neuro_wave(self, config: dict, gain_db: float = -12.0):
        """
        Genera audio neuroacÃºstico usando el motor conectado
        
        Args:
            config: ConfiguraciÃ³n de generaciÃ³n
            gain_db: Ganancia en dB para el audio final
            
        Returns:
            numpy.ndarray con audio generado
        """
        try:
            # Validar configuraciÃ³n primero
            if not self.motor_adapter.validar_configuracion(config):
                raise ValueError("ConfiguraciÃ³n invÃ¡lida")
            
            # Generar audio
            duracion = config.get('duracion', config.get('duration_sec', 60.0))
            audio = self.motor_adapter.generar_audio(config, duracion)
            
            # Aplicar ganancia si es necesario
            if gain_db != 0.0:
                gain_linear = 10 ** (gain_db / 20)
                audio = audio * gain_linear
            
            self._stats["generaciones_exitosas"] += 1
            
            if not self.silent:
                logger.info(f"ðŸŽµ Audio generado exitosamente ({len(audio)} samples)")
            
            return audio
            
        except Exception as e:
            logger.error(f"âŒ Error generando audio: {e}")
            # Fallback a generaciÃ³n bÃ¡sica
            return self._generar_audio_fallback(config.get('duracion', 60.0))
    
    def get_capabilities(self):
        """Expone capacidades del motor de forma segura"""
        try:
            caps_base = self.motor_adapter.obtener_capacidades()
            caps_wrapper = {
                "wrapper_version": self.version,
                "modo": self.modo,
                "modos_disponibles": ["cientifico", "adaptativo", "terapeutico", "creativo", "performance"],
                "cache_enabled": self.cache_enabled,
                "silent_mode": self.silent,
                "stats": self._stats.copy()
            }
            
            # Combinar capacidades
            return {**caps_base, "wrapper": caps_wrapper}
            
        except Exception as e:
            logger.error(f"Error obteniendo capacidades: {e}")
            return {"error": str(e), "fallback": True}
    
    def get_preset_info(self, nombre: str) -> dict:
        """
        Obtiene informaciÃ³n detallada de un preset sin aplicarlo
        
        Args:
            nombre: Nombre del preset/neurotransmisor
            
        Returns:
            Dict con informaciÃ³n del preset
        """
        try:
            preset_info = {
                "nombre": nombre,
                "disponible": nombre.lower() in self.motor_cientifico.presets_cientificos,
                "modo_recomendado": self._recomendar_modo_preset(nombre),
                "neurotransmisor_valido": nombre.lower() in [nt.value for nt in Neurotransmisor]
            }
            
            if preset_info["disponible"]:
                preset_data = self.motor_cientifico.obtener_preset_cientifico(nombre)
                preset_info.update({
                    "carrier_freq": preset_data.get("carrier", 0),
                    "beat_freq": preset_data.get("beat_freq", 0),
                    "confidence": preset_data.get("confidence", 0.5)
                })
            
            return preset_info
            
        except Exception as e:
            logger.error(f"Error obteniendo info de preset {nombre}: {e}")
            return {"nombre": nombre, "error": str(e)}
    
    def _normalizar_preset(self, preset_obj):
        """Normaliza presets a formato estÃ¡ndar Aurora"""
        if isinstance(preset_obj, dict):
            return preset_obj
        elif hasattr(preset_obj, '__dict__'):
            return vars(preset_obj)
        elif hasattr(preset_obj, '_asdict'):  # namedtuple
            return preset_obj._asdict()
        else:
            raise TypeError(f"Formato de preset no soportado: {type(preset_obj)}")
    
    def _generar_preset_terapeutico(self, nombre: str, objetivo: str) -> dict:
        """Genera preset optimizado para uso terapÃ©utico"""
        base = self.motor_cientifico.obtener_preset_cientifico(nombre)
        
        # Ajustes terapÃ©uticos
        ajustes_terapeuticos = {
            "am_depth": base.get("am_depth", 0.5) * 0.8,  # MÃ¡s suave
            "fm_index": base.get("fm_index", 3) * 0.9,    # Menos complejo
            "therapeutic_mode": True,
            "objetivo_terapeutico": objetivo
        }
        
        return {**base, **ajustes_terapeuticos}
    
    def _generar_preset_creativo(self, nombre: str, intensidad: str, estilo: str) -> dict:
        """Genera preset optimizado para creatividad"""
        base = self.motor_cientifico.crear_preset_adaptativo_ppp(nombre, intensidad, estilo, "creatividad")
        
        # Potenciar aspectos creativos
        base["fm_index"] = base.get("fm_index", 3) * 1.2  # MÃ¡s complejidad
        base["creative_enhancement"] = True
        
        return base
    
    def _generar_preset_performance(self, nombre: str) -> dict:
        """Genera preset optimizado para mÃ¡ximo rendimiento"""
        base = self.motor_cientifico.obtener_preset_ppp(nombre)  # MÃ¡s rÃ¡pido que cientÃ­fico
        base["performance_mode"] = True
        base["reduced_complexity"] = True
        return base
    
    def _generar_preset_fallback(self, nombre: str) -> dict:
        """Preset de emergencia bÃ¡sico"""
        return {
            "carrier": 220.0,
            "beat_freq": 4.0,
            "am_depth": 0.5,
            "fm_index": 3,
            "fallback": True,
            "preset_name": nombre
        }
    
    def _generar_audio_fallback(self, duracion_sec: float) -> np.ndarray:
        """Audio de emergencia bÃ¡sico"""
        t = np.linspace(0, duracion_sec, int(SAMPLE_RATE * duracion_sec))
        audio = 0.1 * np.sin(2 * np.pi * 220 * t)  # Tono bÃ¡sico
        return audio
    
    def _recomendar_modo_preset(self, nombre: str) -> str:
        """Recomienda el mejor modo para un preset dado"""
        if nombre.lower() in ["dopamina", "acetilcolina"]:
            return "adaptativo"
        elif nombre.lower() in ["gaba", "serotonina", "melatonina"]:
            return "terapeutico"
        elif nombre.lower() in ["anandamida", "glutamato"]:
            return "creativo"
        else:
            return "cientifico"
    
    # MÃ©todos de compatibilidad con interfaces Aurora
    def generar_audio(self, config: Dict[str, Any], duracion_sec: float = None) -> np.ndarray:
        """
        ðŸ† VICTORIA #6: Compatibilidad total con auditor Aurora V7
        
        Genera audio neuroacÃºstico usando el motor conectado
        
        Args:
            config: ConfiguraciÃ³n de generaciÃ³n
            duracion_sec: DuraciÃ³n en segundos (AHORA OPCIONAL)
                - Si no se proporciona, se extrae de config
                - Fallback inteligente a 60s por defecto
            
        Returns:
            numpy.ndarray con audio generado
        """
        
        # ðŸ”§ EXTRACCIÃ“N INTELIGENTE DE DURACIÃ“N - VICTORIA #6
        if duracion_sec is None:
            # Prioridad 1: 'duracion_sec' (usado por algunos componentes)
            duracion_sec = config.get('duracion_sec')
            
            # Prioridad 2: 'duracion' (usado por Aurora Director)
            if duracion_sec is None:
                duracion_sec = config.get('duracion')
            
            # Prioridad 3: 'duration' (compatibilidad adicional)
            if duracion_sec is None:
                duracion_sec = config.get('duration')
            
            # Fallback final: 60 segundos por defecto
            if duracion_sec is None:
                duracion_sec = 60.0
                
            # Log para debugging (opcional)
            if hasattr(self, 'logger') and not self.silent:
                logger.debug(f"ðŸ”§ DuraciÃ³n extraÃ­da automÃ¡ticamente: {duracion_sec}s")
        
        # âœ… RESTO DEL CÃ“DIGO ORIGINAL PRESERVADO
        try:
            # Validar configuraciÃ³n primero
            if not self.motor_adapter.validar_configuracion(config):
                raise ValueError("ConfiguraciÃ³n invÃ¡lida")
            
            # Generar audio usando el adaptador existente
            audio = self.motor_adapter.generar_audio(config, duracion_sec)
            
            # Aplicar ganancia por defecto si es necesario
            gain_db = config.get('gain_db', -12.0)
            if gain_db != 0.0:
                gain_linear = 10 ** (gain_db / 20)
                audio = audio * gain_linear
            
            self._stats["generaciones_exitosas"] += 1
            
            if not self.silent:
                logger.info(f"ðŸŽµ Audio generado exitosamente ({audio.shape if hasattr(audio, 'shape') else 'unknown'} samples)")
            
            return audio
            
        except Exception as e:
            logger.error(f"âŒ Error generando audio: {e}")
            # Fallback a generaciÃ³n bÃ¡sica
            return self._generar_audio_fallback(duracion_sec)
    
    def validar_configuracion(self, config: Dict[str, Any]) -> bool:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.motor_adapter.validar_configuracion(config)
    
    def obtener_capacidades(self) -> Dict[str, Any]:
        """Compatibilidad con interfaz MotorAuroraInterface"""
        return self.get_capabilities()
    
    def get_info(self) -> Dict[str, str]:
        """InformaciÃ³n bÃ¡sica del wrapper"""
        return {
            "name": "NeuroMix Aurora V27 Wrapper",
            "version": self.version,
            "description": "Wrapper avanzado con modos configurables y presets inteligentes",
            "modo": self.modo,
            "capabilities": f"Presets aplicados: {self._stats['presets_aplicados']}, Generaciones: {self._stats['generaciones_exitosas']}",
            "integration": "Aurora Director V7 Compatible",
            "status": "Operativo con wrapper avanzado"
        }

# ================================================================
# ðŸŽ¯ REGISTRO AUTOMÃTICO EN EL ECOSISTEMA AURORA
# ================================================================
# Registrar la clase en el espacio global para detecciÃ³n automÃ¡tica
globals()['NeuroMixAuroraV27'] = NeuroMixAuroraV27

# Log de integraciÃ³n exitosa
if not logging.getLogger("Aurora.NeuroMix.V27.Complete").handlers or \
   logging.getLogger("Aurora.NeuroMix.V27.Complete").level <= logging.INFO:
    logger.info("ðŸŽ‰ SEXTA VICTORIA: NeuroMixAuroraV27 wrapper integrado exitosamente")
    logger.info("ðŸ”§ Clase disponible: NeuroMixAuroraV27 con soporte para aplicar_presets")
    logger.info("âœ… Compatible con: Aurora Director V7, objective_manager, GUI")

if __name__ == "__main__":
    print(f"NeuroMix V27 Complete - Sistema NeuroacÃºstico Total")
    print("=" * 80)
    
    info = get_aurora_info()
    print(f"{info['compatibility']}")
    print(f"Compatibilidad PPP: {info['features']['ppp_compatibility']}")
    print(f"IntegraciÃ³n Aurora: {info['features']['aurora_director_integration']}")
    
    print(f"\nTest PPP (compatibilidad 100%):")
    try:
        legacy_audio = generate_neuro_wave("dopamina", 2.0, "binaural", intensity="alta")
        print(f"   Audio PPP generado: {legacy_audio.shape}")
    except Exception as e:
        print(f"   Error PPP: {e}")
    
    print(f"\nTest Aurora Director:")
    try:
        config_aurora = {'objetivo': 'concentracion', 'intensidad': 'media', 'estilo': 'crystalline', 'calidad_objetivo': 'alta'}
        
        engine = _global_engine
        if engine.validar_configuracion(config_aurora):
            audio_aurora = engine.generar_audio(config_aurora, 2.0)
            print(f"   Audio Aurora generado: {audio_aurora.shape}")
        else:
            print(f"   ConfiguraciÃ³n Aurora invÃ¡lida")
    except Exception as e:
        print(f"   Error Aurora: {e}")
    
    print(f"\nTest avanzado V27:")
    try:
        config = create_aurora_config(neurotransmitter="serotonina", duration_sec=1.0, wave_type="therapeutic", quality_level=NeuroQualityLevel.THERAPEUTIC)
        
        advanced_audio, analysis = generate_aurora_session(config)
        print(f"   Audio avanzado: {advanced_audio.shape}")
        print(f"   Calidad: {analysis.get('quality_score', 'N/A')}/100")
    except Exception as e:
        print(f"   Error avanzado: {e}")
    
    stats = _global_engine.get_processing_stats()
    print(f"\nEstadÃ­sticas del motor:")
    print(f"   â€¢ Total generado: {stats['total_generated']}")
    print(f"   â€¢ Usos PPP: {stats['ppp_compatibility_uses']}")
    print(f"   â€¢ Integraciones Aurora: {stats['aurora_integrations']}")
    
    print(f"\nNEUROMIX V27 COMPLETE")
    print(f"Compatible 100% con PPP + Aurora Director V7")
    print(f"Sistema cientÃ­fico + fallbacks garantizados")
    print(f"Â¡Motor neuroacÃºstico mÃ¡s completo del ecosistema Aurora!")

# Alias oficial Ãºnico para compatibilidad AuroraDirector
# AuroraNeuroAcousticEngineV27 = AuroraNeuroAcousticEngineV27Connected  # COMENTADO: CAUSA RECURSIÃ“N